{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bb6b2b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winutils.exe: C:\\Users\\Rodrigo\\.spark\\hadoop\\bin\\winutils.exe\n",
      "hadoop.dll: C:\\Users\\Rodrigo\\.spark\\hadoop\\bin\\hadoop.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_in_path(filename):\n",
    "    for path in os.environ[\"PATH\"].split(os.pathsep):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            return full_path\n",
    "    return None\n",
    "\n",
    "print(\"winutils.exe:\", find_in_path(\"winutils.exe\"))\n",
    "print(\"hadoop.dll:\", find_in_path(\"hadoop.dll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "0f1128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "get_spark_session.cache_clear()\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "647e768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Fetching BACEN 11: 02/05/2016 to 02/05/2025 (step=10)\n",
      "âœ… Retrieved 2258 rows.\n",
      "ðŸ”Ž Fetching BACEN 11: 01/05/2007 to 01/05/2016 (step=10)\n",
      "âœ… Retrieved 2262 rows.\n",
      "ðŸ”Ž Fetching BACEN 11: 30/04/1998 to 30/04/2007 (step=10)\n",
      "âœ… Retrieved 2260 rows.\n",
      "ðŸ”Ž Fetching BACEN 11: 29/04/1989 to 29/04/1998 (step=10)\n",
      "âœ… Retrieved 2246 rows.\n",
      "ðŸ”Ž Fetching BACEN 11: 28/04/1980 to 28/04/1989 (step=10)\n",
      "âœ… Retrieved 726 rows.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1971 to 27/04/1980 (step=10)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1971&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1972 to 27/04/1980 (step=9)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1972&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1973 to 27/04/1980 (step=8)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1973&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1974 to 27/04/1980 (step=7)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1974&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1975 to 27/04/1980 (step=6)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1975&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1976 to 27/04/1980 (step=5)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1976&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1977 to 27/04/1980 (step=4)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1977&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1978 to 27/04/1980 (step=3)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1978&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1979 to 27/04/1980 (step=2)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1979&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸ”Ž Fetching BACEN 11: 27/04/1980 to 27/04/1980 (step=1)\n",
      "âŒ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1980&dataFinal=27/04/1980. Reducing step.\n",
      "ðŸŽ‰ Finished fetching BACEN series 11. Total windows: 5\n",
      "ðŸ“¦ Total rows fetched: 9752\n",
      "9752 (9752, 2) data     datetime64[ns]\n",
      "valor           float64\n",
      "dtype: object         data     valor\n",
      "0 1986-06-04  0.065041\n",
      "1 1986-06-05  0.067397\n",
      "2 1986-06-06  0.066740\n",
      "3 1986-06-09  0.068247\n",
      "4 1986-06-10  0.067041\n"
     ]
    }
   ],
   "source": [
    "# 2. IngestÃ£o BACEN API\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "\n",
    "def fetch_all_bacen_series(series_id, end_date=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Fetch all data from BACEN API for a given series_id, handling the 10-year window limit.\n",
    "    Logs progress for each window.\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today()\n",
    "    all_data = []\n",
    "    step = 10  # years\n",
    "    min_year = 1900  # BACEN data doesn't go before this\n",
    "    finished = False\n",
    "    window_count = 0\n",
    "    while not finished:\n",
    "        start_date = end_date.replace(year=max(min_year, end_date.year - step + 1))\n",
    "        print(f\"ðŸ”Ž Fetching BACEN {series_id}: {start_date.strftime('%d/%m/%Y')} to {end_date.strftime('%d/%m/%Y')} (step={step})\")\n",
    "        url = (\n",
    "            f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_id}/dados\"\n",
    "            f\"?formato=json&dataInicial={start_date.strftime('%d/%m/%Y')}&dataFinal={end_date.strftime('%d/%m/%Y')}\"\n",
    "        )\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            df = pd.read_json(io.StringIO(response.text))\n",
    "            if df.empty:\n",
    "                print(\"âš ï¸  No data returned for window. Reducing step.\")\n",
    "                if step == 1:\n",
    "                    finished = True\n",
    "                else:\n",
    "                    step = max(1, step - 1)\n",
    "                continue\n",
    "            print(f\"âœ… Retrieved {len(df)} rows.\")\n",
    "            all_data.append(df)\n",
    "            window_count += 1\n",
    "            # Move window back\n",
    "            end_date = start_date - timedelta(days=1)\n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error: {e}. Reducing step.\")\n",
    "            if step == 1:\n",
    "                finished = True\n",
    "            else:\n",
    "                step = max(1, step - 1)\n",
    "    print(f\"ðŸŽ‰ Finished fetching BACEN series {series_id}. Total windows: {window_count}\")\n",
    "    if all_data:\n",
    "        result = pd.concat(all_data, ignore_index=True)\n",
    "        result.columns = [\"data\", \"valor\"]\n",
    "        result[\"data\"] = pd.to_datetime(result[\"data\"], format=\"%d/%m/%Y\")\n",
    "        result[\"valor\"] = pd.to_numeric(result[\"valor\"], errors=\"coerce\")\n",
    "        result = result.sort_values(\"data\").reset_index(drop=True)\n",
    "        print(f\"ðŸ“¦ Total rows fetched: {len(result)}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"âš ï¸  No data fetched from BACEN API.\")\n",
    "        return pd.DataFrame(columns=[\"data\", \"valor\"])\n",
    "\n",
    "# Example usage:\n",
    "bacen_series_id = 11  # SELIC\n",
    "df_bacen = fetch_all_bacen_series(bacen_series_id)\n",
    "print(len(df_bacen), df_bacen.shape, df_bacen.dtypes, df_bacen.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6dd6b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202505.zip\n",
      "âœ… Loaded inf_diario_fi_202505.csv (2025-05) with 7 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202504.zip\n",
      "âœ… Loaded inf_diario_fi_202504.csv (2025-04) with 479399 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202503.zip\n",
      "âœ… Loaded inf_diario_fi_202503.csv (2025-03) with 487107 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202502.zip\n",
      "âœ… Loaded inf_diario_fi_202502.csv (2025-02) with 511188 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202501.zip\n",
      "âœ… Loaded inf_diario_fi_202501.csv (2025-01) with 560316 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202412.zip\n",
      "âœ… Loaded inf_diario_fi_202412.csv (2024-12) with 538841 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202411.zip\n",
      "âœ… Loaded inf_diario_fi_202411.csv (2024-11) with 486379 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202410.zip\n",
      "âœ… Loaded inf_diario_fi_202410.csv (2024-10) with 593063 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202409.zip\n",
      "âœ… Loaded inf_diario_fi_202409.csv (2024-09) with 538493 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202408.zip\n",
      "âœ… Loaded inf_diario_fi_202408.csv (2024-08) with 565953 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202407.zip\n",
      "âœ… Loaded inf_diario_fi_202407.csv (2024-07) with 593746 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202406.zip\n",
      "âœ… Loaded inf_diario_fi_202406.csv (2024-06) with 517137 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202405.zip\n",
      "âœ… Loaded inf_diario_fi_202405.csv (2024-05) with 543625 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202404.zip\n",
      "âœ… Loaded inf_diario_fi_202404.csv (2024-04) with 569499 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202403.zip\n",
      "âœ… Loaded inf_diario_fi_202403.csv (2024-03) with 517245 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202402.zip\n",
      "âœ… Loaded inf_diario_fi_202402.csv (2024-02) with 491206 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202401.zip\n",
      "âœ… Loaded inf_diario_fi_202401.csv (2024-01) with 567834 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202312.zip\n",
      "âœ… Loaded inf_diario_fi_202312.csv (2023-12) with 514295 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202311.zip\n",
      "âœ… Loaded inf_diario_fi_202311.csv (2023-11) with 511280 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202310.zip\n",
      "âœ… Loaded inf_diario_fi_202310.csv (2023-10) with 537581 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202309.zip\n",
      "âœ… Loaded inf_diario_fi_202309.csv (2023-09) with 505652 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202308.zip\n",
      "âœ… Loaded inf_diario_fi_202308.csv (2023-08) with 578756 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202307.zip\n",
      "âœ… Loaded inf_diario_fi_202307.csv (2023-07) with 526682 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202306.zip\n",
      "âœ… Loaded inf_diario_fi_202306.csv (2023-06) with 525127 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202305.zip\n",
      "âœ… Loaded inf_diario_fi_202305.csv (2023-05) with 548579 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202304.zip\n",
      "âœ… Loaded inf_diario_fi_202304.csv (2023-04) with 447645 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202303.zip\n",
      "âœ… Loaded inf_diario_fi_202303.csv (2023-03) with 568942 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202302.zip\n",
      "âœ… Loaded inf_diario_fi_202302.csv (2023-02) with 444372 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202301.zip\n",
      "âœ… Loaded inf_diario_fi_202301.csv (2023-01) with 542278 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202212.zip\n",
      "âœ… Loaded inf_diario_fi_202212.csv (2022-12) with 539894 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202211.zip\n",
      "âœ… Loaded inf_diario_fi_202211.csv (2022-11) with 488756 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202210.zip\n",
      "âœ… Loaded inf_diario_fi_202210.csv (2022-10) with 485486 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202209.zip\n",
      "âœ… Loaded inf_diario_fi_202209.csv (2022-09) with 506331 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202208.zip\n",
      "âœ… Loaded inf_diario_fi_202208.csv (2022-08) with 551185 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202207.zip\n",
      "âœ… Loaded inf_diario_fi_202207.csv (2022-07) with 500546 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202206.zip\n",
      "âœ… Loaded inf_diario_fi_202206.csv (2022-06) with 496430 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202205.zip\n",
      "âœ… Loaded inf_diario_fi_202205.csv (2022-05) with 515505 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202204.zip\n",
      "âœ… Loaded inf_diario_fi_202204.csv (2022-04) with 442702 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202203.zip\n",
      "âœ… Loaded inf_diario_fi_202203.csv (2022-03) with 509156 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202202.zip\n",
      "âœ… Loaded inf_diario_fi_202202.csv (2022-02) with 437388 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202201.zip\n",
      "âœ… Loaded inf_diario_fi_202201.csv (2022-01) with 480909 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202112.zip\n",
      "âœ… Loaded inf_diario_fi_202112.csv (2021-12) with 522539 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202111.zip\n",
      "âœ… Loaded inf_diario_fi_202111.csv (2021-11) with 448543 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202110.zip\n",
      "âœ… Loaded inf_diario_fi_202110.csv (2021-10) with 443413 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202109.zip\n",
      "âœ… Loaded inf_diario_fi_202109.csv (2021-09) with 460276 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202108.zip\n",
      "âœ… Loaded inf_diario_fi_202108.csv (2021-08) with 476411 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202107.zip\n",
      "âœ… Loaded inf_diario_fi_202107.csv (2021-07) with 469766 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202106.zip\n",
      "âœ… Loaded inf_diario_fi_202106.csv (2021-06) with 441178 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202105.zip\n",
      "âœ… Loaded inf_diario_fi_202105.csv (2021-05) with 434213 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202104.zip\n",
      "âœ… Loaded inf_diario_fi_202104.csv (2021-04) with 407176 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202103.zip\n",
      "âœ… Loaded inf_diario_fi_202103.csv (2021-03) with 460407 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202102.zip\n",
      "âœ… Loaded inf_diario_fi_202102.csv (2021-02) with 355168 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202101.zip\n",
      "âœ… Loaded inf_diario_fi_202101.csv (2021-01) with 389625 rows\n",
      "ðŸ”Ž Fetching CVM: https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/inf_diario_fi_202012.zip\n",
      "âš ï¸  No valid zip for 2020-12. Stopping.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "import requests\n",
    "from collections import Counter\n",
    "from datetime import datetime  #noqa\n",
    "from difflib import get_close_matches\n",
    "from functools import reduce\n",
    "\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def fetch_all_cvm_months(start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    Fetch all CVM FI daily reports going back month by month until no data is found.\n",
    "    Returns a list of Spark DataFrames (one per month), going backward in time.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    today = datetime.today()\n",
    "    year = today.year\n",
    "    month = today.month\n",
    "\n",
    "    while (year > start_year) or (year == start_year and month >= start_month):\n",
    "        cvm_base_url = \"https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/\"\n",
    "        cvm_file_name = f\"inf_diario_fi_{year}{str(month).zfill(2)}.zip\"\n",
    "        cvm_url = f\"{cvm_base_url}{cvm_file_name}\"\n",
    "        print(f\"ðŸ”Ž Fetching CVM: {cvm_url}\")\n",
    "        try:\n",
    "            response = requests.get(cvm_url)\n",
    "            if response.status_code != requests.codes.ok or not response.content.startswith(b'PK'):\n",
    "                print(f\"âš ï¸  No valid zip for {year}-{month:02d}. Stopping.\")\n",
    "                break\n",
    "            with tempfile.NamedTemporaryFile(delete=False, suffix=\".zip\") as tmp:\n",
    "                tmp.write(response.content)\n",
    "                tmp_path = tmp.name\n",
    "            with zipfile.ZipFile(tmp_path, 'r') as zip_ref:\n",
    "                csv_name = zip_ref.namelist()[0]\n",
    "                zip_ref.extract(csv_name, os.path.dirname(tmp_path))\n",
    "                csv_path = os.path.join(os.path.dirname(tmp_path), csv_name)\n",
    "            df = spark.read.csv(\n",
    "                csv_path,\n",
    "                header=True,\n",
    "                sep=\";\",\n",
    "                inferSchema=True,\n",
    "                encoding=\"ISO-8859-1\"\n",
    "            )\n",
    "            row_count = df.count()\n",
    "            if row_count == 0:\n",
    "                print(f\"âš ï¸  No data found for {year}-{month:02d}. Stopping.\")\n",
    "                os.unlink(tmp_path)\n",
    "                os.unlink(csv_path)\n",
    "                break\n",
    "            df.cache()\n",
    "            dfs.append(df)\n",
    "            print(f\"âœ… Loaded {csv_name} ({year}-{month:02d}) with {row_count} rows\")\n",
    "            os.unlink(tmp_path)\n",
    "            os.unlink(csv_path)\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Failed to fetch or load {cvm_url}: {e}\")\n",
    "            break\n",
    "        # Move to previous month\n",
    "        if month == 1:\n",
    "            month = 12\n",
    "            year -= 1\n",
    "        else:\n",
    "            month -= 1\n",
    "    return dfs\n",
    "\n",
    "# Example usage:\n",
    "dfs = fetch_all_cvm_months(start_year=2015, start_month=1)\n",
    "if dfs:\n",
    "    # Fuzzy schema normalization\n",
    "    # Find the most common set of column names\n",
    "    colname_lists = [tuple(sorted(df.columns)) for df in dfs]\n",
    "    most_common_cols, _ = Counter(colname_lists).most_common(1)[0]\n",
    "    most_common_cols = list(most_common_cols)\n",
    "\n",
    "    def fuzzy_normalize_df(df, target_cols, cutoff=0.8):\n",
    "        col_map = {}\n",
    "        for target in target_cols:\n",
    "            match = get_close_matches(target, df.columns, n=1, cutoff=cutoff)\n",
    "            if match:\n",
    "                col_map[match[0]] = target\n",
    "        # Rename columns that match\n",
    "        for src, tgt in col_map.items():\n",
    "            if src != tgt:\n",
    "                df = df.withColumnRenamed(src, tgt)\n",
    "        # Add missing columns as nulls\n",
    "        for col in target_cols:\n",
    "            if col not in df.columns:\n",
    "                df = df.withColumn(col, F.lit(None))\n",
    "        # Select only target columns in order\n",
    "        df = df.select([col for col in target_cols])\n",
    "        return df\n",
    "\n",
    "    dfs_normalized = [fuzzy_normalize_df(df, most_common_cols) for df in dfs]\n",
    "    cvm_spark_df = reduce(DataFrame.unionByName, reversed(dfs_normalized))\n",
    "else:\n",
    "    print(\"âš ï¸ No CVM data was fetched. The DataFrame list is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27d51403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 26075230\n",
      "Columns: 9\n",
      "Schema: [('CAPTC_DIA', 'double'), ('CNPJ_FUNDO', 'string'), ('DT_COMPTC', 'date'), ('NR_COTST', 'int'), ('RESG_DIA', 'double'), ('TP_FUNDO', 'string'), ('VL_PATRIM_LIQ', 'double'), ('VL_QUOTA', 'double'), ('VL_TOTAL', 'double')]\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "|CAPTC_DIA|CNPJ_FUNDO        |DT_COMPTC |NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA  |VL_TOTAL  |\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "|0.0      |00.017.024/0001-53|2021-01-04|1       |0.0     |FI      |1095773.57   |27.5033358|1097664.87|\n",
      "|0.0      |00.017.024/0001-53|2021-01-05|1       |0.0     |FI      |1095778.31   |27.5034547|1097742.61|\n",
      "|0.0      |00.017.024/0001-53|2021-01-06|1       |0.0     |FI      |1095768.02   |27.5031964|1097837.04|\n",
      "|0.0      |00.017.024/0001-53|2021-01-07|1       |0.0     |FI      |1095774.2    |27.5033516|1097939.54|\n",
      "|0.0      |00.017.024/0001-53|2021-01-08|1       |0.0     |FI      |1095788.49   |27.5037102|1096790.38|\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Rows: {cvm_spark_df.count()}\",\n",
    "    f\"Columns: {len(cvm_spark_df.columns)}\",\n",
    "    f\"Schema: {cvm_spark_df.dtypes}\",\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "cvm_spark_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39c3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airflow\n",
      "âœ… Bucket 'lakehouse' jÃ¡ existe.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "from botocore.exceptions import ClientError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# ConfiguraÃ§Ãµes do MinIO\n",
    "MINIO_ENDPOINT = \"http://localhost:9000\"\n",
    "ACCESS_KEY = os.getenv(\"MINIO_USER\")\n",
    "SECRET_KEY = os.getenv(\"MINIO_PASSWORD\")\n",
    "print(os.getenv(\"AIRFLOW_PROJ_DIR\"))\n",
    "BUCKET_NAME = \"lakehouse\"\n",
    "\n",
    "# Conectar ao MinIO (S3-compatible)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")\n",
    "\n",
    "# Checar e criar bucket\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"âœ… Bucket '{BUCKET_NAME}' jÃ¡ existe.\")\n",
    "except ClientError as e:\n",
    "    error_code = int(e.response[\"Error\"][\"Code\"])\n",
    "    if error_code == requests.codes.not_found:\n",
    "        print(f\"ðŸ”§ Criando bucket '{BUCKET_NAME}'...\")\n",
    "        s3.create_bucket(Bucket=BUCKET_NAME)\n",
    "        print(\"âœ… Bucket criado com sucesso.\")\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1e749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Salvar como Delta (Bronze) no MinIO\n",
    "df_bacen_spark = spark.createDataFrame(df_bacen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4633468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bacen_spark.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/bronze/bacen_selic/\")\n",
    "cvm_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/bronze/cvm_if_di/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9b61619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TransformaÃ§Ãµes da camada Silver\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver_bacen = (\n",
    "    df_bacen_spark\n",
    "    .withColumn(\"ano\", F.year(\"data\"))\n",
    "    .withColumn(\"mes\", F.month(\"data\"))\n",
    "    .withColumn(\"dia\", F.dayofmonth(\"data\"))\n",
    ")\n",
    "\n",
    "silver_cvm = (\n",
    "    cvm_spark_df.withColumn(\"cap_liquida_dia\", F.col(\"CAPTC_DIA\") - F.col(\"RESG_DIA\"))\n",
    "        .withColumn(\"ano\", F.year(\"DT_COMPTC\"))\n",
    "        .withColumn(\"mes\", F.month(\"DT_COMPTC\"))\n",
    "        .withColumn(\"dia\", F.dayofmonth(\"DT_COMPTC\"))\n",
    "        .filter(F.col(\"VL_QUOTA\") > 0)\n",
    "        .filter(F.col(\"VL_PATRIM_LIQ\") > 0)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "silver_bacen.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/silver/bacen_selic/\")\n",
    "silver_cvm.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/silver/cvm_if_di/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccbce57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "|CAPTC_DIA|CNPJ_FUNDO        |DT_COMPTC |NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA  |VL_TOTAL  |cap_liquida_dia|ano |mes|dia|\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "|0.0      |00.017.024/0001-53|2021-01-04|1       |0.0     |FI      |1095773.57   |27.5033358|1097664.87|0.0            |2021|1  |4  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-05|1       |0.0     |FI      |1095778.31   |27.5034547|1097742.61|0.0            |2021|1  |5  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-06|1       |0.0     |FI      |1095768.02   |27.5031964|1097837.04|0.0            |2021|1  |6  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-07|1       |0.0     |FI      |1095774.2    |27.5033516|1097939.54|0.0            |2021|1  |7  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-08|1       |0.0     |FI      |1095788.49   |27.5037102|1096790.38|0.0            |2021|1  |8  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-11|1       |4079.29 |FI      |1091741.25   |27.5045147|1092815.44|-4079.29       |2021|1  |11 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-12|1       |0.0     |FI      |1091757.17   |27.5049157|1092924.8 |0.0            |2021|1  |12 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-13|1       |0.0     |FI      |1091778.39   |27.5054503|1093008.2 |0.0            |2021|1  |13 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-14|1       |0.0     |FI      |1091773.65   |27.5053309|1093080.65|0.0            |2021|1  |14 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-15|1       |0.0     |FI      |1091757.92   |27.5049346|1093180.0 |0.0            |2021|1  |15 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-18|1       |0.0     |FI      |1091768.13   |27.5051919|1093267.95|0.0            |2021|1  |18 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-19|1       |0.0     |FI      |1091767.4    |27.5051735|1093376.59|0.0            |2021|1  |19 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-20|1       |0.0     |FI      |1091787.4    |27.5056773|1092837.03|0.0            |2021|1  |20 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-21|1       |0.0     |FI      |1091776.0    |27.5053901|1092916.89|0.0            |2021|1  |21 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-22|1       |0.0     |FI      |1091767.17   |27.5051677|1093005.15|0.0            |2021|1  |22 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-25|1       |0.0     |FI      |1091765.14   |27.5051165|1093055.58|0.0            |2021|1  |25 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-26|1       |0.0     |FI      |1091761.38   |27.5050218|1093137.6 |0.0            |2021|1  |26 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-27|1       |0.0     |FI      |1091754.18   |27.5048404|1093192.16|0.0            |2021|1  |27 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-28|1       |0.0     |FI      |1091720.58   |27.5039939|1093286.91|0.0            |2021|1  |28 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-29|1       |0.0     |FI      |1091731.51   |27.5042693|1093386.42|0.0            |2021|1  |29 |\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver_cvm.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "599537b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in CNPJ_FUNDO: 0 of 9137937 (0.00%)\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "|CAPTC_DIA|CNPJ_FUNDO|DT_COMPTC|NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA|VL_TOTAL|cap_liquida_dia|ano|mes|dia|\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count nulls in CNPJ_FUNDO\n",
    "null_count = silver_cvm.filter(F.col(\"CNPJ_FUNDO\").isNull()).count()\n",
    "total_count = silver_cvm.count()\n",
    "print(f\"Nulls in CNPJ_FUNDO: {null_count} of {total_count} ({null_count/total_count:.2%})\")\n",
    "\n",
    "# Show some rows with null CNPJ_FUNDO\n",
    "silver_cvm.filter(\n",
    "    (F.col(\"CNPJ_FUNDO\").isNull()) & (F.col(\"NR_COTST\") > 1)\n",
    ").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cd8546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clean expectation suite created and saved (no validation run, no validator used).\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "if \"silver_bacen_selic\" in [asset.name for asset in spark_ds.assets]:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "\n",
    "# Overwrite the expectation suite with only valid expectations (NO validation run)\n",
    "suite_name = \"silver_bacen_selic_suite\"\n",
    "if suite_name in [suite.expectation_suite_name for suite in context.list_expectation_suites()]:\n",
    "    context.delete_expectation_suite(suite_name)\n",
    "suite = context.add_expectation_suite(suite_name)\n",
    "\n",
    "# Add expectations directly to the suite (no validator, no data access)\n",
    "suite.expectations = [\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"data\", \"type_\": \"TimestampType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"valor\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"valor\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_row_count_to_be_between\",\n",
    "        kwargs={\"min_value\": 1}\n",
    "    ),\n",
    "]\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "print(\"âœ… Clean expectation suite created and saved (no validation run, no validator used).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6ee1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clean expectation suite for silver_cvm created and saved (no validation run, no validator used).\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "if \"silver_cvm_if_di\" in [asset.name for asset in spark_ds.assets]:\n",
    "    spark_ds.delete_asset(\"silver_cvm_if_di\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_cvm_if_di\", dataframe=silver_cvm)\n",
    "\n",
    "# Overwrite the expectation suite with only valid expectations (NO validation run)\n",
    "suite_name = \"silver_cvm_if_di_suite\"\n",
    "if suite_name in [suite.expectation_suite_name for suite in context.list_expectation_suites()]:\n",
    "    context.delete_expectation_suite(suite_name)\n",
    "suite = context.add_expectation_suite(suite_name)\n",
    "\n",
    "# Add expectations directly to the suite (no validator, no data access)\n",
    "suite.expectations = [\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"CNPJ_FUNDO\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"cap_liquida_dia\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"CNPJ_FUNDO\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\", \"type_\": \"DateType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_row_count_to_be_between\",\n",
    "        kwargs={\"min_value\": 1}\n",
    "    ),\n",
    "]\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "print(\"âœ… Clean expectation suite for silver_cvm created and saved (no validation run, no validator used).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b878b463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09cf90acf09454ca0cbbe5b5f383c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7607711f344b5797a95e107a6743f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation Success (bacen & cvm): False\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# Ensure Spark datasource exists\n",
    "if \"spark_datasource\" not in context.datasources:\n",
    "    context.sources.add_spark(name=\"spark_datasource\")\n",
    "\n",
    "# (Re-)register the assets with the current DataFrames\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "asset_names = [asset.name for asset in spark_ds.assets]\n",
    "if \"silver_bacen_selic\" in asset_names:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "if \"silver_cvm_if_di\" in asset_names:\n",
    "    spark_ds.delete_asset(\"silver_cvm_if_di\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "spark_ds.add_dataframe_asset(name=\"silver_cvm_if_di\", dataframe=silver_cvm)\n",
    "\n",
    "# Ensure expectation suites exist\n",
    "suite_names = [suite.expectation_suite_name for suite in context.list_expectation_suites()]\n",
    "if \"silver_bacen_selic_suite\" not in suite_names:\n",
    "    context.add_expectation_suite(\"silver_bacen_selic_suite\")\n",
    "if \"silver_cvm_if_di_suite\" not in suite_names:\n",
    "    context.add_expectation_suite(\"silver_cvm_if_di_suite\")\n",
    "\n",
    "# Build batch requests\n",
    "batch_request_bacen = {\n",
    "    \"datasource_name\": \"spark_datasource\",\n",
    "    \"data_asset_name\": \"silver_bacen_selic\",\n",
    "}\n",
    "batch_request_cvm = {\n",
    "    \"datasource_name\": \"spark_datasource\",\n",
    "    \"data_asset_name\": \"silver_cvm_if_di\",\n",
    "}\n",
    "\n",
    "# Run the checkpoint for both assets\n",
    "checkpoint = SimpleCheckpoint(\n",
    "    name=\"silver_combined_checkpoint\",\n",
    "    data_context=context,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request_bacen,\n",
    "            \"expectation_suite_name\": \"silver_bacen_selic_suite\",\n",
    "        },\n",
    "        {\n",
    "            \"batch_request\": batch_request_cvm,\n",
    "            \"expectation_suite_name\": \"silver_cvm_if_di_suite\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = checkpoint.run()\n",
    "print(\"âœ… Validation Success (bacen & cvm):\", result[\"success\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a6075ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âŒ Failed: expect_column_values_to_not_be_null on column CNPJ_FUNDO\n",
      "    Details: {'element_count': 25957177, 'unexpected_count': 9020632, 'unexpected_percent': 34.75197630312418, 'partial_unexpected_list': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'partial_unexpected_counts': [{'value': None, 'count': 20}]}\n"
     ]
    }
   ],
   "source": [
    "for run_result in result[\"run_results\"].values():\n",
    "    validation_result = run_result[\"validation_result\"]\n",
    "    for res in validation_result[\"results\"]:\n",
    "        if not res[\"success\"]:\n",
    "            print(f\"âŒ Failed: {res['expectation_config']['expectation_type']} on column {res['expectation_config']['kwargs'].get('column')}\")\n",
    "            print(f\"    Details: {res['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "690ddce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---+-----+------------------+\n",
      "|inicio             |fim                |min|max  |media             |\n",
      "+-------------------+-------------------+---+-----+------------------+\n",
      "|1986-06-04 00:00:00|2025-04-30 00:00:00|0.0|3.626|0.2555755175348646|\n",
      "+-------------------+-------------------+---+-----+------------------+\n",
      "\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "|CNPJ_FUNDO        |data_inicio|data_fim  |vl_quota_inicio|vl_quota_fim |cap_liquida_total    |cotistas_inicio|cotistas_fim|rentabilidade_pct |crescimento_cotistas|\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "|00.360.293/0001-18|2021-01-04 |2023-11-30|30.501901      |27.87017     |-1.8322185264E8      |12826          |2984        |-8.628088459142264|-9842               |\n",
      "|00.068.305/0001-35|2021-01-04 |2023-11-30|27.454385      |35.051298    |-1.6706400189999998E7|7238           |6026        |27.671036885364597|-1212               |\n",
      "|00.071.477/0001-68|2021-01-04 |2023-11-30|10.027742319   |12.522327042 |-3.761534833925E10   |322135         |47017       |24.876833125970965|-275118             |\n",
      "|00.185.259/0001-54|2021-01-04 |2023-11-30|51.55522661    |52.44688596  |-1.219685915E8       |196            |116         |1.7295227053216997|-80                 |\n",
      "|00.017.024/0001-53|2021-01-04 |2023-11-30|27.5033358     |34.0298254   |-193928.61000000002  |1              |1           |23.72981098532783 |0                   |\n",
      "|00.398.561/0001-90|2021-01-04 |2023-11-30|215.8460996    |204.0592828  |-1.0643308632999995E8|4737           |1408        |-5.460750424419528|-3329               |\n",
      "|00.180.995/0001-10|2021-01-04 |2023-11-30|564.770071     |715.168816   |-2.2481302401E8      |2726           |861         |26.630084121437086|-1865               |\n",
      "|00.812.433/0001-41|2021-01-04 |2023-11-30|9.16067        |11.281341    |1.7495191955299997E9 |43588          |71900       |23.149736864224995|28312               |\n",
      "|00.222.725/0001-24|2021-01-04 |2023-11-30|3750.6983937   |4739.9885894 |-5.682295641E7       |1517           |973         |26.376159633675105|-544                |\n",
      "|00.829.163/0001-81|2021-01-04 |2023-11-30|3119.44435     |3840.13484   |-2774212.91          |62             |46          |23.103168678101273|-16                 |\n",
      "|00.524.617/0001-06|2021-01-04 |2023-11-30|12.930825      |12.955702    |-1.2868287760000001E8|5333           |1474        |0.1923852499743832|-3859               |\n",
      "|00.832.445/0001-38|2021-01-04 |2023-11-30|1595.660717    |2069.560427  |-9.099587628E7       |921            |779         |29.69927785719876 |-142                |\n",
      "|00.194.256/0001-87|2021-01-04 |2023-11-30|48.516457869   |62.434695284 |-1.1704974145599992E9|40             |34          |28.687661932329927|-6                  |\n",
      "|00.840.008/0001-66|2021-01-04 |2023-11-30|32.349645      |40.86054     |-4.204447083E7       |1380           |944         |26.309083144498175|-436                |\n",
      "|00.777.815/0001-81|2021-01-04 |2023-11-30|30.5243251     |39.7048878   |-1.3822833036999997E8|6264           |3611        |30.076218458307547|-2653               |\n",
      "|00.842.960/0001-07|2021-01-04 |2023-11-30|28.4334466     |36.7782816   |-2.5210217929999996E7|406            |268         |29.34865799913261 |-138                |\n",
      "|00.073.041/0001-08|2021-01-04 |2023-11-30|28.7917845     |36.9377487   |-9265966.05          |946            |791         |28.29266869512726 |-155                |\n",
      "|00.849.567/0001-37|2021-01-04 |2023-11-30|71382.0023243  |99361.2477996|-6.2766587819999985E7|3              |3           |39.19649850698464 |0                   |\n",
      "|00.822.055/0001-87|2021-01-04 |2023-11-30|37.511935511   |52.610391587 |1.5242389647599998E10|1              |1           |40.249738837316286|0                   |\n",
      "|00.852.311/0001-89|2021-01-04 |2023-11-30|20.325622515   |26.964626872 |-6.032100621369999E9 |36             |67          |32.66322766793744 |31                  |\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def run_gold_pipeline():\n",
    "\n",
    "    # Load silver datasets\n",
    "    # silver_cvm = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/cvm/\")\n",
    "    silver_bacen = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/bacen_selic/\")\n",
    "\n",
    "    # KPIs CVM Fundos\n",
    "    gold_cvm = (\n",
    "        silver_cvm.groupBy(\"CNPJ_FUNDO\")\n",
    "        .agg(\n",
    "            F.min(\"DT_COMPTC\").alias(\"data_inicio\"),\n",
    "            F.max(\"DT_COMPTC\").alias(\"data_fim\"),\n",
    "            F.first(\"VL_QUOTA\", ignorenulls=True).alias(\"vl_quota_inicio\"),\n",
    "            F.last(\"VL_QUOTA\", ignorenulls=True).alias(\"vl_quota_fim\"),\n",
    "            F.sum(\"cap_liquida_dia\").alias(\"cap_liquida_total\"),\n",
    "            F.first(\"NR_COTST\", ignorenulls=True).alias(\"cotistas_inicio\"),\n",
    "            F.last(\"NR_COTST\", ignorenulls=True).alias(\"cotistas_fim\")\n",
    "        )\n",
    "        .withColumn(\"rentabilidade_pct\", ((F.col(\"vl_quota_fim\") - F.col(\"vl_quota_inicio\")) / F.col(\"vl_quota_inicio\")) * 100)\n",
    "        .withColumn(\"crescimento_cotistas\", F.col(\"cotistas_fim\") - F.col(\"cotistas_inicio\"))\n",
    "    )\n",
    "\n",
    "    # KPIs BACEN indicadores\n",
    "    gold_bacen = (\n",
    "        silver_bacen.agg(\n",
    "            F.min(\"data\").alias(\"inicio\"),\n",
    "            F.max(\"data\").alias(\"fim\"),\n",
    "            F.min(\"valor\").alias(\"min\"),\n",
    "            F.max(\"valor\").alias(\"max\"),\n",
    "            F.mean(\"valor\").alias(\"media\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    gold_bacen.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/gold/bacen_kpis/\")\n",
    "    gold_cvm.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/gold/cvm_kpis/\")\n",
    "    return gold_bacen, gold_cvm\n",
    "gold_bacen, gold_cvm = run_gold_pipeline()\n",
    "gold_bacen.show(20,truncate=False)\n",
    "gold_cvm.orderBy(\"data_inicio\", ascending=True).show(20,truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
