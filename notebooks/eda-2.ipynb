{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bb6b2b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winutils.exe: C:\\Users\\Mo.DESKTOP-3491UQD\\.spark\\Hadoop\\bin\\winutils.exe\n",
      "hadoop.dll: C:\\Users\\Mo.DESKTOP-3491UQD\\.spark\\Hadoop\\bin\\hadoop.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_in_path(filename):\n",
    "    for path in os.environ[\"PATH\"].split(os.pathsep):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            return full_path\n",
    "    return None\n",
    "\n",
    "print(\"winutils.exe:\", find_in_path(\"winutils.exe\"))\n",
    "print(\"hadoop.dll:\", find_in_path(\"hadoop.dll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0f1128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "get_spark_session.cache_clear()\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "647e768b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔎 Fetching BACEN 11: 02/05/2016 to 02/05/2025 (step=10)\n",
      "✅ Retrieved 2258 rows.\n",
      "🔎 Fetching BACEN 11: 01/05/2007 to 01/05/2016 (step=10)\n",
      "✅ Retrieved 2262 rows.\n",
      "🔎 Fetching BACEN 11: 30/04/1998 to 30/04/2007 (step=10)\n",
      "✅ Retrieved 2260 rows.\n",
      "🔎 Fetching BACEN 11: 29/04/1989 to 29/04/1998 (step=10)\n",
      "✅ Retrieved 2246 rows.\n",
      "🔎 Fetching BACEN 11: 28/04/1980 to 28/04/1989 (step=10)\n",
      "✅ Retrieved 726 rows.\n",
      "🔎 Fetching BACEN 11: 27/04/1971 to 27/04/1980 (step=10)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1971&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1972 to 27/04/1980 (step=9)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1972&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1973 to 27/04/1980 (step=8)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1973&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1974 to 27/04/1980 (step=7)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1974&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1975 to 27/04/1980 (step=6)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1975&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1976 to 27/04/1980 (step=5)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1976&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1977 to 27/04/1980 (step=4)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1977&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1978 to 27/04/1980 (step=3)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1978&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1979 to 27/04/1980 (step=2)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1979&dataFinal=27/04/1980. Reducing step.\n",
      "🔎 Fetching BACEN 11: 27/04/1980 to 27/04/1980 (step=1)\n",
      "❌ Error: 404 Client Error: Not Found for url: https://api.bcb.gov.br/dados/serie/bcdata.sgs.11/dados?formato=json&dataInicial=27/04/1980&dataFinal=27/04/1980. Reducing step.\n",
      "🎉 Finished fetching BACEN series 11. Total windows: 5\n",
      "📦 Total rows fetched: 9752\n",
      "9752 (9752, 2) data     datetime64[ns]\n",
      "valor           float64\n",
      "dtype: object         data     valor\n",
      "0 1986-06-04  0.065041\n",
      "1 1986-06-05  0.067397\n",
      "2 1986-06-06  0.066740\n",
      "3 1986-06-09  0.068247\n",
      "4 1986-06-10  0.067041\n"
     ]
    }
   ],
   "source": [
    "# 2. Ingestão BACEN API\n",
    "import io\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "\n",
    "def fetch_all_bacen_series(series_id, end_date=None):\n",
    "\n",
    "    \"\"\"\n",
    "    Fetch all data from BACEN API for a given series_id, handling the 10-year window limit.\n",
    "    Logs progress for each window.\n",
    "    \"\"\"\n",
    "    if end_date is None:\n",
    "        end_date = datetime.today()\n",
    "    all_data = []\n",
    "    step = 10  # years\n",
    "    min_year = 1900  # BACEN data doesn't go before this\n",
    "    finished = False\n",
    "    window_count = 0\n",
    "    while not finished:\n",
    "        start_date = end_date.replace(year=max(min_year, end_date.year - step + 1))\n",
    "        print(f\"🔎 Fetching BACEN {series_id}: {start_date.strftime('%d/%m/%Y')} to {end_date.strftime('%d/%m/%Y')} (step={step})\")\n",
    "        url = (\n",
    "            f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{series_id}/dados\"\n",
    "            f\"?formato=json&dataInicial={start_date.strftime('%d/%m/%Y')}&dataFinal={end_date.strftime('%d/%m/%Y')}\"\n",
    "        )\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            df = pd.read_json(io.StringIO(response.text))\n",
    "            if df.empty:\n",
    "                print(\"⚠️  No data returned for window. Reducing step.\")\n",
    "                if step == 1:\n",
    "                    finished = True\n",
    "                else:\n",
    "                    step = max(1, step - 1)\n",
    "                continue\n",
    "            print(f\"✅ Retrieved {len(df)} rows.\")\n",
    "            all_data.append(df)\n",
    "            window_count += 1\n",
    "            # Move window back\n",
    "            end_date = start_date - timedelta(days=1)\n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error: {e}. Reducing step.\")\n",
    "            if step == 1:\n",
    "                finished = True\n",
    "            else:\n",
    "                step = max(1, step - 1)\n",
    "    print(f\"🎉 Finished fetching BACEN series {series_id}. Total windows: {window_count}\")\n",
    "    if all_data:\n",
    "        result = pd.concat(all_data, ignore_index=True)\n",
    "        result.columns = [\"data\", \"valor\"]\n",
    "        result[\"data\"] = pd.to_datetime(result[\"data\"], format=\"%d/%m/%Y\")\n",
    "        result[\"valor\"] = pd.to_numeric(result[\"valor\"], errors=\"coerce\")\n",
    "        result = result.sort_values(\"data\").reset_index(drop=True)\n",
    "        print(f\"📦 Total rows fetched: {len(result)}\")\n",
    "        return result\n",
    "    else:\n",
    "        print(\"⚠️  No data fetched from BACEN API.\")\n",
    "        return pd.DataFrame(columns=[\"data\", \"valor\"])\n",
    "\n",
    "# Example usage:\n",
    "bacen_series_id = 11  # SELIC\n",
    "df_bacen = fetch_all_bacen_series(bacen_series_id)\n",
    "print(len(df_bacen), df_bacen.shape, df_bacen.dtypes, df_bacen.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dd6b0b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Attempt 1 for inf_diario_fi_202505.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202505.csv.\n",
      "✅ Loaded inf_diario_fi_202505.csv (2025-05) with 90 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202504.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202504.csv.\n",
      "✅ Loaded inf_diario_fi_202504.csv (2025-04) with 503066 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202503.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202503.csv.\n",
      "✅ Loaded inf_diario_fi_202503.csv (2025-03) with 487444 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202502.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202502.csv.\n",
      "✅ Loaded inf_diario_fi_202502.csv (2025-02) with 511300 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202501.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202501.csv.\n",
      "✅ Loaded inf_diario_fi_202501.csv (2025-01) with 560370 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202412.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202412.csv.\n",
      "✅ Loaded inf_diario_fi_202412.csv (2024-12) with 538856 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202411.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202411.csv.\n",
      "✅ Loaded inf_diario_fi_202411.csv (2024-11) with 486387 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202410.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202410.csv.\n",
      "✅ Loaded inf_diario_fi_202410.csv (2024-10) with 593063 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202409.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202409.csv.\n",
      "✅ Loaded inf_diario_fi_202409.csv (2024-09) with 538493 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202408.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202408.csv.\n",
      "✅ Loaded inf_diario_fi_202408.csv (2024-08) with 565953 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202407.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202407.csv.\n",
      "✅ Loaded inf_diario_fi_202407.csv (2024-07) with 593746 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202406.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202406.csv.\n",
      "✅ Loaded inf_diario_fi_202406.csv (2024-06) with 517137 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202405.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202405.csv.\n",
      "✅ Loaded inf_diario_fi_202405.csv (2024-05) with 543625 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202404.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202404.csv.\n",
      "✅ Loaded inf_diario_fi_202404.csv (2024-04) with 569499 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202403.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202403.csv.\n",
      "✅ Loaded inf_diario_fi_202403.csv (2024-03) with 517245 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202402.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202402.csv.\n",
      "✅ Loaded inf_diario_fi_202402.csv (2024-02) with 491206 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202401.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202401.csv.\n",
      "✅ Loaded inf_diario_fi_202401.csv (2024-01) with 567834 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202312.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO_CLASSE\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202312.csv.\n",
      "✅ Loaded inf_diario_fi_202312.csv (2023-12) with 514295 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202311.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202311.csv.\n",
      "✅ Loaded inf_diario_fi_202311.csv (2023-11) with 511280 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202310.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202310.csv.\n",
      "✅ Loaded inf_diario_fi_202310.csv (2023-10) with 537581 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202309.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202309.csv.\n",
      "✅ Loaded inf_diario_fi_202309.csv (2023-09) with 505652 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202308.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202308.csv.\n",
      "✅ Loaded inf_diario_fi_202308.csv (2023-08) with 578756 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202307.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202307.csv.\n",
      "✅ Loaded inf_diario_fi_202307.csv (2023-07) with 526682 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202306.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202306.csv.\n",
      "✅ Loaded inf_diario_fi_202306.csv (2023-06) with 525127 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202305.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202305.csv.\n",
      "✅ Loaded inf_diario_fi_202305.csv (2023-05) with 548579 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202304.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202304.csv.\n",
      "✅ Loaded inf_diario_fi_202304.csv (2023-04) with 447645 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202303.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202303.csv.\n",
      "✅ Loaded inf_diario_fi_202303.csv (2023-03) with 568942 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202302.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202302.csv.\n",
      "✅ Loaded inf_diario_fi_202302.csv (2023-02) with 444372 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202301.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202301.csv.\n",
      "✅ Loaded inf_diario_fi_202301.csv (2023-01) with 542278 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202212.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202212.csv.\n",
      "✅ Loaded inf_diario_fi_202212.csv (2022-12) with 539894 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202211.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202211.csv.\n",
      "✅ Loaded inf_diario_fi_202211.csv (2022-11) with 488756 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202210.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202210.csv.\n",
      "✅ Loaded inf_diario_fi_202210.csv (2022-10) with 485486 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202209.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202209.csv.\n",
      "✅ Loaded inf_diario_fi_202209.csv (2022-09) with 506331 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202208.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202208.csv.\n",
      "✅ Loaded inf_diario_fi_202208.csv (2022-08) with 551185 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202207.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202207.csv.\n",
      "✅ Loaded inf_diario_fi_202207.csv (2022-07) with 500546 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202206.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202206.csv.\n",
      "✅ Loaded inf_diario_fi_202206.csv (2022-06) with 496430 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202205.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202205.csv.\n",
      "✅ Loaded inf_diario_fi_202205.csv (2022-05) with 515505 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202204.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202204.csv.\n",
      "✅ Loaded inf_diario_fi_202204.csv (2022-04) with 442702 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202203.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202203.csv.\n",
      "✅ Loaded inf_diario_fi_202203.csv (2022-03) with 509156 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202202.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202202.csv.\n",
      "✅ Loaded inf_diario_fi_202202.csv (2022-02) with 437388 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202201.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202201.csv.\n",
      "✅ Loaded inf_diario_fi_202201.csv (2022-01) with 480909 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202112.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202112.csv.\n",
      "✅ Loaded inf_diario_fi_202112.csv (2021-12) with 522539 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202111.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202111.csv.\n",
      "✅ Loaded inf_diario_fi_202111.csv (2021-11) with 448543 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202110.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202110.csv.\n",
      "✅ Loaded inf_diario_fi_202110.csv (2021-10) with 443413 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202109.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202109.csv.\n",
      "✅ Loaded inf_diario_fi_202109.csv (2021-09) with 460276 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202108.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202108.csv.\n",
      "✅ Loaded inf_diario_fi_202108.csv (2021-08) with 476411 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202107.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202107.csv.\n",
      "✅ Loaded inf_diario_fi_202107.csv (2021-07) with 469766 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202106.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202106.csv.\n",
      "✅ Loaded inf_diario_fi_202106.csv (2021-06) with 441178 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202105.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202105.csv.\n",
      "✅ Loaded inf_diario_fi_202105.csv (2021-05) with 434213 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202104.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202104.csv.\n",
      "✅ Loaded inf_diario_fi_202104.csv (2021-04) with 407176 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202103.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202103.csv.\n",
      "✅ Loaded inf_diario_fi_202103.csv (2021-03) with 460407 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202102.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202102.csv.\n",
      "✅ Loaded inf_diario_fi_202102.csv (2021-02) with 355168 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202101.zip: 200\n",
      "🔍 Found CNPJ column: CNPJ_FUNDO\n",
      "🔍 Found 0 null CNPJ rows in inf_diario_fi_202101.csv.\n",
      "✅ Loaded inf_diario_fi_202101.csv (2021-01) with 389625 rows\n",
      "🔍 Attempt 1 for inf_diario_fi_202012.zip: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202012.zip: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202012.zip: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202012.csv: 403\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202012.csv: 403\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202012.csv: 403\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202012.parquet: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202012.parquet: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202012.parquet: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202012.txt: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202012.txt: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202012.txt: 404\n",
      "⚠️  No valid file for 2020-12 (inf_diario_fi_202012.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-12 after 3 attempts per type. Consecutive missing: 1\n",
      "🔍 Attempt 1 for inf_diario_fi_202011.zip: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202011.zip: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202011.zip: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202011.csv: 403\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202011.csv: 403\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202011.csv: 403\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202011.parquet: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202011.parquet: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202011.parquet: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202011.txt: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202011.txt: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202011.txt: 404\n",
      "⚠️  No valid file for 2020-11 (inf_diario_fi_202011.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-11 after 3 attempts per type. Consecutive missing: 2\n",
      "🔍 Attempt 1 for inf_diario_fi_202010.zip: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202010.zip: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202010.zip: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202010.csv: 403\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202010.csv: 403\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202010.csv: 403\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202010.parquet: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202010.parquet: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202010.parquet: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202010.txt: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202010.txt: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202010.txt: 404\n",
      "⚠️  No valid file for 2020-10 (inf_diario_fi_202010.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-10 after 3 attempts per type. Consecutive missing: 3\n",
      "🔍 Attempt 1 for inf_diario_fi_202009.zip: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202009.zip: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202009.zip: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202009.csv: 403\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202009.csv: 403\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202009.csv: 403\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202009.parquet: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202009.parquet: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202009.parquet: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202009.txt: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202009.txt: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202009.txt: 404\n",
      "⚠️  No valid file for 2020-09 (inf_diario_fi_202009.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-09 after 3 attempts per type. Consecutive missing: 4\n",
      "🔍 Attempt 1 for inf_diario_fi_202008.zip: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202008.zip: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202008.zip: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202008.csv: 403\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202008.csv: 403\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202008.csv: 403\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202008.parquet: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202008.parquet: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202008.parquet: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202008.txt: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202008.txt: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202008.txt: 404\n",
      "⚠️  No valid file for 2020-08 (inf_diario_fi_202008.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-08 after 3 attempts per type. Consecutive missing: 5\n",
      "🔍 Attempt 1 for inf_diario_fi_202007.zip: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202007.zip: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202007.zip: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202007.csv: 403\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202007.csv: 403\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202007.csv: 403\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202007.parquet: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202007.parquet: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202007.parquet: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202007.txt: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202007.txt: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202007.txt: 404\n",
      "⚠️  No valid file for 2020-07 (inf_diario_fi_202007.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-07 after 3 attempts per type. Consecutive missing: 6\n",
      "🔍 Attempt 1 for inf_diario_fi_202006.zip: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202006.zip: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202006.zip: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202006.csv: 403\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202006.csv: 403\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202006.csv: 403\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202006.parquet: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202006.parquet: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202006.parquet: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202006.txt: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202006.txt: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202006.txt: 404\n",
      "⚠️  No valid file for 2020-06 (inf_diario_fi_202006.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-06 after 3 attempts per type. Consecutive missing: 7\n",
      "🔍 Attempt 1 for inf_diario_fi_202005.zip: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202005.zip: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202005.zip: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202005.csv: 403\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202005.csv: 403\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202005.csv: 403\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202005.parquet: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202005.parquet: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202005.parquet: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202005.txt: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202005.txt: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202005.txt: 404\n",
      "⚠️  No valid file for 2020-05 (inf_diario_fi_202005.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-05 after 3 attempts per type. Consecutive missing: 8\n",
      "🔍 Attempt 1 for inf_diario_fi_202004.zip: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202004.zip: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202004.zip: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202004.csv: 403\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202004.csv: 403\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202004.csv: 403\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202004.parquet: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202004.parquet: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202004.parquet: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202004.txt: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202004.txt: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202004.txt: 404\n",
      "⚠️  No valid file for 2020-04 (inf_diario_fi_202004.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-04 after 3 attempts per type. Consecutive missing: 9\n",
      "🔍 Attempt 1 for inf_diario_fi_202003.zip: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202003.zip: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202003.zip: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202003.csv: 403\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202003.csv: 403\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202003.csv: 403\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202003.parquet: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202003.parquet: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202003.parquet: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202003.txt: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202003.txt: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202003.txt: 404\n",
      "⚠️  No valid file for 2020-03 (inf_diario_fi_202003.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-03 after 3 attempts per type. Consecutive missing: 10\n",
      "🔍 Attempt 1 for inf_diario_fi_202002.zip: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202002.zip: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202002.zip: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202002.csv: 403\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202002.csv: 403\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202002.csv: 403\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202002.parquet: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202002.parquet: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202002.parquet: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202002.txt: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202002.txt: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202002.txt: 404\n",
      "⚠️  No valid file for 2020-02 (inf_diario_fi_202002.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-02 after 3 attempts per type. Consecutive missing: 11\n",
      "🔍 Attempt 1 for inf_diario_fi_202001.zip: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202001.zip: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202001.zip: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202001.csv: 403\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202001.csv: 403\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202001.csv: 403\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202001.parquet: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202001.parquet: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202001.parquet: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_202001.txt: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_202001.txt: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_202001.txt: 404\n",
      "⚠️  No valid file for 2020-01 (inf_diario_fi_202001.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2020-01 after 3 attempts per type. Consecutive missing: 12\n",
      "🔍 Attempt 1 for inf_diario_fi_201912.zip: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201912.zip: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201912.zip: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201912.csv: 403\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201912.csv: 403\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201912.csv: 403\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201912.parquet: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201912.parquet: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201912.parquet: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201912.txt: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201912.txt: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201912.txt: 404\n",
      "⚠️  No valid file for 2019-12 (inf_diario_fi_201912.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-12 after 3 attempts per type. Consecutive missing: 13\n",
      "🔍 Attempt 1 for inf_diario_fi_201911.zip: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201911.zip: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201911.zip: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201911.csv: 403\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201911.csv: 403\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201911.csv: 403\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201911.parquet: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201911.parquet: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201911.parquet: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201911.txt: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201911.txt: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201911.txt: 404\n",
      "⚠️  No valid file for 2019-11 (inf_diario_fi_201911.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-11 after 3 attempts per type. Consecutive missing: 14\n",
      "🔍 Attempt 1 for inf_diario_fi_201910.zip: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201910.zip: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201910.zip: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201910.csv: 403\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201910.csv: 403\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201910.csv: 403\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201910.parquet: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201910.parquet: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201910.parquet: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201910.txt: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201910.txt: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201910.txt: 404\n",
      "⚠️  No valid file for 2019-10 (inf_diario_fi_201910.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-10 after 3 attempts per type. Consecutive missing: 15\n",
      "🔍 Attempt 1 for inf_diario_fi_201909.zip: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201909.zip: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201909.zip: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201909.csv: 403\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201909.csv: 403\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201909.csv: 403\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201909.parquet: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201909.parquet: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201909.parquet: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201909.txt: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201909.txt: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201909.txt: 404\n",
      "⚠️  No valid file for 2019-09 (inf_diario_fi_201909.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-09 after 3 attempts per type. Consecutive missing: 16\n",
      "🔍 Attempt 1 for inf_diario_fi_201908.zip: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201908.zip: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201908.zip: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201908.csv: 403\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201908.csv: 403\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201908.csv: 403\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201908.parquet: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201908.parquet: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201908.parquet: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201908.txt: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201908.txt: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201908.txt: 404\n",
      "⚠️  No valid file for 2019-08 (inf_diario_fi_201908.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-08 after 3 attempts per type. Consecutive missing: 17\n",
      "🔍 Attempt 1 for inf_diario_fi_201907.zip: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201907.zip: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201907.zip: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201907.csv: 403\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201907.csv: 403\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201907.csv: 403\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201907.parquet: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201907.parquet: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201907.parquet: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201907.txt: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201907.txt: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201907.txt: 404\n",
      "⚠️  No valid file for 2019-07 (inf_diario_fi_201907.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-07 after 3 attempts per type. Consecutive missing: 18\n",
      "🔍 Attempt 1 for inf_diario_fi_201906.zip: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201906.zip: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201906.zip: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201906.csv: 403\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201906.csv: 403\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201906.csv: 403\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201906.parquet: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201906.parquet: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201906.parquet: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201906.txt: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201906.txt: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201906.txt: 404\n",
      "⚠️  No valid file for 2019-06 (inf_diario_fi_201906.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-06 after 3 attempts per type. Consecutive missing: 19\n",
      "🔍 Attempt 1 for inf_diario_fi_201905.zip: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201905.zip: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201905.zip: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201905.csv: 403\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201905.csv: 403\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201905.csv: 403\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201905.parquet: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201905.parquet: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201905.parquet: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201905.txt: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201905.txt: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201905.txt: 404\n",
      "⚠️  No valid file for 2019-05 (inf_diario_fi_201905.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-05 after 3 attempts per type. Consecutive missing: 20\n",
      "🔍 Attempt 1 for inf_diario_fi_201904.zip: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201904.zip: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201904.zip: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201904.csv: 403\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201904.csv: 403\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201904.csv: 403\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201904.parquet: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201904.parquet: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201904.parquet: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201904.txt: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201904.txt: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201904.txt: 404\n",
      "⚠️  No valid file for 2019-04 (inf_diario_fi_201904.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-04 after 3 attempts per type. Consecutive missing: 21\n",
      "🔍 Attempt 1 for inf_diario_fi_201903.zip: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201903.zip: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201903.zip: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201903.csv: 403\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201903.csv: 403\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201903.csv: 403\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201903.parquet: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201903.parquet: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201903.parquet: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201903.txt: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201903.txt: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201903.txt: 404\n",
      "⚠️  No valid file for 2019-03 (inf_diario_fi_201903.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-03 after 3 attempts per type. Consecutive missing: 22\n",
      "🔍 Attempt 1 for inf_diario_fi_201902.zip: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201902.zip: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201902.zip: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201902.csv: 403\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201902.csv: 403\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201902.csv: 403\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201902.parquet: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201902.parquet: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201902.parquet: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201902.txt: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201902.txt: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201902.txt: 404\n",
      "⚠️  No valid file for 2019-02 (inf_diario_fi_201902.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-02 after 3 attempts per type. Consecutive missing: 23\n",
      "🔍 Attempt 1 for inf_diario_fi_201901.zip: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201901.zip: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201901.zip: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201901.csv: 403\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201901.csv: 403\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201901.csv: 403\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201901.parquet: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201901.parquet: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201901.parquet: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201901.txt: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201901.txt: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201901.txt: 404\n",
      "⚠️  No valid file for 2019-01 (inf_diario_fi_201901.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2019-01 after 3 attempts per type. Consecutive missing: 24\n",
      "🔍 Attempt 1 for inf_diario_fi_201812.zip: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201812.zip: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201812.zip: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201812.csv: 403\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201812.csv: 403\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201812.csv: 403\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201812.parquet: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201812.parquet: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201812.parquet: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201812.txt: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201812.txt: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201812.txt: 404\n",
      "⚠️  No valid file for 2018-12 (inf_diario_fi_201812.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-12 after 3 attempts per type. Consecutive missing: 25\n",
      "🔍 Attempt 1 for inf_diario_fi_201811.zip: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201811.zip: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201811.zip: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201811.csv: 403\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201811.csv: 403\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201811.csv: 403\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201811.parquet: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201811.parquet: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201811.parquet: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201811.txt: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201811.txt: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201811.txt: 404\n",
      "⚠️  No valid file for 2018-11 (inf_diario_fi_201811.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-11 after 3 attempts per type. Consecutive missing: 26\n",
      "🔍 Attempt 1 for inf_diario_fi_201810.zip: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201810.zip: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201810.zip: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201810.csv: 403\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201810.csv: 403\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201810.csv: 403\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201810.parquet: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201810.parquet: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201810.parquet: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201810.txt: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201810.txt: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201810.txt: 404\n",
      "⚠️  No valid file for 2018-10 (inf_diario_fi_201810.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-10 after 3 attempts per type. Consecutive missing: 27\n",
      "🔍 Attempt 1 for inf_diario_fi_201809.zip: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201809.zip: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201809.zip: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201809.csv: 403\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201809.csv: 403\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201809.csv: 403\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201809.parquet: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201809.parquet: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201809.parquet: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201809.txt: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201809.txt: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201809.txt: 404\n",
      "⚠️  No valid file for 2018-09 (inf_diario_fi_201809.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-09 after 3 attempts per type. Consecutive missing: 28\n",
      "🔍 Attempt 1 for inf_diario_fi_201808.zip: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201808.zip: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201808.zip: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201808.csv: 403\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201808.csv: 403\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201808.csv: 403\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201808.parquet: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201808.parquet: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201808.parquet: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201808.txt: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201808.txt: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201808.txt: 404\n",
      "⚠️  No valid file for 2018-08 (inf_diario_fi_201808.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-08 after 3 attempts per type. Consecutive missing: 29\n",
      "🔍 Attempt 1 for inf_diario_fi_201807.zip: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201807.zip: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201807.zip: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201807.csv: 403\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201807.csv: 403\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201807.csv: 403\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201807.parquet: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201807.parquet: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201807.parquet: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201807.txt: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201807.txt: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201807.txt: 404\n",
      "⚠️  No valid file for 2018-07 (inf_diario_fi_201807.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-07 after 3 attempts per type. Consecutive missing: 30\n",
      "🔍 Attempt 1 for inf_diario_fi_201806.zip: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201806.zip: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201806.zip: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201806.csv: 403\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201806.csv: 403\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201806.csv: 403\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201806.parquet: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201806.parquet: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201806.parquet: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201806.txt: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201806.txt: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201806.txt: 404\n",
      "⚠️  No valid file for 2018-06 (inf_diario_fi_201806.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-06 after 3 attempts per type. Consecutive missing: 31\n",
      "🔍 Attempt 1 for inf_diario_fi_201805.zip: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201805.zip: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201805.zip: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201805.csv: 403\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201805.csv: 403\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201805.csv: 403\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201805.parquet: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201805.parquet: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201805.parquet: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201805.txt: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201805.txt: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201805.txt: 404\n",
      "⚠️  No valid file for 2018-05 (inf_diario_fi_201805.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-05 after 3 attempts per type. Consecutive missing: 32\n",
      "🔍 Attempt 1 for inf_diario_fi_201804.zip: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201804.zip: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201804.zip: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201804.csv: 403\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201804.csv: 403\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201804.csv: 403\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201804.parquet: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201804.parquet: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201804.parquet: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201804.txt: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201804.txt: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201804.txt: 404\n",
      "⚠️  No valid file for 2018-04 (inf_diario_fi_201804.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-04 after 3 attempts per type. Consecutive missing: 33\n",
      "🔍 Attempt 1 for inf_diario_fi_201803.zip: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201803.zip: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201803.zip: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201803.csv: 403\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201803.csv: 403\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201803.csv: 403\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201803.parquet: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201803.parquet: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201803.parquet: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201803.txt: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201803.txt: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201803.txt: 404\n",
      "⚠️  No valid file for 2018-03 (inf_diario_fi_201803.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-03 after 3 attempts per type. Consecutive missing: 34\n",
      "🔍 Attempt 1 for inf_diario_fi_201802.zip: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201802.zip: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201802.zip: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201802.csv: 403\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201802.csv: 403\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201802.csv: 403\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201802.parquet: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201802.parquet: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201802.parquet: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201802.txt: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201802.txt: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201802.txt: 404\n",
      "⚠️  No valid file for 2018-02 (inf_diario_fi_201802.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-02 after 3 attempts per type. Consecutive missing: 35\n",
      "🔍 Attempt 1 for inf_diario_fi_201801.zip: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201801.zip: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201801.zip: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201801.csv: 403\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201801.csv: 403\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201801.csv: 403\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201801.parquet: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201801.parquet: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201801.parquet: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201801.txt: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201801.txt: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201801.txt: 404\n",
      "⚠️  No valid file for 2018-01 (inf_diario_fi_201801.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2018-01 after 3 attempts per type. Consecutive missing: 36\n",
      "🔍 Attempt 1 for inf_diario_fi_201712.zip: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201712.zip: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201712.zip: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201712.csv: 403\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201712.csv: 403\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201712.csv: 403\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201712.parquet: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201712.parquet: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201712.parquet: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201712.txt: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201712.txt: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201712.txt: 404\n",
      "⚠️  No valid file for 2017-12 (inf_diario_fi_201712.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-12 after 3 attempts per type. Consecutive missing: 37\n",
      "🔍 Attempt 1 for inf_diario_fi_201711.zip: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201711.zip: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201711.zip: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201711.csv: 403\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201711.csv: 403\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201711.csv: 403\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201711.parquet: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201711.parquet: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201711.parquet: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201711.txt: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201711.txt: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201711.txt: 404\n",
      "⚠️  No valid file for 2017-11 (inf_diario_fi_201711.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-11 after 3 attempts per type. Consecutive missing: 38\n",
      "🔍 Attempt 1 for inf_diario_fi_201710.zip: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201710.zip: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201710.zip: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201710.csv: 403\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201710.csv: 403\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201710.csv: 403\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201710.parquet: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201710.parquet: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201710.parquet: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201710.txt: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201710.txt: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201710.txt: 404\n",
      "⚠️  No valid file for 2017-10 (inf_diario_fi_201710.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-10 after 3 attempts per type. Consecutive missing: 39\n",
      "🔍 Attempt 1 for inf_diario_fi_201709.zip: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201709.zip: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201709.zip: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201709.csv: 403\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201709.csv: 403\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201709.csv: 403\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201709.parquet: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201709.parquet: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201709.parquet: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201709.txt: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201709.txt: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201709.txt: 404\n",
      "⚠️  No valid file for 2017-09 (inf_diario_fi_201709.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-09 after 3 attempts per type. Consecutive missing: 40\n",
      "🔍 Attempt 1 for inf_diario_fi_201708.zip: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201708.zip: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201708.zip: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201708.csv: 403\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201708.csv: 403\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201708.csv: 403\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201708.parquet: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201708.parquet: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201708.parquet: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201708.txt: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201708.txt: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201708.txt: 404\n",
      "⚠️  No valid file for 2017-08 (inf_diario_fi_201708.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-08 after 3 attempts per type. Consecutive missing: 41\n",
      "🔍 Attempt 1 for inf_diario_fi_201707.zip: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201707.zip: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201707.zip: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201707.csv: 403\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201707.csv: 403\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201707.csv: 403\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201707.parquet: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201707.parquet: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201707.parquet: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201707.txt: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201707.txt: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201707.txt: 404\n",
      "⚠️  No valid file for 2017-07 (inf_diario_fi_201707.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-07 after 3 attempts per type. Consecutive missing: 42\n",
      "🔍 Attempt 1 for inf_diario_fi_201706.zip: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201706.zip: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201706.zip: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201706.csv: 403\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201706.csv: 403\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201706.csv: 403\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201706.parquet: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201706.parquet: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201706.parquet: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201706.txt: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201706.txt: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201706.txt: 404\n",
      "⚠️  No valid file for 2017-06 (inf_diario_fi_201706.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-06 after 3 attempts per type. Consecutive missing: 43\n",
      "🔍 Attempt 1 for inf_diario_fi_201705.zip: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201705.zip: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201705.zip: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201705.csv: 403\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201705.csv: 403\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201705.csv: 403\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201705.parquet: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201705.parquet: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201705.parquet: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201705.txt: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201705.txt: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201705.txt: 404\n",
      "⚠️  No valid file for 2017-05 (inf_diario_fi_201705.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-05 after 3 attempts per type. Consecutive missing: 44\n",
      "🔍 Attempt 1 for inf_diario_fi_201704.zip: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201704.zip: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201704.zip: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201704.csv: 403\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201704.csv: 403\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201704.csv: 403\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201704.parquet: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201704.parquet: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201704.parquet: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201704.txt: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201704.txt: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201704.txt: 404\n",
      "⚠️  No valid file for 2017-04 (inf_diario_fi_201704.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-04 after 3 attempts per type. Consecutive missing: 45\n",
      "🔍 Attempt 1 for inf_diario_fi_201703.zip: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201703.zip: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201703.zip: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201703.csv: 403\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201703.csv: 403\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201703.csv: 403\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201703.parquet: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201703.parquet: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201703.parquet: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201703.txt: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201703.txt: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201703.txt: 404\n",
      "⚠️  No valid file for 2017-03 (inf_diario_fi_201703.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-03 after 3 attempts per type. Consecutive missing: 46\n",
      "🔍 Attempt 1 for inf_diario_fi_201702.zip: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201702.zip: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201702.zip: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201702.csv: 403\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201702.csv: 403\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201702.csv: 403\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201702.parquet: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201702.parquet: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201702.parquet: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201702.txt: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201702.txt: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201702.txt: 404\n",
      "⚠️  No valid file for 2017-02 (inf_diario_fi_201702.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-02 after 3 attempts per type. Consecutive missing: 47\n",
      "🔍 Attempt 1 for inf_diario_fi_201701.zip: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201701.zip: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201701.zip: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201701.csv: 403\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201701.csv: 403\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201701.csv: 403\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201701.parquet: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201701.parquet: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201701.parquet: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201701.txt: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201701.txt: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201701.txt: 404\n",
      "⚠️  No valid file for 2017-01 (inf_diario_fi_201701.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2017-01 after 3 attempts per type. Consecutive missing: 48\n",
      "🔍 Attempt 1 for inf_diario_fi_201612.zip: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201612.zip: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201612.zip: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201612.csv: 403\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201612.csv: 403\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201612.csv: 403\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201612.parquet: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201612.parquet: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201612.parquet: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201612.txt: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201612.txt: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201612.txt: 404\n",
      "⚠️  No valid file for 2016-12 (inf_diario_fi_201612.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2016-12 after 3 attempts per type. Consecutive missing: 49\n",
      "🔍 Attempt 1 for inf_diario_fi_201611.zip: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.zip) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201611.zip: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.zip) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201611.zip: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.zip) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201611.csv: 403\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.csv) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201611.csv: 403\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.csv) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201611.csv: 403\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.csv) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201611.parquet: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.parquet) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201611.parquet: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.parquet) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201611.parquet: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.parquet) (attempt 3).\n",
      "🔍 Attempt 1 for inf_diario_fi_201611.txt: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.txt) (attempt 1).\n",
      "🔍 Attempt 2 for inf_diario_fi_201611.txt: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.txt) (attempt 2).\n",
      "🔍 Attempt 3 for inf_diario_fi_201611.txt: 404\n",
      "⚠️  No valid file for 2016-11 (inf_diario_fi_201611.txt) (attempt 3).\n",
      "❌ Failed to fetch any file for 2016-11 after 3 attempts per type. Consecutive missing: 50\n",
      "🛑 Giving up after 50 consecutive missing datasets.\n"
     ]
    }
   ],
   "source": [
    "import tempfile\n",
    "import zipfile\n",
    "from collections import Counter\n",
    "from datetime import datetime  #noqa\n",
    "from difflib import get_close_matches\n",
    "from functools import reduce\n",
    "from pathlib import Path\n",
    "\n",
    "import requests\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def fetch_all_cvm_months(start_year=2015, start_month=1):\n",
    "    \"\"\"\n",
    "    Fetch all CVM FI daily reports going back month by month until no data is found.\n",
    "    Returns a list of Spark DataFrames (one per month), going backward in time.\n",
    "    Retries up to 3 times for up to 4 consecutive missing datasets before giving up.\n",
    "    Logs all rows with null CNPJ to a file.\n",
    "    Accepts any file type: zip, csv, parquet, etc.\n",
    "    \"\"\"\n",
    "    dfs = []\n",
    "    today = datetime.today()\n",
    "    year = today.year\n",
    "    month = today.month\n",
    "    null_log_path = Path(\"null_cnpj_log.txt\")\n",
    "    log_file = open(null_log_path, \"a\", encoding=\"utf-8\")\n",
    "\n",
    "    consecutive_missing = 0\n",
    "    max_consecutive_missing = 50\n",
    "\n",
    "    file_types = [\n",
    "        (\".zip\", \"zip\"),\n",
    "        (\".csv\", \"csv\"),\n",
    "        (\".parquet\", \"parquet\"),\n",
    "        (\".txt\", \"csv\"),  # Sometimes txt is used for CSVs\n",
    "    ]\n",
    "\n",
    "    link_historico=  \"https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/HIST/\"\n",
    "\n",
    "    while (year > start_year) or (year == start_year and month >= start_month):\n",
    "        cvm_base_url = \"https://dados.cvm.gov.br/dados/FI/DOC/INF_DIARIO/DADOS/\"\n",
    "        file_found = False\n",
    "        for ext, fmt in file_types:\n",
    "            cvm_file_name = f\"inf_diario_fi_{year}{str(month).zfill(2)}{ext}\"\n",
    "            cvm_url = f\"{cvm_base_url}{cvm_file_name}\"\n",
    "            for attempt in range(1, 4):  # up to 3 attempts\n",
    "                try:\n",
    "                    response = requests.get(cvm_url)\n",
    "                    print(f\"🔍 Attempt {attempt} for {cvm_file_name}: {response.status_code}\")\n",
    "                    if response.status_code != requests.codes.ok:\n",
    "                        print(f\"⚠️  No valid file for {year}-{month:02d} ({cvm_file_name}) (attempt {attempt}).\")\n",
    "                        continue\n",
    "\n",
    "                    # Save to temp file\n",
    "                    with tempfile.NamedTemporaryFile(delete=False, suffix=ext) as tmp:\n",
    "                        tmp.write(response.content)\n",
    "                        tmp_path = tmp.name\n",
    "\n",
    "                    # Read file according to type\n",
    "                    if fmt == \"zip\":\n",
    "                        if not response.content.startswith(b'PK'):\n",
    "                            print(f\"⚠️  Not a valid zip file for {cvm_file_name}.\")\n",
    "                            os.unlink(tmp_path)\n",
    "                            continue\n",
    "                        with zipfile.ZipFile(tmp_path, 'r') as zip_ref:\n",
    "                            csv_name = [n for n in zip_ref.namelist() if n.lower().endswith('.csv') or n.lower().endswith('.txt')]\n",
    "                            if not csv_name:\n",
    "                                print(f\"⚠️  No CSV/TXT found in zip for {cvm_file_name}.\")\n",
    "                                os.unlink(tmp_path)\n",
    "                                continue\n",
    "                            csv_name = csv_name[0]\n",
    "                            zip_ref.extract(csv_name, os.path.dirname(tmp_path))\n",
    "                            file_to_read = os.path.join(os.path.dirname(tmp_path), csv_name)\n",
    "                        read_fmt = \"csv\"\n",
    "                        cleanup_files = [tmp_path, file_to_read]\n",
    "                    elif fmt == \"csv\":\n",
    "                        file_to_read = tmp_path\n",
    "                        read_fmt = \"csv\"\n",
    "                        cleanup_files = [tmp_path]\n",
    "                        csv_name = cvm_file_name\n",
    "                    elif fmt == \"parquet\":\n",
    "                        file_to_read = tmp_path\n",
    "                        read_fmt = \"parquet\"\n",
    "                        cleanup_files = [tmp_path]\n",
    "                        csv_name = cvm_file_name\n",
    "                    else:\n",
    "                        os.unlink(tmp_path)\n",
    "                        continue\n",
    "\n",
    "                    # Read with Spark\n",
    "                    if read_fmt == \"csv\":\n",
    "                        df = spark.read.csv(\n",
    "                            file_to_read,\n",
    "                            header=True,\n",
    "                            sep=\";\",\n",
    "                            inferSchema=True,\n",
    "                            encoding=\"ISO-8859-1\"\n",
    "                        )\n",
    "                    elif read_fmt == \"parquet\":\n",
    "                        df = spark.read.parquet(file_to_read)\n",
    "                    else:\n",
    "                        print(f\"⚠️  Unknown file format for {cvm_file_name}.\")\n",
    "                        for f in cleanup_files:\n",
    "                            os.unlink(f)\n",
    "                        continue\n",
    "\n",
    "                    row_count = df.count()\n",
    "                    if row_count == 0:\n",
    "                        print(f\"⚠️  No data found for {year}-{month:02d}.\")\n",
    "                        for f in cleanup_files:\n",
    "                            os.unlink(f)\n",
    "                        continue\n",
    "                    df.cache()\n",
    "                    cnpj_col = None\n",
    "                    for col in df.columns:\n",
    "                        if \"cnpj\" in col.lower():\n",
    "                            cnpj_col = col\n",
    "                            print(f\"🔍 Found CNPJ column: {cnpj_col}\")\n",
    "                            break\n",
    "                    if cnpj_col:\n",
    "                        null_cnpj_rows = df.filter(F.col(cnpj_col).isNull())\n",
    "                        null_count = null_cnpj_rows.count()\n",
    "                        print(f\"🔍 Found {null_count} null CNPJ rows in {csv_name}.\")\n",
    "                        if null_count > 0:\n",
    "                            print(f\"⚠️  {null_count} rows with null {cnpj_col} in {csv_name}. Logging to {null_log_path}\")\n",
    "                            rows = null_cnpj_rows.toPandas().to_dict(orient=\"records\")\n",
    "                            for row in rows:\n",
    "                                log_file.write(f\"{csv_name}: {row}\\n\")\n",
    "                    else:\n",
    "                        print(\"⚠️  No CNPJ column found for null check.\")\n",
    "                    dfs.append(df)\n",
    "                    print(f\"✅ Loaded {csv_name} ({year}-{month:02d}) with {row_count} rows\")\n",
    "                    for f in cleanup_files:\n",
    "                        os.unlink(f)\n",
    "                    file_found = True\n",
    "                    break  # exit retry loop\n",
    "                except Exception as e:\n",
    "                    print(f\"⚠️  Failed to fetch or load {cvm_url} (attempt {attempt}): {e}\")\n",
    "            if file_found:\n",
    "                break  # found a file for this month, move to next month\n",
    "\n",
    "        if not file_found:\n",
    "            consecutive_missing += 1\n",
    "            print(f\"❌ Failed to fetch any file for {year}-{month:02d} after 3 attempts per type. Consecutive missing: {consecutive_missing}\")\n",
    "            if consecutive_missing >= max_consecutive_missing:\n",
    "                print(f\"🛑 Giving up after {max_consecutive_missing} consecutive missing datasets.\")\n",
    "                break\n",
    "        else:\n",
    "            consecutive_missing = 0  # reset on success\n",
    "\n",
    "        # Move to previous month\n",
    "        if month == 1:\n",
    "            month = 12\n",
    "            year -= 1\n",
    "        else:\n",
    "            month -= 1\n",
    "\n",
    "    log_file.close()\n",
    "    return dfs\n",
    "\n",
    "# Example usage:\n",
    "dfs = fetch_all_cvm_months(start_year=2015, start_month=1)\n",
    "if dfs:\n",
    "    # Fuzzy schema normalization\n",
    "    # Find the most common set of column names\n",
    "    colname_lists = [tuple(sorted(df.columns)) for df in dfs]\n",
    "    most_common_cols, _ = Counter(colname_lists).most_common(1)[0]\n",
    "    most_common_cols = list(most_common_cols)\n",
    "\n",
    "    def fuzzy_normalize_df(df, target_cols, cutoff=0.8):\n",
    "        col_map = {}\n",
    "        for target in target_cols:\n",
    "            match = get_close_matches(target, df.columns, n=1, cutoff=cutoff)\n",
    "            if match:\n",
    "                col_map[match[0]] = target\n",
    "        # Rename columns that match\n",
    "        for src, tgt in col_map.items():\n",
    "            if src != tgt:\n",
    "                df = df.withColumnRenamed(src, tgt)\n",
    "        # Add missing columns as nulls\n",
    "        for col in target_cols:\n",
    "            if col not in df.columns:\n",
    "                df = df.withColumn(col, F.lit(None))\n",
    "        # Select only target columns in order\n",
    "        df = df.select([col for col in target_cols])\n",
    "        return df\n",
    "\n",
    "    dfs_normalized = [fuzzy_normalize_df(df, most_common_cols) for df in dfs]\n",
    "    cvm_spark_df = reduce(DataFrame.unionByName, reversed(dfs_normalized))\n",
    "else:\n",
    "    print(\"⚠️ No CVM data was fetched. The DataFrame list is empty.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "27d51403",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rows: 26075230\n",
      "Columns: 9\n",
      "Schema: [('CAPTC_DIA', 'double'), ('CNPJ_FUNDO', 'string'), ('DT_COMPTC', 'date'), ('NR_COTST', 'int'), ('RESG_DIA', 'double'), ('TP_FUNDO', 'string'), ('VL_PATRIM_LIQ', 'double'), ('VL_QUOTA', 'double'), ('VL_TOTAL', 'double')]\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "|CAPTC_DIA|CNPJ_FUNDO        |DT_COMPTC |NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA  |VL_TOTAL  |\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "|0.0      |00.017.024/0001-53|2021-01-04|1       |0.0     |FI      |1095773.57   |27.5033358|1097664.87|\n",
      "|0.0      |00.017.024/0001-53|2021-01-05|1       |0.0     |FI      |1095778.31   |27.5034547|1097742.61|\n",
      "|0.0      |00.017.024/0001-53|2021-01-06|1       |0.0     |FI      |1095768.02   |27.5031964|1097837.04|\n",
      "|0.0      |00.017.024/0001-53|2021-01-07|1       |0.0     |FI      |1095774.2    |27.5033516|1097939.54|\n",
      "|0.0      |00.017.024/0001-53|2021-01-08|1       |0.0     |FI      |1095788.49   |27.5037102|1096790.38|\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    f\"Rows: {cvm_spark_df.count()}\",\n",
    "    f\"Columns: {len(cvm_spark_df.columns)}\",\n",
    "    f\"Schema: {cvm_spark_df.dtypes}\",\n",
    "    sep=\"\\n\"\n",
    ")\n",
    "cvm_spark_df.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c39c3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./airflow\n",
      "✅ Bucket 'lakehouse' já existe.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "from botocore.exceptions import ClientError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# Configurações do MinIO\n",
    "MINIO_ENDPOINT = \"http://localhost:9000\"\n",
    "ACCESS_KEY = os.getenv(\"MINIO_USER\")\n",
    "SECRET_KEY = os.getenv(\"MINIO_PASSWORD\")\n",
    "print(os.getenv(\"AIRFLOW_PROJ_DIR\"))\n",
    "BUCKET_NAME = \"lakehouse\"\n",
    "\n",
    "# Conectar ao MinIO (S3-compatible)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")\n",
    "\n",
    "# Checar e criar bucket\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"✅ Bucket '{BUCKET_NAME}' já existe.\")\n",
    "except ClientError as e:\n",
    "    error_code = int(e.response[\"Error\"][\"Code\"])\n",
    "    if error_code == requests.codes.not_found:\n",
    "        print(f\"🔧 Criando bucket '{BUCKET_NAME}'...\")\n",
    "        s3.create_bucket(Bucket=BUCKET_NAME)\n",
    "        print(\"✅ Bucket criado com sucesso.\")\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "a1e749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Salvar como Delta (Bronze) no MinIO\n",
    "df_bacen_spark = spark.createDataFrame(df_bacen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "4633468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bacen_spark.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/bronze/bacen_selic/\")\n",
    "cvm_spark_df.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/bronze/cvm_if_di/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "f9b61619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. Transformações da camada Silver\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver_bacen = (\n",
    "    df_bacen_spark\n",
    "    .withColumn(\"ano\", F.year(\"data\"))\n",
    "    .withColumn(\"mes\", F.month(\"data\"))\n",
    "    .withColumn(\"dia\", F.dayofmonth(\"data\"))\n",
    ")\n",
    "\n",
    "silver_cvm = (\n",
    "    cvm_spark_df.withColumn(\"cap_liquida_dia\", F.col(\"CAPTC_DIA\") - F.col(\"RESG_DIA\"))\n",
    "        .withColumn(\"ano\", F.year(\"DT_COMPTC\"))\n",
    "        .withColumn(\"mes\", F.month(\"DT_COMPTC\"))\n",
    "        .withColumn(\"dia\", F.dayofmonth(\"DT_COMPTC\"))\n",
    "        .filter(F.col(\"VL_QUOTA\") > 0)\n",
    "        .filter(F.col(\"VL_PATRIM_LIQ\") > 0)\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "silver_bacen.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/silver/bacen_selic/\")\n",
    "silver_cvm.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/silver/cvm_if_di/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "ccbce57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "|CAPTC_DIA|CNPJ_FUNDO        |DT_COMPTC |NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA  |VL_TOTAL  |cap_liquida_dia|ano |mes|dia|\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "|0.0      |00.017.024/0001-53|2021-01-04|1       |0.0     |FI      |1095773.57   |27.5033358|1097664.87|0.0            |2021|1  |4  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-05|1       |0.0     |FI      |1095778.31   |27.5034547|1097742.61|0.0            |2021|1  |5  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-06|1       |0.0     |FI      |1095768.02   |27.5031964|1097837.04|0.0            |2021|1  |6  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-07|1       |0.0     |FI      |1095774.2    |27.5033516|1097939.54|0.0            |2021|1  |7  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-08|1       |0.0     |FI      |1095788.49   |27.5037102|1096790.38|0.0            |2021|1  |8  |\n",
      "|0.0      |00.017.024/0001-53|2021-01-11|1       |4079.29 |FI      |1091741.25   |27.5045147|1092815.44|-4079.29       |2021|1  |11 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-12|1       |0.0     |FI      |1091757.17   |27.5049157|1092924.8 |0.0            |2021|1  |12 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-13|1       |0.0     |FI      |1091778.39   |27.5054503|1093008.2 |0.0            |2021|1  |13 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-14|1       |0.0     |FI      |1091773.65   |27.5053309|1093080.65|0.0            |2021|1  |14 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-15|1       |0.0     |FI      |1091757.92   |27.5049346|1093180.0 |0.0            |2021|1  |15 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-18|1       |0.0     |FI      |1091768.13   |27.5051919|1093267.95|0.0            |2021|1  |18 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-19|1       |0.0     |FI      |1091767.4    |27.5051735|1093376.59|0.0            |2021|1  |19 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-20|1       |0.0     |FI      |1091787.4    |27.5056773|1092837.03|0.0            |2021|1  |20 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-21|1       |0.0     |FI      |1091776.0    |27.5053901|1092916.89|0.0            |2021|1  |21 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-22|1       |0.0     |FI      |1091767.17   |27.5051677|1093005.15|0.0            |2021|1  |22 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-25|1       |0.0     |FI      |1091765.14   |27.5051165|1093055.58|0.0            |2021|1  |25 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-26|1       |0.0     |FI      |1091761.38   |27.5050218|1093137.6 |0.0            |2021|1  |26 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-27|1       |0.0     |FI      |1091754.18   |27.5048404|1093192.16|0.0            |2021|1  |27 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-28|1       |0.0     |FI      |1091720.58   |27.5039939|1093286.91|0.0            |2021|1  |28 |\n",
      "|0.0      |00.017.024/0001-53|2021-01-29|1       |0.0     |FI      |1091731.51   |27.5042693|1093386.42|0.0            |2021|1  |29 |\n",
      "+---------+------------------+----------+--------+--------+--------+-------------+----------+----------+---------------+----+---+---+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "silver_cvm.show(20, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "599537b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nulls in CNPJ_FUNDO: 0 of 9137937 (0.00%)\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "|CAPTC_DIA|CNPJ_FUNDO|DT_COMPTC|NR_COTST|RESG_DIA|TP_FUNDO|VL_PATRIM_LIQ|VL_QUOTA|VL_TOTAL|cap_liquida_dia|ano|mes|dia|\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "+---------+----------+---------+--------+--------+--------+-------------+--------+--------+---------------+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Count nulls in CNPJ_FUNDO\n",
    "null_count = silver_cvm.filter(F.col(\"CNPJ_FUNDO\").isNull()).count()\n",
    "total_count = silver_cvm.count()\n",
    "print(f\"Nulls in CNPJ_FUNDO: {null_count} of {total_count} ({null_count/total_count:.2%})\")\n",
    "\n",
    "# Show some rows with null CNPJ_FUNDO\n",
    "silver_cvm.filter(\n",
    "    (F.col(\"CNPJ_FUNDO\").isNull()) & (F.col(\"NR_COTST\") > 1)\n",
    ").show(30, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2cd8546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean expectation suite created and saved (no validation run, no validator used).\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "if \"silver_bacen_selic\" in [asset.name for asset in spark_ds.assets]:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "\n",
    "# Overwrite the expectation suite with only valid expectations (NO validation run)\n",
    "suite_name = \"silver_bacen_selic_suite\"\n",
    "if suite_name in [suite.expectation_suite_name for suite in context.list_expectation_suites()]:\n",
    "    context.delete_expectation_suite(suite_name)\n",
    "suite = context.add_expectation_suite(suite_name)\n",
    "\n",
    "# Add expectations directly to the suite (no validator, no data access)\n",
    "suite.expectations = [\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"data\", \"type_\": \"TimestampType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"valor\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"valor\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_row_count_to_be_between\",\n",
    "        kwargs={\"min_value\": 1}\n",
    "    ),\n",
    "]\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "print(\"✅ Clean expectation suite created and saved (no validation run, no validator used).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f6ee1a2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Clean expectation suite for silver_cvm created and saved (no validation run, no validator used).\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "if \"silver_cvm_if_di\" in [asset.name for asset in spark_ds.assets]:\n",
    "    spark_ds.delete_asset(\"silver_cvm_if_di\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_cvm_if_di\", dataframe=silver_cvm)\n",
    "\n",
    "# Overwrite the expectation suite with only valid expectations (NO validation run)\n",
    "suite_name = \"silver_cvm_if_di_suite\"\n",
    "if suite_name in [suite.expectation_suite_name for suite in context.list_expectation_suites()]:\n",
    "    context.delete_expectation_suite(suite_name)\n",
    "suite = context.add_expectation_suite(suite_name)\n",
    "\n",
    "# Add expectations directly to the suite (no validator, no data access)\n",
    "suite.expectations = [\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"CNPJ_FUNDO\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"cap_liquida_dia\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"CNPJ_FUNDO\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"DT_COMPTC\", \"type_\": \"DateType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"VL_QUOTA\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"VL_PATRIM_LIQ\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_row_count_to_be_between\",\n",
    "        kwargs={\"min_value\": 1}\n",
    "    ),\n",
    "]\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "print(\"✅ Clean expectation suite for silver_cvm created and saved (no validation run, no validator used).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b878b463",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e09cf90acf09454ca0cbbe5b5f383c3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7607711f344b5797a95e107a6743f2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/40 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Validation Success (bacen & cvm): False\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# Ensure Spark datasource exists\n",
    "if \"spark_datasource\" not in context.datasources:\n",
    "    context.sources.add_spark(name=\"spark_datasource\")\n",
    "\n",
    "# (Re-)register the assets with the current DataFrames\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "asset_names = [asset.name for asset in spark_ds.assets]\n",
    "if \"silver_bacen_selic\" in asset_names:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "if \"silver_cvm_if_di\" in asset_names:\n",
    "    spark_ds.delete_asset(\"silver_cvm_if_di\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "spark_ds.add_dataframe_asset(name=\"silver_cvm_if_di\", dataframe=silver_cvm)\n",
    "\n",
    "# Ensure expectation suites exist\n",
    "suite_names = [suite.expectation_suite_name for suite in context.list_expectation_suites()]\n",
    "if \"silver_bacen_selic_suite\" not in suite_names:\n",
    "    context.add_expectation_suite(\"silver_bacen_selic_suite\")\n",
    "if \"silver_cvm_if_di_suite\" not in suite_names:\n",
    "    context.add_expectation_suite(\"silver_cvm_if_di_suite\")\n",
    "\n",
    "# Build batch requests\n",
    "batch_request_bacen = {\n",
    "    \"datasource_name\": \"spark_datasource\",\n",
    "    \"data_asset_name\": \"silver_bacen_selic\",\n",
    "}\n",
    "batch_request_cvm = {\n",
    "    \"datasource_name\": \"spark_datasource\",\n",
    "    \"data_asset_name\": \"silver_cvm_if_di\",\n",
    "}\n",
    "\n",
    "# Run the checkpoint for both assets\n",
    "checkpoint = SimpleCheckpoint(\n",
    "    name=\"silver_combined_checkpoint\",\n",
    "    data_context=context,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request_bacen,\n",
    "            \"expectation_suite_name\": \"silver_bacen_selic_suite\",\n",
    "        },\n",
    "        {\n",
    "            \"batch_request\": batch_request_cvm,\n",
    "            \"expectation_suite_name\": \"silver_cvm_if_di_suite\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = checkpoint.run()\n",
    "print(\"✅ Validation Success (bacen & cvm):\", result[\"success\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "6a6075ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "❌ Failed: expect_column_values_to_not_be_null on column CNPJ_FUNDO\n",
      "    Details: {'element_count': 25957177, 'unexpected_count': 9020632, 'unexpected_percent': 34.75197630312418, 'partial_unexpected_list': [None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None, None], 'partial_unexpected_counts': [{'value': None, 'count': 20}]}\n"
     ]
    }
   ],
   "source": [
    "for run_result in result[\"run_results\"].values():\n",
    "    validation_result = run_result[\"validation_result\"]\n",
    "    for res in validation_result[\"results\"]:\n",
    "        if not res[\"success\"]:\n",
    "            print(f\"❌ Failed: {res['expectation_config']['expectation_type']} on column {res['expectation_config']['kwargs'].get('column')}\")\n",
    "            print(f\"    Details: {res['result']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "690ddce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+---+-----+------------------+\n",
      "|inicio             |fim                |min|max  |media             |\n",
      "+-------------------+-------------------+---+-----+------------------+\n",
      "|1986-06-04 00:00:00|2025-04-30 00:00:00|0.0|3.626|0.2555755175348646|\n",
      "+-------------------+-------------------+---+-----+------------------+\n",
      "\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "|CNPJ_FUNDO        |data_inicio|data_fim  |vl_quota_inicio|vl_quota_fim |cap_liquida_total    |cotistas_inicio|cotistas_fim|rentabilidade_pct |crescimento_cotistas|\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "|00.360.293/0001-18|2021-01-04 |2023-11-30|30.501901      |27.87017     |-1.8322185264E8      |12826          |2984        |-8.628088459142264|-9842               |\n",
      "|00.068.305/0001-35|2021-01-04 |2023-11-30|27.454385      |35.051298    |-1.6706400189999998E7|7238           |6026        |27.671036885364597|-1212               |\n",
      "|00.071.477/0001-68|2021-01-04 |2023-11-30|10.027742319   |12.522327042 |-3.761534833925E10   |322135         |47017       |24.876833125970965|-275118             |\n",
      "|00.185.259/0001-54|2021-01-04 |2023-11-30|51.55522661    |52.44688596  |-1.219685915E8       |196            |116         |1.7295227053216997|-80                 |\n",
      "|00.017.024/0001-53|2021-01-04 |2023-11-30|27.5033358     |34.0298254   |-193928.61000000002  |1              |1           |23.72981098532783 |0                   |\n",
      "|00.398.561/0001-90|2021-01-04 |2023-11-30|215.8460996    |204.0592828  |-1.0643308632999995E8|4737           |1408        |-5.460750424419528|-3329               |\n",
      "|00.180.995/0001-10|2021-01-04 |2023-11-30|564.770071     |715.168816   |-2.2481302401E8      |2726           |861         |26.630084121437086|-1865               |\n",
      "|00.812.433/0001-41|2021-01-04 |2023-11-30|9.16067        |11.281341    |1.7495191955299997E9 |43588          |71900       |23.149736864224995|28312               |\n",
      "|00.222.725/0001-24|2021-01-04 |2023-11-30|3750.6983937   |4739.9885894 |-5.682295641E7       |1517           |973         |26.376159633675105|-544                |\n",
      "|00.829.163/0001-81|2021-01-04 |2023-11-30|3119.44435     |3840.13484   |-2774212.91          |62             |46          |23.103168678101273|-16                 |\n",
      "|00.524.617/0001-06|2021-01-04 |2023-11-30|12.930825      |12.955702    |-1.2868287760000001E8|5333           |1474        |0.1923852499743832|-3859               |\n",
      "|00.832.445/0001-38|2021-01-04 |2023-11-30|1595.660717    |2069.560427  |-9.099587628E7       |921            |779         |29.69927785719876 |-142                |\n",
      "|00.194.256/0001-87|2021-01-04 |2023-11-30|48.516457869   |62.434695284 |-1.1704974145599992E9|40             |34          |28.687661932329927|-6                  |\n",
      "|00.840.008/0001-66|2021-01-04 |2023-11-30|32.349645      |40.86054     |-4.204447083E7       |1380           |944         |26.309083144498175|-436                |\n",
      "|00.777.815/0001-81|2021-01-04 |2023-11-30|30.5243251     |39.7048878   |-1.3822833036999997E8|6264           |3611        |30.076218458307547|-2653               |\n",
      "|00.842.960/0001-07|2021-01-04 |2023-11-30|28.4334466     |36.7782816   |-2.5210217929999996E7|406            |268         |29.34865799913261 |-138                |\n",
      "|00.073.041/0001-08|2021-01-04 |2023-11-30|28.7917845     |36.9377487   |-9265966.05          |946            |791         |28.29266869512726 |-155                |\n",
      "|00.849.567/0001-37|2021-01-04 |2023-11-30|71382.0023243  |99361.2477996|-6.2766587819999985E7|3              |3           |39.19649850698464 |0                   |\n",
      "|00.822.055/0001-87|2021-01-04 |2023-11-30|37.511935511   |52.610391587 |1.5242389647599998E10|1              |1           |40.249738837316286|0                   |\n",
      "|00.852.311/0001-89|2021-01-04 |2023-11-30|20.325622515   |26.964626872 |-6.032100621369999E9 |36             |67          |32.66322766793744 |31                  |\n",
      "+------------------+-----------+----------+---------------+-------------+---------------------+---------------+------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import functions as F\n",
    "\n",
    "\n",
    "def run_gold_pipeline():\n",
    "\n",
    "    # Load silver datasets\n",
    "    # silver_cvm = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/cvm/\")\n",
    "    silver_bacen = spark.read.format(\"delta\").load(\"s3a://lakehouse/silver/bacen_selic/\")\n",
    "\n",
    "    # KPIs CVM Fundos\n",
    "    gold_cvm = (\n",
    "        silver_cvm.groupBy(\"CNPJ_FUNDO\")\n",
    "        .agg(\n",
    "            F.min(\"DT_COMPTC\").alias(\"data_inicio\"),\n",
    "            F.max(\"DT_COMPTC\").alias(\"data_fim\"),\n",
    "            F.first(\"VL_QUOTA\", ignorenulls=True).alias(\"vl_quota_inicio\"),\n",
    "            F.last(\"VL_QUOTA\", ignorenulls=True).alias(\"vl_quota_fim\"),\n",
    "            F.sum(\"cap_liquida_dia\").alias(\"cap_liquida_total\"),\n",
    "            F.first(\"NR_COTST\", ignorenulls=True).alias(\"cotistas_inicio\"),\n",
    "            F.last(\"NR_COTST\", ignorenulls=True).alias(\"cotistas_fim\")\n",
    "        )\n",
    "        .withColumn(\"rentabilidade_pct\", ((F.col(\"vl_quota_fim\") - F.col(\"vl_quota_inicio\")) / F.col(\"vl_quota_inicio\")) * 100)\n",
    "        .withColumn(\"crescimento_cotistas\", F.col(\"cotistas_fim\") - F.col(\"cotistas_inicio\"))\n",
    "    )\n",
    "\n",
    "    # KPIs BACEN indicadores\n",
    "    gold_bacen = (\n",
    "        silver_bacen.agg(\n",
    "            F.min(\"data\").alias(\"inicio\"),\n",
    "            F.max(\"data\").alias(\"fim\"),\n",
    "            F.min(\"valor\").alias(\"min\"),\n",
    "            F.max(\"valor\").alias(\"max\"),\n",
    "            F.mean(\"valor\").alias(\"media\")\n",
    "        )\n",
    "    )\n",
    "\n",
    "\n",
    "    gold_bacen.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/gold/bacen_kpis/\")\n",
    "    gold_cvm.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/gold/cvm_kpis/\")\n",
    "    return gold_bacen, gold_cvm\n",
    "gold_bacen, gold_cvm = run_gold_pipeline()\n",
    "gold_bacen.show(20,truncate=False)\n",
    "gold_cvm.orderBy(\"data_inicio\", ascending=True).show(20,truncate=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
