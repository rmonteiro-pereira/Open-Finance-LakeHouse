{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0f1128ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"PYSPARK_PYTHON\"] = sys.executable\n",
    "os.environ[\"PYSPARK_DRIVER_PYTHON\"] = sys.executable\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "get_spark_session.cache_clear()\n",
    "spark = get_spark_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "647e768b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>data</th>\n",
       "      <th>valor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-05-04</td>\n",
       "      <td>0.049037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2015-05-05</td>\n",
       "      <td>0.049037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2015-05-06</td>\n",
       "      <td>0.049037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2015-05-07</td>\n",
       "      <td>0.049037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2015-05-08</td>\n",
       "      <td>0.049037</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        data     valor\n",
       "0 2015-05-04  0.049037\n",
       "1 2015-05-05  0.049037\n",
       "2 2015-05-06  0.049037\n",
       "3 2015-05-07  0.049037\n",
       "4 2015-05-08  0.049037"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2. IngestÃ£o BACEN API\n",
    "import io\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import requests\n",
    "\n",
    "from open_finance_lakehouse.utils.spark_session import get_spark_session\n",
    "\n",
    "# --- Parameters ---\n",
    "bacen_series_id = 11  # Example: SELIC\n",
    "bacen_start_date = (datetime.today().replace(year=datetime.today().year - 10)).strftime(\"%d/%m/%Y\")\n",
    "bacen_end_date = datetime.today().strftime(\"%d/%m/%Y\")\n",
    "cvm_year = 2024\n",
    "cvm_month = 4\n",
    "\n",
    "\n",
    "bacen_url = (\n",
    "    f\"https://api.bcb.gov.br/dados/serie/bcdata.sgs.{bacen_series_id}/dados\"\n",
    "    f\"?formato=json&dataInicial={bacen_start_date}&dataFinal={bacen_end_date}\"\n",
    ")\n",
    "\n",
    "response = requests.get(bacen_url)\n",
    "\n",
    "df_bacen = pd.read_json(io.StringIO(response.text))\n",
    "df_bacen.columns = [\"data\", \"valor\"]\n",
    "df_bacen[\"data\"] = pd.to_datetime(df_bacen[\"data\"], format=\"%d/%m/%Y\")\n",
    "df_bacen[\"valor\"] = pd.to_numeric(df_bacen[\"valor\"], errors=\"coerce\")\n",
    "df_bacen.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c39c3879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/airflow\n",
      "âœ… Bucket 'lakehouse' jÃ¡ existe.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import boto3\n",
    "import requests\n",
    "from botocore.exceptions import ClientError\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "# ConfiguraÃ§Ãµes do MinIO\n",
    "MINIO_ENDPOINT = \"http://localhost:9000\"\n",
    "ACCESS_KEY = os.getenv(\"MINIO_USER\")\n",
    "SECRET_KEY = os.getenv(\"MINIO_PASSWORD\")\n",
    "print(os.getenv(\"AIRFLOW_PROJ_DIR\"))\n",
    "BUCKET_NAME = \"lakehouse\"\n",
    "\n",
    "# Conectar ao MinIO (S3-compatible)\n",
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=MINIO_ENDPOINT,\n",
    "    aws_access_key_id=ACCESS_KEY,\n",
    "    aws_secret_access_key=SECRET_KEY,\n",
    ")\n",
    "\n",
    "# Checar e criar bucket\n",
    "try:\n",
    "    s3.head_bucket(Bucket=BUCKET_NAME)\n",
    "    print(f\"âœ… Bucket '{BUCKET_NAME}' jÃ¡ existe.\")\n",
    "except ClientError as e:\n",
    "    error_code = int(e.response[\"Error\"][\"Code\"])\n",
    "    if error_code == requests.codes.not_found:\n",
    "        print(f\"ðŸ”§ Criando bucket '{BUCKET_NAME}'...\")\n",
    "        s3.create_bucket(Bucket=BUCKET_NAME)\n",
    "        print(\"âœ… Bucket criado com sucesso.\")\n",
    "    else:\n",
    "        raise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb6b2b46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "winutils.exe: C:\\Users\\Rodrigo\\.spark\\hadoop\\bin\\winutils.exe\n",
      "hadoop.dll: C:\\Users\\Rodrigo\\.spark\\hadoop\\bin\\hadoop.dll\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "\n",
    "def find_in_path(filename):\n",
    "    for path in os.environ[\"PATH\"].split(os.pathsep):\n",
    "        full_path = os.path.join(path, filename)\n",
    "        if os.path.isfile(full_path):\n",
    "            return full_path\n",
    "    return None\n",
    "\n",
    "print(\"winutils.exe:\", find_in_path(\"winutils.exe\"))\n",
    "print(\"hadoop.dll:\", find_in_path(\"hadoop.dll\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a1e749ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. Salvar como Delta (Bronze) no MinIO\n",
    "df_bacen_spark = spark.createDataFrame(df_bacen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4633468e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bacen_spark.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/bronze/bacen_selic/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f9b61619",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4. TransformaÃ§Ãµes da camada Silver\n",
    "from pyspark.sql import functions as F\n",
    "\n",
    "silver_bacen = (\n",
    "    df_bacen_spark\n",
    "    .withColumn(\"ano\", F.year(\"data\"))\n",
    "    .withColumn(\"mes\", F.month(\"data\"))\n",
    "    .withColumn(\"dia\", F.dayofmonth(\"data\"))\n",
    ")\n",
    "\n",
    "silver_bacen.write.format(\"delta\").mode(\"overwrite\").save(\"s3a://lakehouse/silver/bacen_selic/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2cd8546a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Clean expectation suite created and saved (no validation run, no validator used).\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.core.expectation_configuration import ExpectationConfiguration\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "if \"silver_bacen_selic\" in [asset.name for asset in spark_ds.assets]:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "\n",
    "# Overwrite the expectation suite with only valid expectations (NO validation run)\n",
    "suite_name = \"silver_bacen_selic_suite\"\n",
    "if suite_name in [suite.expectation_suite_name for suite in context.list_expectation_suites()]:\n",
    "    context.delete_expectation_suite(suite_name)\n",
    "suite = context.add_expectation_suite(suite_name)\n",
    "\n",
    "# Add expectations directly to the suite (no validator, no data access)\n",
    "suite.expectations = [\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_to_exist\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"data\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_not_be_null\",\n",
    "        kwargs={\"column\": \"valor\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"data\", \"type_\": \"TimestampType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_of_type\",\n",
    "        kwargs={\"column\": \"valor\", \"type_\": \"DoubleType\"}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_column_values_to_be_between\",\n",
    "        kwargs={\"column\": \"valor\", \"min_value\": 0}\n",
    "    ),\n",
    "    ExpectationConfiguration(\n",
    "        expectation_type=\"expect_table_row_count_to_be_between\",\n",
    "        kwargs={\"min_value\": 1}\n",
    "    ),\n",
    "]\n",
    "\n",
    "context.save_expectation_suite(suite)\n",
    "print(\"âœ… Clean expectation suite created and saved (no validation run, no validator used).\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "24c128f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b927a9ef4bf5476baf915773a0225af2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Calculating Metrics:   0%|          | 0/22 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Validation Success: True\n"
     ]
    }
   ],
   "source": [
    "import great_expectations as gx\n",
    "from great_expectations.checkpoint import SimpleCheckpoint\n",
    "\n",
    "context = gx.data_context.DataContext(\"gx\")\n",
    "\n",
    "# 1. Ensure Spark datasource exists\n",
    "if \"spark_datasource\" not in context.datasources:\n",
    "    context.sources.add_spark(name=\"spark_datasource\")\n",
    "\n",
    "# 2. (Re-)register the asset with the current DataFrame\n",
    "spark_ds = context.get_datasource(\"spark_datasource\")\n",
    "asset_names = [asset.name for asset in spark_ds.assets]\n",
    "if \"silver_bacen_selic\" in asset_names:\n",
    "    spark_ds.delete_asset(\"silver_bacen_selic\")\n",
    "spark_ds.add_dataframe_asset(name=\"silver_bacen_selic\", dataframe=df_bacen_spark)\n",
    "\n",
    "# 3. Ensure expectation suite exists\n",
    "suite_names = [suite.expectation_suite_name for suite in context.list_expectation_suites()]\n",
    "if \"silver_bacen_selic_suite\" not in suite_names:\n",
    "    context.add_expectation_suite(\"silver_bacen_selic_suite\")\n",
    "\n",
    "# 4. Build the batch request (Fluent API: just use asset name)\n",
    "batch_request = {\n",
    "    \"datasource_name\": \"spark_datasource\",\n",
    "    \"data_asset_name\": \"silver_bacen_selic\",\n",
    "}\n",
    "\n",
    "# 5. Run the checkpoint\n",
    "checkpoint = SimpleCheckpoint(\n",
    "    name=\"silver_bacen_checkpoint\",\n",
    "    data_context=context,\n",
    "    validations=[\n",
    "        {\n",
    "            \"batch_request\": batch_request,\n",
    "            \"expectation_suite_name\": \"silver_bacen_selic_suite\",\n",
    "        }\n",
    "    ]\n",
    ")\n",
    "\n",
    "result = checkpoint.run()\n",
    "print(\"âœ… Validation Success:\", result[\"success\"])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
