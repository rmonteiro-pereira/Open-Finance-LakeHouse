{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "db43b459",
   "metadata": {},
   "source": [
    "# üè¶ BACEN Economic Data Visualization\n",
    "\n",
    "**Brazilian Central Bank (BACEN) Financial Time Series Analysis**\n",
    "\n",
    "This notebook provides comprehensive visualization and analysis of Brazilian economic indicators from BACEN (Banco Central do Brasil), including:\n",
    "\n",
    "- üìà **Interest Rates**: SELIC rate, CDI, over rate, SELIC target\n",
    "- \udcb0 **Exchange Rates**: USD/BRL, EUR/BRL \n",
    "- \udcca **Inflation Indices**: IPCA, INPC, IGP-M, IGP-DI, IGP-10\n",
    "- üèõÔ∏è **Economic Indicators**: Government debt/GDP ratio, international reserves, GDP forecasts\n",
    "- üìã **Financial Instruments**: TLP (Long-term Rate)\n",
    "\n",
    "**Data Sources**: \n",
    "- Local raw data: 4 BACEN series\n",
    "- MinIO data lake: 13 additional BACEN series\n",
    "- **Total**: 17 economic time series with historical data from 1944 to 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c4c64ae",
   "metadata": {},
   "source": [
    "## üîß Environment Setup\n",
    "\n",
    "Initialize the Python environment with all necessary libraries and establish connections to both local data files and the MinIO data lake infrastructure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b631de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# üåü LAKEHOUSE DATA VISUALIZATION ENVIRONMENT SETUP\n",
    "# Este c√≥digo configura o ambiente Python necess√°rio para an√°lise de dados do lakehouse brasileiro\n",
    "\n",
    "# Importa√ß√£o de bibliotecas essenciais\n",
    "import os  # Para acessar vari√°veis de ambiente do sistema operacional\n",
    "import pandas as pd  # Para manipula√ß√£o e an√°lise de dados estruturados\n",
    "import io  # Para opera√ß√µes de entrada/sa√≠da, especialmente com streams de bytes\n",
    "import warnings  # Para controlar exibi√ß√£o de avisos/warnings\n",
    "warnings.filterwarnings('ignore')  # Suprime warnings para sa√≠da mais limpa\n",
    "\n",
    "# Carregamento de vari√°veis de ambiente de arquivo .env\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Carrega configura√ß√µes do arquivo .env para as vari√°veis de ambiente\n",
    "\n",
    "# Configura√ß√£o do cliente MinIO para acesso ao data lake\n",
    "from minio import Minio  # Cliente Python para MinIO (storage S3-compat√≠vel)\n",
    "\n",
    "# Dicion√°rio de configura√ß√£o do MinIO usando vari√°veis de ambiente com fallbacks\n",
    "MINIO_CONFIG = {\n",
    "    \"endpoint\": os.getenv(\"MINIO_ENDPOINT\", \"localhost:9000\"),  # Endere√ßo do servidor MinIO\n",
    "    \"access_key\": os.getenv(\"MINIO_USER\", \"minioadmin\"),        # Chave de acesso (usu√°rio)\n",
    "    \"secret_key\": os.getenv(\"MINIO_PASSWORD\", \"minioadmin\"),    # Chave secreta (senha)\n",
    "    \"bucket_name\": os.getenv(\"MINIO_BUCKET\", \"lakehouse\")       # Nome do bucket onde est√£o os dados\n",
    "}\n",
    "\n",
    "# Sanitiza√ß√£o do endpoint para garantir formato correto\n",
    "import re\n",
    "endpoint = MINIO_CONFIG[\"endpoint\"]\n",
    "# Remove protocolo (http:// ou https://) se presente\n",
    "endpoint = re.sub(r\"^https?://\", \"\", endpoint)  \n",
    "# Remove qualquer caminho ap√≥s o dom√≠nio/IP\n",
    "endpoint = endpoint.split(\"/\")[0]  \n",
    "\n",
    "# Inicializa√ß√£o do cliente MinIO com configura√ß√µes sanitizadas\n",
    "minio_client = Minio(\n",
    "    endpoint,  # Endpoint limpo (apenas host:porta)\n",
    "    access_key=MINIO_CONFIG[\"access_key\"],  # Credenciais de acesso\n",
    "    secret_key=MINIO_CONFIG[\"secret_key\"],  # Credenciais secretas\n",
    "    secure=MINIO_CONFIG[\"endpoint\"].startswith(\"https\")  # SSL se endpoint usar HTTPS\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Ambiente configurado com sucesso!\")\n",
    "print(f\"üîó MinIO Endpoint: {endpoint}\")\n",
    "print(f\"üì¶ Bucket: {MINIO_CONFIG['bucket_name']}\")\n",
    "print(\"üöÄ Pronto para descoberta e an√°lise de dados do lakehouse!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07fc5fb2",
   "metadata": {},
   "source": [
    "# üè¶ Brazilian Financial Market Data Visualization\n",
    "\n",
    "This notebook provides comprehensive visualization and analysis of Brazilian financial and economic data from multiple sources:\n",
    "\n",
    "## üìä **Data Sources:**\n",
    "\n",
    "### üèõÔ∏è **BACEN (Central Bank) Economic Indicators:**\n",
    "- SELIC rate, CDI, exchange rates (USD/BRL, EUR/BRL)\n",
    "- Inflation indices (IPCA, INPC, IGP-M, IGP-DI, IGP-10)\n",
    "- Government debt/GDP ratio, international reserves, GDP forecasts\n",
    "\n",
    "### üìà **B3 (Stock Exchange) Market Data:**\n",
    "- Stock market indices and financial instruments\n",
    "- Trading volumes and market indicators\n",
    "\n",
    "### üåç **Yahoo Finance International Data:**\n",
    "- Brazilian ETFs (BOVA11, SMAL11, SPXI11, etc.)\n",
    "- Commodities (Oil, Coffee, Soybeans, Gold)\n",
    "- Currency pairs and international indices\n",
    "\n",
    "### üìã **IBGE & IPEA Economic Statistics:**\n",
    "- Consumer price indices\n",
    "- Government revenue and fiscal data\n",
    "\n",
    "Let's start by exploring what data is available across all these sources."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b032dce4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üöÄ STARTING COMPREHENSIVE PARQUET/DELTA FORMAT DATA DISCOVERY...\n",
      "üí∞ DISCOVERING ALL PARQUET/DELTA FORMAT DATA SOURCES\n",
      "=================================================================\n",
      "üîç Reading from data lake layers...\n",
      "üèõÔ∏è COMPREHENSIVE BACEN DATA DISCOVERY:\n",
      "=============================================\n",
      "\n",
      "ü•â READING BACEN BRONZE LAYER DATA:\n",
      "----------------------------------------\n",
      "üìÅ Found 18 BACEN bronze layer files\n",
      "üìà Reading bronze/bacen_cdi/part-00000-f707704a-3bce-4ca5-b133-6bc7e1fbae72-c000.snappy.parquet...\n",
      "üìÅ Found 18 BACEN bronze layer files\n",
      "üìà Reading bronze/bacen_cdi/part-00000-f707704a-3bce-4ca5-b133-6bc7e1fbae72-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy: 9,848 records\n",
      "üìà Reading bronze/bacen_eur_brl/part-00000-89297f99-39ac-4233-b1dd-ea2551bd04ab-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy: 6,662 records\n",
      "üìà Reading bronze/bacen_igp_10/part-00000-69f59842-ba26-4197-bd10-11ed23d5e659-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy: 9,848 records\n",
      "üìà Reading bronze/bacen_eur_brl/part-00000-89297f99-39ac-4233-b1dd-ea2551bd04ab-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy: 6,662 records\n",
      "üìà Reading bronze/bacen_igp_10/part-00000-69f59842-ba26-4197-bd10-11ed23d5e659-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy: 373 records\n",
      "üìà Reading bronze/bacen_igp_di/part-00000-88bca5ea-3187-4930-b7df-1394799d29d9-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy: 436 records\n",
      "üìà Reading bronze/bacen_igp_m/part-00000-f635231b-b320-4801-b7d1-50a2c46d1370-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy: 985 records\n",
      "üìà Reading bronze/bacen_inpc/part-00000-df681ed7-552b-4a40-bd06-3b5d67a1605e-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy: 373 records\n",
      "üìà Reading bronze/bacen_igp_di/part-00000-88bca5ea-3187-4930-b7df-1394799d29d9-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy: 436 records\n",
      "üìà Reading bronze/bacen_igp_m/part-00000-f635231b-b320-4801-b7d1-50a2c46d1370-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy: 985 records\n",
      "üìà Reading bronze/bacen_inpc/part-00000-df681ed7-552b-4a40-bd06-3b5d67a1605e-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy: 559 records\n",
      "üìà Reading bronze/bacen_ipca/part-00000-4f565512-b3a8-443c-b79f-4fdd2429e510-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy: 550 records\n",
      "üìà Reading bronze/bacen_ipca/part-00000-fe20e3f6-c178-4bc6-8066-0d92e30928d6-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy: 550 records\n",
      "üìà Reading bronze/bacen_ipca_15/part-00000-43fd73c2-4d03-462f-99de-06a1908dbba5-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy: 559 records\n",
      "üìà Reading bronze/bacen_ipca/part-00000-4f565512-b3a8-443c-b79f-4fdd2429e510-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy: 550 records\n",
      "üìà Reading bronze/bacen_ipca/part-00000-fe20e3f6-c178-4bc6-8066-0d92e30928d6-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy: 550 records\n",
      "üìà Reading bronze/bacen_ipca_15/part-00000-43fd73c2-4d03-462f-99de-06a1908dbba5-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy: 303 records\n",
      "üìà Reading bronze/bacen_over/part-00000-a848f716-2ebf-49e2-9daf-89a92a99e968-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy: 9,807 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-953105a6-fa85-4b2e-90e8-31e2f628c50d-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy: 303 records\n",
      "üìà Reading bronze/bacen_over/part-00000-a848f716-2ebf-49e2-9daf-89a92a99e968-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy: 9,807 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-953105a6-fa85-4b2e-90e8-31e2f628c50d-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-af830f2f-cbf2-4822-bfe0-4217477d64d3-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-df9b8d4f-4086-4a2a-883f-3430602d6370-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-af830f2f-cbf2-4822-bfe0-4217477d64d3-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-df9b8d4f-4086-4a2a-883f-3430602d6370-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy: 9,807 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-e70619e3-c38d-49cf-8b30-044ad19485f1-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic_meta/part-00000-087fbc5c-82af-48ad-babc-a614bbb8aeb2-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy: 9,807 records\n",
      "üìà Reading bronze/bacen_selic/part-00000-e70619e3-c38d-49cf-8b30-044ad19485f1-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy: 9,806 records\n",
      "üìà Reading bronze/bacen_selic_meta/part-00000-087fbc5c-82af-48ad-babc-a614bbb8aeb2-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy: 9,633 records\n",
      "üìà Reading bronze/bacen_tlp/part-00000-b9c9f40e-b7a1-4198-8279-c7b053ed8448-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy: 46 records\n",
      "üìà Reading bronze/bacen_usd_brl/part-00000-e3777257-fcb3-4f2c-82f1-3ed7a803655c-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy: 9,633 records\n",
      "üìà Reading bronze/bacen_tlp/part-00000-b9c9f40e-b7a1-4198-8279-c7b053ed8448-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy: 46 records\n",
      "üìà Reading bronze/bacen_usd_brl/part-00000-e3777257-fcb3-4f2c-82f1-3ed7a803655c-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy: 10,182 records\n",
      "üìà Reading bronze/bacen_usd_brl/part-00000-fd14e1a9-98ca-4627-b93d-1a76b370edc4-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy: 10,182 records\n",
      "üìà Reading bronze/bacen_usd_brl/part-00000-fd14e1a9-98ca-4627-b93d-1a76b370edc4-c000.snappy.parquet...\n",
      "   ‚úÖ Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy: 10,182 records\n",
      "\n",
      "üìä BACEN DATA SUMMARY:\n",
      "-------------------------\n",
      "‚úÖ BACEN_BRONZE_Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy: 9,848 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_cdi/part-00000-f707704a-3bce-4ca5-b133-6bc7e1fbae72-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy: 6,662 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_eur_brl/part-00000-89297f99-39ac-4233-b1dd-ea2551bd04ab-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy: 373 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_10/part-00000-69f59842-ba26-4197-bd10-11ed23d5e659-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy: 436 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_di/part-00000-88bca5ea-3187-4930-b7df-1394799d29d9-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy: 985 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_m/part-00000-f635231b-b320-4801-b7d1-50a2c46d1370-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy: 559 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_inpc/part-00000-df681ed7-552b-4a40-bd06-3b5d67a1605e-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy: 550 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca/part-00000-4f565512-b3a8-443c-b79f-4fdd2429e510-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy: 550 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca/part-00000-fe20e3f6-c178-4bc6-8066-0d92e30928d6-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy: 303 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca_15/part-00000-43fd73c2-4d03-462f-99de-06a1908dbba5-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy: 9,807 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_over/part-00000-a848f716-2ebf-49e2-9daf-89a92a99e968-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-953105a6-fa85-4b2e-90e8-31e2f628c50d-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-af830f2f-cbf2-4822-bfe0-4217477d64d3-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy: 9,807 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-df9b8d4f-4086-4a2a-883f-3430602d6370-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-e70619e3-c38d-49cf-8b30-044ad19485f1-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy: 9,633 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic_meta/part-00000-087fbc5c-82af-48ad-babc-a614bbb8aeb2-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy: 46 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_tlp/part-00000-b9c9f40e-b7a1-4198-8279-c7b053ed8448-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy: 10,182 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_usd_brl/part-00000-e3777257-fcb3-4f2c-82f1-3ed7a803655c-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy: 10,182 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_usd_brl/part-00000-fd14e1a9-98ca-4627-b93d-1a76b370edc4-c000.snappy.parquet\n",
      "\n",
      "ü•à READING SILVER LAYER PARQUET DATA:\n",
      "----------------------------------------\n",
      "üìÅ Found 115 silver layer parquet files\n",
      "üìà Reading IMA_B series (20 files)...\n",
      "   ‚úÖ Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy: 10,182 records\n",
      "\n",
      "üìä BACEN DATA SUMMARY:\n",
      "-------------------------\n",
      "‚úÖ BACEN_BRONZE_Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy: 9,848 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_cdi/part-00000-f707704a-3bce-4ca5-b133-6bc7e1fbae72-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy: 6,662 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_eur_brl/part-00000-89297f99-39ac-4233-b1dd-ea2551bd04ab-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy: 373 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_10/part-00000-69f59842-ba26-4197-bd10-11ed23d5e659-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy: 436 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_di/part-00000-88bca5ea-3187-4930-b7df-1394799d29d9-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy: 985 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_igp_m/part-00000-f635231b-b320-4801-b7d1-50a2c46d1370-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy: 559 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_inpc/part-00000-df681ed7-552b-4a40-bd06-3b5d67a1605e-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy: 550 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca/part-00000-4f565512-b3a8-443c-b79f-4fdd2429e510-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy: 550 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca/part-00000-fe20e3f6-c178-4bc6-8066-0d92e30928d6-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy: 303 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_ipca_15/part-00000-43fd73c2-4d03-462f-99de-06a1908dbba5-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy: 9,807 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_over/part-00000-a848f716-2ebf-49e2-9daf-89a92a99e968-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-953105a6-fa85-4b2e-90e8-31e2f628c50d-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-af830f2f-cbf2-4822-bfe0-4217477d64d3-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy: 9,807 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-df9b8d4f-4086-4a2a-883f-3430602d6370-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy: 9,806 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic/part-00000-e70619e3-c38d-49cf-8b30-044ad19485f1-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy: 9,633 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_selic_meta/part-00000-087fbc5c-82af-48ad-babc-a614bbb8aeb2-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy: 46 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_tlp/part-00000-b9c9f40e-b7a1-4198-8279-c7b053ed8448-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy: 10,182 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_usd_brl/part-00000-e3777257-fcb3-4f2c-82f1-3ed7a803655c-c000.snappy.parquet\n",
      "‚úÖ BACEN_BRONZE_Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy: 10,182 records (BACEN Bronze)\n",
      "   üìÅ File: bronze/bacen_usd_brl/part-00000-fd14e1a9-98ca-4627-b93d-1a76b370edc4-c000.snappy.parquet\n",
      "\n",
      "ü•à READING SILVER LAYER PARQUET DATA:\n",
      "----------------------------------------\n",
      "üìÅ Found 115 silver layer parquet files\n",
      "üìà Reading IMA_B series (20 files)...\n",
      "   ‚úÖ IMA_B: 20 records\n",
      "üìà Reading IMA_B_5 series (20 files)...\n",
      "   ‚úÖ IMA_B: 20 records\n",
      "üìà Reading IMA_B_5 series (20 files)...\n",
      "   ‚úÖ IMA_B_5: 20 records\n",
      "\n",
      "ü•á READING GOLD LAYER PARQUET DATA:\n",
      "--------------------------------------\n",
      "üìÅ Found 58 gold layer parquet files\n",
      "üìà Reading gold/cdi_kpis/part-00000-8bafb8d7-0943-4f97-8717-b7171049d197-c000.snappy.parquet...\n",
      "   ‚úÖ Cdi Kpis: 473 records\n",
      "üìà Reading gold/divida_pib/part-00000-41f770b4-88e0-47d8-8a7e-a0f06f40956e-c000.snappy.parquet...\n",
      "   ‚úÖ IMA_B_5: 20 records\n",
      "\n",
      "ü•á READING GOLD LAYER PARQUET DATA:\n",
      "--------------------------------------\n",
      "üìÅ Found 58 gold layer parquet files\n",
      "üìà Reading gold/cdi_kpis/part-00000-8bafb8d7-0943-4f97-8717-b7171049d197-c000.snappy.parquet...\n",
      "   ‚úÖ Cdi Kpis: 473 records\n",
      "üìà Reading gold/divida_pib/part-00000-41f770b4-88e0-47d8-8a7e-a0f06f40956e-c000.snappy.parquet...\n",
      "   ‚úÖ Divida Pib: 282 records\n",
      "üìà Reading gold/divida_pib/part-00000-89beb9c5-8f62-40d8-a196-8bd5af207b83-c000.snappy.parquet...\n",
      "   ‚úÖ Divida Pib: 282 records\n",
      "üìà Reading gold/eur_brl_kpis/part-00000-d726f7d4-1cee-4e9d-8395-453efb4f1bd2-c000.snappy.parquet...\n",
      "   ‚úÖ Eur Brl Kpis: 320 records\n",
      "üìà Reading gold/focus_pib/part-00000-1ab7f4dc-70f4-4dab-86b8-8237751c0770-c000.snappy.parquet...\n",
      "   ‚úÖ Divida Pib: 282 records\n",
      "üìà Reading gold/divida_pib/part-00000-89beb9c5-8f62-40d8-a196-8bd5af207b83-c000.snappy.parquet...\n",
      "   ‚úÖ Divida Pib: 282 records\n",
      "üìà Reading gold/eur_brl_kpis/part-00000-d726f7d4-1cee-4e9d-8395-453efb4f1bd2-c000.snappy.parquet...\n",
      "   ‚úÖ Eur Brl Kpis: 320 records\n",
      "üìà Reading gold/focus_pib/part-00000-1ab7f4dc-70f4-4dab-86b8-8237751c0770-c000.snappy.parquet...\n",
      "   ‚úÖ Focus Pib: 473 records\n",
      "üìà Reading gold/focus_pib/part-00000-92f5589a-89b7-4175-84ce-d386363f434b-c000.snappy.parquet...\n",
      "   ‚úÖ Focus Pib: 473 records\n",
      "üìà Reading gold/igp_10_kpis/part-00000-d195673e-0cc8-4c0c-95a2-11c6cafe07d6-c000.snappy.parquet...\n",
      "   ‚úÖ Igp 10 Kpis: 370 records\n",
      "üìà Reading gold/igp_di_kpis/part-00000-0dc5b527-679d-468d-8a89-98f8275f8b97-c000.snappy.parquet...\n",
      "   ‚úÖ Focus Pib: 473 records\n",
      "üìà Reading gold/focus_pib/part-00000-92f5589a-89b7-4175-84ce-d386363f434b-c000.snappy.parquet...\n",
      "   ‚úÖ Focus Pib: 473 records\n",
      "üìà Reading gold/igp_10_kpis/part-00000-d195673e-0cc8-4c0c-95a2-11c6cafe07d6-c000.snappy.parquet...\n",
      "   ‚úÖ Igp 10 Kpis: 370 records\n",
      "üìà Reading gold/igp_di_kpis/part-00000-0dc5b527-679d-468d-8a89-98f8275f8b97-c000.snappy.parquet...\n",
      "   ‚úÖ Igp Di Kpis: 432 records\n",
      "üìà Reading gold/igp_m_kpis/part-00000-bec4e06b-985d-409e-b75b-bbc78ae358e8-c000.snappy.parquet...\n",
      "   ‚úÖ Igp M Kpis: 976 records\n",
      "üìà Reading gold/inpc_kpis/part-00000-0669c47d-66d6-4a92-934a-50cd03cffddd-c000.snappy.parquet...\n",
      "   ‚úÖ Inpc Kpis: 554 records\n",
      "üìà Reading gold/ipca_15_kpis/part-00000-eaaffd9b-2203-4d6c-8021-4518f449bbbe-c000.snappy.parquet...\n",
      "   ‚úÖ Igp Di Kpis: 432 records\n",
      "üìà Reading gold/igp_m_kpis/part-00000-bec4e06b-985d-409e-b75b-bbc78ae358e8-c000.snappy.parquet...\n",
      "   ‚úÖ Igp M Kpis: 976 records\n",
      "üìà Reading gold/inpc_kpis/part-00000-0669c47d-66d6-4a92-934a-50cd03cffddd-c000.snappy.parquet...\n",
      "   ‚úÖ Inpc Kpis: 554 records\n",
      "üìà Reading gold/ipca_15_kpis/part-00000-eaaffd9b-2203-4d6c-8021-4518f449bbbe-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca 15 Kpis: 301 records\n",
      "üìà Reading gold/ipca_kpis/part-00000-124abc5b-1595-43cb-8e14-6055e971f30b-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca Kpis: 545 records\n",
      "üìà Reading gold/ipca_kpis/part-00000-80a0b315-b803-429a-b9b9-e563a7653a16-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca Kpis: 545 records\n",
      "üìà Reading gold/over_kpis/part-00000-62af86fa-b000-494c-b193-e2e82f0e8caf-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca 15 Kpis: 301 records\n",
      "üìà Reading gold/ipca_kpis/part-00000-124abc5b-1595-43cb-8e14-6055e971f30b-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca Kpis: 545 records\n",
      "üìà Reading gold/ipca_kpis/part-00000-80a0b315-b803-429a-b9b9-e563a7653a16-c000.snappy.parquet...\n",
      "   ‚úÖ Ipca Kpis: 545 records\n",
      "üìà Reading gold/over_kpis/part-00000-62af86fa-b000-494c-b193-e2e82f0e8caf-c000.snappy.parquet...\n",
      "   ‚úÖ Over Kpis: 470 records\n",
      "üìà Reading gold/reservas_internacionais/part-00000-8a7a77c4-8df5-42b2-b4ab-e1bc4befc074-c000.snappy.parquet...\n",
      "   ‚úÖ Reservas Internacionais: 68 records\n",
      "üìà Reading gold/reservas_internacionais/part-00000-b6fc79b2-75bd-4395-8f0e-687e4f81d5f9-c000.snappy.parquet...\n",
      "   ‚úÖ Reservas Internacionais: 68 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000010.checkpoint.parquet...\n",
      "   ‚úÖ Over Kpis: 470 records\n",
      "üìà Reading gold/reservas_internacionais/part-00000-8a7a77c4-8df5-42b2-b4ab-e1bc4befc074-c000.snappy.parquet...\n",
      "   ‚úÖ Reservas Internacionais: 68 records\n",
      "üìà Reading gold/reservas_internacionais/part-00000-b6fc79b2-75bd-4395-8f0e-687e4f81d5f9-c000.snappy.parquet...\n",
      "   ‚úÖ Reservas Internacionais: 68 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000010.checkpoint.parquet...\n",
      "   ‚úÖ Selic Kpis: 12 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000020.checkpoint.parquet...\n",
      "   ‚úÖ Selic Kpis: 22 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000030.checkpoint.parquet...\n",
      "   ‚úÖ Selic Kpis: 32 records\n",
      "üìà Reading gold/selic_kpis/monthly_selic.parquet...\n",
      "   ‚úÖ Selic Kpis: 12 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000020.checkpoint.parquet...\n",
      "   ‚úÖ Selic Kpis: 22 records\n",
      "üìà Reading gold/selic_kpis/_delta_log/00000000000000000030.checkpoint.parquet...\n",
      "   ‚úÖ Selic Kpis: 32 records\n",
      "üìà Reading gold/selic_kpis/monthly_selic.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-05cd5b2c-1dbc-4bae-b69d-4ddc2588a5e0-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-0815b4fb-aa9a-41b0-8b97-ec3f1450674b-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-0cc378cd-97e5-45fe-961f-bd150098a442-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-05cd5b2c-1dbc-4bae-b69d-4ddc2588a5e0-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-0815b4fb-aa9a-41b0-8b97-ec3f1450674b-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-0cc378cd-97e5-45fe-961f-bd150098a442-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-17e8d3bd-7976-4c0c-9858-e5f3cdda6489-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-1c857476-7ed5-41db-8815-3e6192daaea4-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-1fc20701-e349-4098-8b09-75c137f78d34-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-17e8d3bd-7976-4c0c-9858-e5f3cdda6489-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-1c857476-7ed5-41db-8815-3e6192daaea4-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-1fc20701-e349-4098-8b09-75c137f78d34-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-2d617c03-6e03-4c25-bd4f-4b2f16e21cd4-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-2fcd238e-9449-47eb-bb42-0b4042047f08-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-31aad762-fb92-4406-9fb2-951ce2a82c2c-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-2d617c03-6e03-4c25-bd4f-4b2f16e21cd4-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-2fcd238e-9449-47eb-bb42-0b4042047f08-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-31aad762-fb92-4406-9fb2-951ce2a82c2c-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-33fef57b-a8be-47ca-9eb2-66f09cf3a149-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-4a3bf731-7305-4ea8-a2c3-9b7b66126948-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-4efd160c-93f9-49e0-b142-c6c8e49e08b5-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-33fef57b-a8be-47ca-9eb2-66f09cf3a149-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-4a3bf731-7305-4ea8-a2c3-9b7b66126948-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-4efd160c-93f9-49e0-b142-c6c8e49e08b5-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-531969ca-efc2-4853-bef0-3f69b9dc9566-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-53c9957b-3a44-4be2-b378-c74d58974e0c-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-55680ff9-f005-4dd2-8f8f-00b7bfd30d84-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-531969ca-efc2-4853-bef0-3f69b9dc9566-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-53c9957b-3a44-4be2-b378-c74d58974e0c-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-55680ff9-f005-4dd2-8f8f-00b7bfd30d84-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-65c53217-9a4a-437a-9364-2780f915fb27-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-7277d7fb-b531-4864-87ec-74cf5428843c-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-74eaa667-3024-469d-af96-da318d2a3ad1-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-65c53217-9a4a-437a-9364-2780f915fb27-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-7277d7fb-b531-4864-87ec-74cf5428843c-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-74eaa667-3024-469d-af96-da318d2a3ad1-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-87188364-f0ed-425e-9902-4226c3c9aa0a-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-91e9fe4c-9067-4b79-a8b6-8af417066e8c-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-93eecd39-fcab-4868-9479-dab01661b530-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-87188364-f0ed-425e-9902-4226c3c9aa0a-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-91e9fe4c-9067-4b79-a8b6-8af417066e8c-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-93eecd39-fcab-4868-9479-dab01661b530-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-955fb4ec-9b10-406f-b4c0-85aac303591b-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-97fb00a6-b41d-4633-9808-9d70b9f99fc0-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-9bde7059-53d2-4fbc-8417-a2af37e69198-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-955fb4ec-9b10-406f-b4c0-85aac303591b-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-97fb00a6-b41d-4633-9808-9d70b9f99fc0-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-9bde7059-53d2-4fbc-8417-a2af37e69198-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-9be3e678-ea8d-4c31-8bc8-584752e7b9ea-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-a5d73b0c-5eb1-40d8-a3d9-545b49e191de-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-b8832a35-f60e-4503-a93b-e895207f5b46-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-9be3e678-ea8d-4c31-8bc8-584752e7b9ea-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-a5d73b0c-5eb1-40d8-a3d9-545b49e191de-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-b8832a35-f60e-4503-a93b-e895207f5b46-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-bdca9453-71d1-4e20-bce0-1e2499ca3d74-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-c2322ed4-b90a-473e-a313-9792b16b5ca9-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-c6c30707-4b1c-4a8b-94b9-76404d3612ef-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-bdca9453-71d1-4e20-bce0-1e2499ca3d74-c000.snappy.parquet...\n",
      "   ‚ö†Ô∏è Selic Kpis: Empty dataframe\n",
      "üìà Reading gold/selic_kpis/part-00000-c2322ed4-b90a-473e-a313-9792b16b5ca9-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-c6c30707-4b1c-4a8b-94b9-76404d3612ef-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-cbdacb3e-a95c-4270-b08d-4b42b1f1fc03-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-d9db01e4-5bf5-4be5-a230-718a914d5d9a-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-de8c54c3-d8a6-4382-acc2-a765f4cc4bdf-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-cbdacb3e-a95c-4270-b08d-4b42b1f1fc03-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-d9db01e4-5bf5-4be5-a230-718a914d5d9a-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-de8c54c3-d8a6-4382-acc2-a765f4cc4bdf-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-e6e76376-4d0d-4f34-9026-29bef475ab57-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_meta_kpis/part-00000-4dc6fc72-4504-4d27-98f1-f01ae1c8ad89-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Meta Kpis: 317 records\n",
      "üìà Reading gold/tlp_kpis/part-00000-89571776-d91f-46b8-8354-d80fe948d53a-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_kpis/part-00000-e6e76376-4d0d-4f34-9026-29bef475ab57-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Kpis: 470 records\n",
      "üìà Reading gold/selic_meta_kpis/part-00000-4dc6fc72-4504-4d27-98f1-f01ae1c8ad89-c000.snappy.parquet...\n",
      "   ‚úÖ Selic Meta Kpis: 317 records\n",
      "üìà Reading gold/tlp_kpis/part-00000-89571776-d91f-46b8-8354-d80fe948d53a-c000.snappy.parquet...\n",
      "   ‚úÖ Tlp Kpis: 45 records\n",
      "üìà Reading gold/usd_brl_kpis/part-00000-6275ed95-e8a7-4720-afab-22a905338dbb-c000.snappy.parquet...\n",
      "   ‚úÖ Usd Brl Kpis: 489 records\n",
      "üìà Reading gold/usd_brl_kpis/part-00000-cb126c60-55bf-4af1-a490-489dcce537ca-c000.snappy.parquet...\n",
      "   ‚úÖ Usd Brl Kpis: 489 records\n",
      "\n",
      "üìä DISCOVERY SUMMARY:\n",
      "=========================\n",
      "üìä BACEN Bronze: 18 datasets\n",
      "üìä Silver Layer: 2 datasets\n",
      "üìä Gold Layer: 16 datasets\n",
      "üìã TOTAL: 36 parquet/delta datasets\n",
      "\n",
      "üìÇ BY CATEGORY:\n",
      "   Economic Indicators: 18 datasets\n",
      "   Processed Financial Data: 2 datasets\n",
      "   Analytics & KPIs: 16 datasets\n",
      "   ‚úÖ Tlp Kpis: 45 records\n",
      "üìà Reading gold/usd_brl_kpis/part-00000-6275ed95-e8a7-4720-afab-22a905338dbb-c000.snappy.parquet...\n",
      "   ‚úÖ Usd Brl Kpis: 489 records\n",
      "üìà Reading gold/usd_brl_kpis/part-00000-cb126c60-55bf-4af1-a490-489dcce537ca-c000.snappy.parquet...\n",
      "   ‚úÖ Usd Brl Kpis: 489 records\n",
      "\n",
      "üìä DISCOVERY SUMMARY:\n",
      "=========================\n",
      "üìä BACEN Bronze: 18 datasets\n",
      "üìä Silver Layer: 2 datasets\n",
      "üìä Gold Layer: 16 datasets\n",
      "üìã TOTAL: 36 parquet/delta datasets\n",
      "\n",
      "üìÇ BY CATEGORY:\n",
      "   Economic Indicators: 18 datasets\n",
      "   Processed Financial Data: 2 datasets\n",
      "   Analytics & KPIs: 16 datasets\n"
     ]
    }
   ],
   "source": [
    "import traceback\n",
    "# üîç DESCOBERTA E CARREGAMENTO DE DADOS EM FORMATO PARQUET/DELTA\n",
    "# Este m√≥dulo cont√©m todas as fun√ß√µes necess√°rias para descobrir, extrair e processar\n",
    "# dados financeiros brasileiros armazenados no data lake em formato Parquet\n",
    "\n",
    "def read_bacen_parquet_data():\n",
    "    \"\"\"\n",
    "    L√™ dados do BACEN (Banco Central) de arquivos parquet no MinIO\n",
    "    \n",
    "    Processo:\n",
    "    1. Lista todos os arquivos parquet na pasta 'raw/' do bucket\n",
    "    2. Filtra apenas arquivos que contenham 'bacen' no nome\n",
    "    3. Carrega cada arquivo parquet em um DataFrame pandas\n",
    "    4. Extrai metadados (nome da s√©rie, n√∫mero de registros, categoria)\n",
    "    5. Retorna dicion√°rio com todos os datasets BACEN encontrados\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üèõÔ∏è READING BACEN PARQUET DATA FROM MINIO:\")\n",
    "    print(\"-\" * 45)\n",
    "    \n",
    "    bacen_sources = {}  # Dicion√°rio para armazenar todos os datasets BACEN\n",
    "    \n",
    "    # Verifica se o cliente MinIO est√° dispon√≠vel\n",
    "    if not minio_client:\n",
    "        print(\"‚ùå MinIO client not available\")\n",
    "        return bacen_sources\n",
    "    \n",
    "    try:\n",
    "        # Lista todos os objetos na pasta 'raw/' recursivamente\n",
    "        objects = list(minio_client.list_objects(MINIO_CONFIG[\"bucket_name\"], prefix=\"raw/\", recursive=True))\n",
    "        # Filtra apenas arquivos parquet do BACEN\n",
    "        bacen_files = [obj for obj in objects if 'bacen' in obj.object_name.lower() and obj.object_name.endswith('.parquet')]\n",
    "        \n",
    "        print(f\"üìÅ Found {len(bacen_files)} BACEN parquet files\")\n",
    "        \n",
    "        # Processa cada arquivo BACEN encontrado\n",
    "        for obj in bacen_files:\n",
    "            try:\n",
    "                print(f\"üìà Reading {obj.object_name}...\")\n",
    "                \n",
    "                # L√™ o arquivo parquet diretamente do MinIO\n",
    "                response = minio_client.get_object(MINIO_CONFIG[\"bucket_name\"], obj.object_name)\n",
    "                df = pd.read_parquet(io.BytesIO(response.data))\n",
    "                \n",
    "                # Extrai nome da s√©rie a partir do caminho do arquivo\n",
    "                series_name = obj.object_name.replace('raw/', '').replace('.parquet', '').replace('_bacen', '').replace('_', ' ').title()\n",
    "                \n",
    "                # Se o DataFrame n√£o est√° vazio, armazena os dados e metadados\n",
    "                if len(df) > 0:\n",
    "                    bacen_sources[f\"BACEN_{series_name}\"] = {\n",
    "                        'source': 'BACEN',                    # Fonte dos dados\n",
    "                        'file': obj.object_name,               # Caminho do arquivo\n",
    "                        'records': len(df),                    # N√∫mero de registros\n",
    "                        'data': df,                            # DataFrame com os dados\n",
    "                        'category': 'Economic Indicators'      # Categoria dos dados\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ {series_name}: {len(df):,} records\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è {series_name}: Empty dataframe\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error reading {obj.object_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing BACEN data: {str(e)}\")\n",
    "    \n",
    "    return bacen_sources\n",
    "\n",
    "def read_bacen_bronze_layer():\n",
    "    \"\"\"\n",
    "    L√™ dados do BACEN da camada Bronze (dados raw processados)\n",
    "    \n",
    "    A camada Bronze cont√©m dados que passaram por limpeza inicial mas mant√™m\n",
    "    a estrutura pr√≥xima aos dados originais. Pode ter particionamento por s√©rie.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nü•â READING BACEN BRONZE LAYER DATA:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    bronze_sources = {}  # Dicion√°rio para datasets da camada Bronze\n",
    "    \n",
    "    if not minio_client:\n",
    "        print(\"‚ùå MinIO client not available\")\n",
    "        return bronze_sources\n",
    "    \n",
    "    try:\n",
    "        # Lista arquivos parquet na camada Bronze\n",
    "        objects = list(minio_client.list_objects(MINIO_CONFIG[\"bucket_name\"], prefix=\"bronze/\", recursive=True))\n",
    "        bacen_bronze_files = [obj for obj in objects if 'bacen' in obj.object_name.lower() and obj.object_name.endswith('.parquet')]\n",
    "        \n",
    "        print(f\"üìÅ Found {len(bacen_bronze_files)} BACEN bronze layer files\")\n",
    "        \n",
    "        for obj in bacen_bronze_files:\n",
    "            try:\n",
    "                print(f\"üìà Reading {obj.object_name}...\")\n",
    "                \n",
    "                # Carrega arquivo parquet do MinIO\n",
    "                response = minio_client.get_object(MINIO_CONFIG[\"bucket_name\"], obj.object_name)\n",
    "                df = pd.read_parquet(io.BytesIO(response.data))\n",
    "                \n",
    "                # Extrai nome da s√©rie - suporta diferentes padr√µes de nomenclatura\n",
    "                if '/series=' in obj.object_name:\n",
    "                    # Formato particionado: bronze/bacen/series=selic/\n",
    "                    series_id = obj.object_name.split('series=')[1].split('/')[0]\n",
    "                    series_name = series_id.replace('_', ' ').title()\n",
    "                else:\n",
    "                    # Formato plano\n",
    "                    series_name = obj.object_name.replace('bronze/', '').replace('.parquet', '').replace('_bacen', '').replace('_', ' ').title()\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    bronze_sources[f\"BACEN_BRONZE_{series_name}\"] = {\n",
    "                        'source': 'BACEN Bronze',\n",
    "                        'file': obj.object_name,\n",
    "                        'records': len(df),\n",
    "                        'data': df,\n",
    "                        'category': 'Economic Indicators'\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ {series_name}: {len(df):,} records\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è {series_name}: Empty dataframe\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error reading {obj.object_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing BACEN bronze layer: {str(e)}\")\n",
    "    \n",
    "    return bronze_sources\n",
    "\n",
    "def read_all_bacen_series():\n",
    "    \"\"\"\n",
    "    Busca abrangente por todas as s√©ries do BACEN em diferentes localiza√ß√µes\n",
    "    \n",
    "    Estrat√©gia de busca em ordem de prioridade:\n",
    "    1. Camada Bronze (dados mais processados)\n",
    "    2. Camada Raw (se Bronze estiver vazia)\n",
    "    3. Busca geral em todo o bucket (fallback)\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üèõÔ∏è COMPREHENSIVE BACEN DATA DISCOVERY:\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    all_bacen = {}  # Dicion√°rio consolidado de todos os dados BACEN\n",
    "    \n",
    "    # 1. Tenta camada Bronze primeiro (mais processada)\n",
    "    bronze_data = read_bacen_bronze_layer()\n",
    "    all_bacen.update(bronze_data)\n",
    "    \n",
    "    # 2. Se Bronze estiver vazia, tenta camada Raw\n",
    "    if not bronze_data:\n",
    "        print(\"\\n‚ö†Ô∏è No Bronze layer data found, checking raw layer...\")\n",
    "        raw_data = read_bacen_parquet_data()\n",
    "        all_bacen.update(raw_data)\n",
    "    \n",
    "    # 3. Busca geral como √∫ltimo recurso\n",
    "    if not all_bacen and minio_client:\n",
    "        print(\"\\nüîç Searching all MinIO objects for BACEN data...\")\n",
    "        try:\n",
    "            # Lista TODOS os objetos no bucket\n",
    "            all_objects = list(minio_client.list_objects(MINIO_CONFIG[\"bucket_name\"], recursive=True))\n",
    "            # Filtra apenas objetos BACEN\n",
    "            bacen_objects = [obj for obj in all_objects if 'bacen' in obj.object_name.lower()]\n",
    "            \n",
    "            print(f\"üìÅ Found {len(bacen_objects)} total BACEN files in MinIO\")\n",
    "            \n",
    "            for obj in bacen_objects:\n",
    "                if obj.object_name.endswith('.parquet'):\n",
    "                    try:\n",
    "                        print(f\"üìà Trying to read {obj.object_name}...\")\n",
    "                        response = minio_client.get_object(MINIO_CONFIG[\"bucket_name\"], obj.object_name)\n",
    "                        df = pd.read_parquet(io.BytesIO(response.data))\n",
    "                        \n",
    "                        if len(df) > 0:\n",
    "                            # Cria nome gen√©rico da s√©rie\n",
    "                            series_name = obj.object_name.split('/')[-1].replace('.parquet', '').replace('_bacen', '').replace('_', ' ').title()\n",
    "                            key = f\"BACEN_GENERAL_{series_name}\"\n",
    "                            \n",
    "                            # Evita duplicatas\n",
    "                            if key not in all_bacen:\n",
    "                                all_bacen[key] = {\n",
    "                                    'source': 'BACEN General',\n",
    "                                    'file': obj.object_name,\n",
    "                                    'records': len(df),\n",
    "                                    'data': df,\n",
    "                                    'category': 'Economic Indicators'\n",
    "                                }\n",
    "                                print(f\"   ‚úÖ {series_name}: {len(df):,} records\")\n",
    "                    except Exception as e:\n",
    "                        print(f\"   ‚ö†Ô∏è Could not read {obj.object_name}: {str(e)}\")\n",
    "                        continue\n",
    "                        \n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå Error searching MinIO objects: {str(e)}\")\n",
    "    \n",
    "    # Resumo dos dados BACEN encontrados\n",
    "    print(\"\\nüìä BACEN DATA SUMMARY:\")\n",
    "    print(\"-\" * 25)\n",
    "    \n",
    "    if all_bacen:\n",
    "        for source_key, info in all_bacen.items():\n",
    "            source_type = info['source']\n",
    "            records = info['records']\n",
    "            file_path = info['file']\n",
    "            print(f\"‚úÖ {source_key}: {records:,} records ({source_type})\")\n",
    "            print(f\"   üìÅ File: {file_path}\")\n",
    "    else:\n",
    "        print(\"‚ùå No BACEN data found in any location\")\n",
    "        print(\"üí° Possible issues:\")\n",
    "        print(\"   - Data pipeline hasn't converted JSON to parquet yet\")\n",
    "        print(\"   - BACEN files are in different location/format\")\n",
    "        print(\"   - MinIO permissions or connectivity issues\")\n",
    "    \n",
    "    return all_bacen\n",
    "\n",
    "def read_silver_layer_data():\n",
    "    \"\"\"\n",
    "    L√™ dados processados da camada Silver (formato parquet)\n",
    "    \n",
    "    A camada Silver cont√©m dados limpos, normalizados e prontos para an√°lise.\n",
    "    Os dados s√£o agrupados por s√©rie e podem estar particionados.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nü•à READING SILVER LAYER PARQUET DATA:\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    silver_sources = {}  # Dicion√°rio para datasets da camada Silver\n",
    "    \n",
    "    if not minio_client:\n",
    "        print(\"‚ùå MinIO client not available\")\n",
    "        return silver_sources\n",
    "    \n",
    "    try:\n",
    "        # Lista todos os arquivos parquet da camada Silver\n",
    "        objects = list(minio_client.list_objects(MINIO_CONFIG[\"bucket_name\"], prefix=\"silver/\", recursive=True))\n",
    "        silver_files = [obj for obj in objects if obj.object_name.endswith('.parquet')]\n",
    "        \n",
    "        print(f\"üìÅ Found {len(silver_files)} silver layer parquet files\")\n",
    "        \n",
    "        # Agrupa arquivos por s√©rie (para dados particionados)\n",
    "        series_groups = {}\n",
    "        for obj in silver_files:\n",
    "            if 'series=' in obj.object_name:\n",
    "                try:\n",
    "                    # Extrai nome da s√©rie do caminho particionado\n",
    "                    series_name = obj.object_name.split('series=')[1].split('/')[0]\n",
    "                    if series_name not in series_groups:\n",
    "                        series_groups[series_name] = []\n",
    "                    series_groups[series_name].append(obj.object_name)\n",
    "                except:\n",
    "                    continue\n",
    "        \n",
    "        # Processa cada grupo de s√©rie\n",
    "        for series_name, file_list in series_groups.items():\n",
    "            try:\n",
    "                print(f\"üìà Reading {series_name.upper()} series ({len(file_list)} files)...\")\n",
    "                \n",
    "                # L√™ e combina todos os arquivos da s√©rie\n",
    "                all_dfs = []\n",
    "                for file_path in file_list:\n",
    "                    response = minio_client.get_object(MINIO_CONFIG[\"bucket_name\"], file_path)\n",
    "                    df = pd.read_parquet(io.BytesIO(response.data))\n",
    "                    if len(df) > 0:\n",
    "                        all_dfs.append(df)\n",
    "                \n",
    "                if all_dfs:\n",
    "                    # Combina todos os DataFrames da s√©rie\n",
    "                    combined_df = pd.concat(all_dfs, ignore_index=True)\n",
    "                    \n",
    "                    silver_sources[f\"SILVER_{series_name.upper()}\"] = {\n",
    "                        'source': 'Silver Layer',\n",
    "                        'file': f\"silver/{series_name}/*\",  # Indica m√∫ltiplos arquivos\n",
    "                        'records': len(combined_df),\n",
    "                        'data': combined_df,\n",
    "                        'category': 'Processed Financial Data'\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ {series_name.upper()}: {len(combined_df):,} records\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è {series_name.upper()}: No valid data\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error reading {series_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing silver layer: {str(e)}\")\n",
    "    \n",
    "    return silver_sources\n",
    "\n",
    "def read_gold_layer_data():\n",
    "    \"\"\"\n",
    "    L√™ dados agregados da camada Gold (formato parquet)\n",
    "    \n",
    "    A camada Gold cont√©m dados agregados, KPIs e m√©tricas prontas para\n",
    "    dashboards e relat√≥rios executivos.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nü•á READING GOLD LAYER PARQUET DATA:\")\n",
    "    print(\"-\" * 38)\n",
    "    \n",
    "    gold_sources = {}  # Dicion√°rio para datasets da camada Gold\n",
    "    \n",
    "    if not minio_client:\n",
    "        print(\"‚ùå MinIO client not available\")\n",
    "        return gold_sources\n",
    "    \n",
    "    try:\n",
    "        # Lista arquivos parquet da camada Gold\n",
    "        objects = list(minio_client.list_objects(MINIO_CONFIG[\"bucket_name\"], prefix=\"gold/\", recursive=True))\n",
    "        gold_files = [obj for obj in objects if obj.object_name.endswith('.parquet')]\n",
    "        \n",
    "        print(f\"üìÅ Found {len(gold_files)} gold layer parquet files\")\n",
    "        \n",
    "        for obj in gold_files:\n",
    "            try:\n",
    "                print(f\"üìà Reading {obj.object_name}...\")\n",
    "                \n",
    "                # Carrega arquivo parquet do MinIO\n",
    "                response = minio_client.get_object(MINIO_CONFIG[\"bucket_name\"], obj.object_name)\n",
    "                df = pd.read_parquet(io.BytesIO(response.data))\n",
    "                \n",
    "                # Extrai nome do dataset do caminho\n",
    "                dataset_name = obj.object_name.replace('gold/', '').split('/')[0].replace('_', ' ').title()\n",
    "                \n",
    "                if len(df) > 0:\n",
    "                    gold_sources[f\"GOLD_{dataset_name}\"] = {\n",
    "                        'source': 'Gold Layer',\n",
    "                        'file': obj.object_name,\n",
    "                        'records': len(df),\n",
    "                        'data': df,\n",
    "                        'category': 'Analytics & KPIs'\n",
    "                    }\n",
    "                    \n",
    "                    print(f\"   ‚úÖ {dataset_name}: {len(df):,} records\")\n",
    "                else:\n",
    "                    print(f\"   ‚ö†Ô∏è {dataset_name}: Empty dataframe\")\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"   ‚ùå Error reading {obj.object_name}: {str(e)}\")\n",
    "                \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error accessing gold layer: {str(e)}\")\n",
    "    \n",
    "    return gold_sources\n",
    "\n",
    "def discover_all_parquet_data_sources():\n",
    "    \"\"\"\n",
    "    Fun√ß√£o principal de descoberta de todas as fontes de dados em formato parquet/delta\n",
    "    \n",
    "    Orquestra a descoberta em todas as camadas do lakehouse:\n",
    "    - BACEN (Bronze, Raw, Geral)\n",
    "    - Silver (dados processados)\n",
    "    - Gold (agrega√ß√µes e KPIs)\n",
    "    \n",
    "    Retorna dicion√°rio consolidado com todos os datasets encontrados.\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üí∞ DISCOVERING ALL PARQUET/DELTA FORMAT DATA SOURCES\")\n",
    "    print(\"=\" * 65)\n",
    "    \n",
    "    all_sources = {}  # Dicion√°rio consolidado de todas as fontes\n",
    "    \n",
    "    print(\"üîç Reading from data lake layers...\")\n",
    "    \n",
    "    # 1. Dados BACEN (busca abrangente)\n",
    "    bacen_data = read_all_bacen_series()\n",
    "    all_sources.update(bacen_data)\n",
    "    \n",
    "    # 2. Dados processados da camada Silver\n",
    "    silver_data = read_silver_layer_data()\n",
    "    all_sources.update(silver_data)\n",
    "    \n",
    "    # 3. Dados anal√≠ticos da camada Gold\n",
    "    gold_data = read_gold_layer_data()\n",
    "    all_sources.update(gold_data)\n",
    "    \n",
    "    # Resumo da descoberta\n",
    "    print(\"\\nüìä DISCOVERY SUMMARY:\")\n",
    "    print(\"=\" * 25)\n",
    "    \n",
    "    # Agrupa por fonte\n",
    "    by_source = {}\n",
    "    for key, info in all_sources.items():\n",
    "        source = info['source']\n",
    "        by_source[source] = by_source.get(source, 0) + 1\n",
    "    \n",
    "    for source, count in by_source.items():\n",
    "        print(f\"üìä {source}: {count} datasets\")\n",
    "    \n",
    "    print(f\"üìã TOTAL: {len(all_sources)} parquet/delta datasets\")\n",
    "    \n",
    "    # Agrupa por categoria\n",
    "    by_category = {}\n",
    "    for key, info in all_sources.items():\n",
    "        category = info['category']\n",
    "        by_category[category] = by_category.get(category, 0) + 1\n",
    "    \n",
    "    print(\"\\nüìÇ BY CATEGORY:\")\n",
    "    for category, count in by_category.items():\n",
    "        print(f\"   {category}: {count} datasets\")\n",
    "    \n",
    "    return all_sources\n",
    "\n",
    "def find_column(df, candidates):\n",
    "    \"\"\"\n",
    "    Fun√ß√£o auxiliar para encontrar coluna baseada em lista de candidatos\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame pandas\n",
    "        candidates: Lista de strings para buscar nos nomes das colunas\n",
    "    \n",
    "    Returns:\n",
    "        Nome da primeira coluna encontrada ou None\n",
    "    \"\"\"\n",
    "    for col in df.columns:\n",
    "        if any(x in col.lower() for x in candidates):\n",
    "            return col\n",
    "    return None\n",
    "\n",
    "def clean_time_series_df(df, date_col, value_col):\n",
    "    \"\"\"\n",
    "    Padroniza e limpa um DataFrame de s√©rie temporal\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame original\n",
    "        date_col: Nome da coluna de data\n",
    "        value_col: Nome da coluna de valor\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame limpo e padronizado ou DataFrame vazio se falhar\n",
    "    \"\"\"\n",
    "    # Cria DataFrame padronizado com colunas 'date' e 'value'\n",
    "    df_std = pd.DataFrame({\n",
    "        'date': pd.to_datetime(df[date_col], errors='coerce'),  # Converte para datetime\n",
    "        'value': pd.to_numeric(df[value_col], errors='coerce')  # Converte para num√©rico\n",
    "    }).dropna()  # Remove registros com valores nulos\n",
    "    \n",
    "    if not df_std.empty:\n",
    "        # Ordena por data e remove duplicatas (mant√©m o √∫ltimo)\n",
    "        df_std = df_std.sort_values('date').drop_duplicates(subset=['date'], keep='last')\n",
    "    return df_std\n",
    "\n",
    "def detect_and_clean_timeseries(df):\n",
    "    \"\"\"\n",
    "    Detecta colunas de data/valor automaticamente e limpa o DataFrame\n",
    "    \n",
    "    Esta fun√ß√£o implementa l√≥gica inteligente para identificar:\n",
    "    - Colunas de data: busca por 'date', 'data', 'time', 'dt'\n",
    "    - Colunas de valor: busca por 'value', 'valor', 'close', 'price', 'rate', 'index_value'\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame original\n",
    "    \n",
    "    Returns:\n",
    "        Tupla (df_limpo, nome_coluna_data, nome_coluna_valor)\n",
    "        Se falhar, retorna (None, nome_coluna_data, nome_coluna_valor)\n",
    "    \"\"\"\n",
    "    # Busca coluna de data usando padr√µes comuns\n",
    "    date_col = next((col for col in df.columns if any(x in col.lower() for x in ['date', 'data', 'time', 'dt'])), None)\n",
    "    # Busca coluna de valor usando padr√µes comuns\n",
    "    value_col = next((col for col in df.columns if any(x in col.lower() for x in ['value', 'valor', 'close', 'price', 'rate', 'index_value'])), None)\n",
    "    \n",
    "    # Se n√£o encontrar ambas as colunas, retorna None\n",
    "    if not date_col or not value_col:\n",
    "        return None, date_col, value_col\n",
    "    \n",
    "    # Padroniza e limpa o DataFrame\n",
    "    df_std = pd.DataFrame({\n",
    "        'date': pd.to_datetime(df[date_col], errors='coerce'),\n",
    "        'value': pd.to_numeric(df[value_col], errors='coerce')\n",
    "    }).dropna()\n",
    "    \n",
    "    # Se resultado for vazio, retorna None\n",
    "    if df_std.empty:\n",
    "        return None, date_col, value_col\n",
    "    \n",
    "    # Ordena e remove duplicatas\n",
    "    df_std = df_std.sort_values('date').drop_duplicates(subset=['date'], keep='last')\n",
    "    return df_std, date_col, value_col\n",
    "\n",
    "def add_metadata(df, source_key, source_type, category, date_col, value_col):\n",
    "    \"\"\"\n",
    "    Adiciona metadados ao DataFrame para rastreabilidade\n",
    "    \n",
    "    Args:\n",
    "        df: DataFrame limpo\n",
    "        source_key: Chave identificadora da fonte\n",
    "        source_type: Tipo da fonte (ex: 'BACEN Bronze')\n",
    "        category: Categoria dos dados (ex: 'Economic Indicators')\n",
    "        date_col: Nome original da coluna de data\n",
    "        value_col: Nome original da coluna de valor\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame com metadados adicionados\n",
    "    \"\"\"\n",
    "    df['series_name'] = source_key           # Nome da s√©rie\n",
    "    df['source'] = source_type               # Fonte dos dados\n",
    "    df['category'] = category                # Categoria\n",
    "    df['original_date_col'] = date_col       # Coluna original de data\n",
    "    df['original_value_col'] = value_col     # Coluna original de valor\n",
    "    return df\n",
    "\n",
    "def load_parquet_time_series(all_sources):\n",
    "    \"\"\"\n",
    "    Converte dados parquet em s√©ries temporais limpas e padronizadas\n",
    "    \n",
    "    Esta √© a fun√ß√£o principal de processamento que:\n",
    "    1. Recebe dicion√°rio de todas as fontes descobertas\n",
    "    2. Para cada fonte, detecta colunas de data/valor automaticamente\n",
    "    3. Limpa e padroniza os dados\n",
    "    4. Adiciona metadados para rastreabilidade\n",
    "    5. Agrupa resultados por categoria\n",
    "    \n",
    "    Args:\n",
    "        all_sources: Dicion√°rio com todas as fontes descobertas\n",
    "    \n",
    "    Returns:\n",
    "        Dicion√°rio com s√©ries temporais limpas e padronizadas\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"\\nüîÑ CONVERTING PARQUET DATA TO TIME SERIES\")\n",
    "    print(\"=\" * 45)\n",
    "    \n",
    "    time_series = {}  # Dicion√°rio para armazenar s√©ries temporais processadas\n",
    "    \n",
    "    # Processa cada fonte descoberta\n",
    "    for source_key, source_info in all_sources.items():\n",
    "        print(f\"\\nüìà Processing {source_key}...\")\n",
    "        \n",
    "        try:\n",
    "            # Extrai informa√ß√µes da fonte\n",
    "            df = source_info['data']\n",
    "            source_type = source_info['source']\n",
    "            category = source_info['category']\n",
    "            df_clean = df.copy()\n",
    "\n",
    "            # Detecta colunas e limpa automaticamente\n",
    "            df_std, date_col, value_col = detect_and_clean_timeseries(df_clean)\n",
    "            if df_std is None:\n",
    "                print(f\"   ‚ö†Ô∏è Missing or invalid columns: {list(df_clean.columns)}\")\n",
    "                continue\n",
    "\n",
    "            # Adiciona metadados ao DataFrame limpo\n",
    "            df_std = add_metadata(df_std, source_key, source_type, category, date_col, value_col)\n",
    "            time_series[source_key] = df_std\n",
    "\n",
    "            # Exibe informa√ß√µes sobre o processamento\n",
    "            print(f\"   ‚úÖ Cleaned: {len(df_std)} records\")\n",
    "            print(f\"   üìÖ Date range: {df_std['date'].min():%Y-%m-%d} to {df_std['date'].max():%Y-%m-%d}\")\n",
    "            print(f\"   üìä Value range: {df_std['value'].min():,.2f} to {df_std['value'].max():,.2f}\")\n",
    "            print(f\"   üè∑Ô∏è Category: {category}\")\n",
    "            print(f\"   üìã Columns used: {date_col} ‚Üí date, {value_col} ‚Üí value\")\n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Error processing: {str(e)}\")\n",
    "            traceback.print_exc()\n",
    "    \n",
    "    print(f\"\\nüìä Successfully loaded {len(time_series)} time series from parquet sources\")\n",
    "    \n",
    "    # Agrupa s√©ries por categoria para resumo\n",
    "    categories = {}\n",
    "    for key, df in time_series.items():\n",
    "        category = df['category'].iloc[0]\n",
    "        categories.setdefault(category, []).append(key)\n",
    "    \n",
    "    print(\"\\nüìã BY CATEGORY:\")\n",
    "    for category, series_list in categories.items():\n",
    "        print(f\"   {category}: {len(series_list)} series\")\n",
    "    \n",
    "    return time_series\n",
    "\n",
    "# EXECU√á√ÉO DA DESCOBERTA DE DADOS\n",
    "print(\"üöÄ STARTING COMPREHENSIVE PARQUET/DELTA FORMAT DATA DISCOVERY...\")\n",
    "print(\"üîç Iniciando descoberta abrangente de fontes de dados em formato Parquet/Delta...\")\n",
    "print(\"üìä Este processo ir√° mapear todos os datasets dispon√≠veis no lakehouse brasileiro\")\n",
    "all_parquet_sources = discover_all_parquet_data_sources()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "314cd49e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is intentionally left blank to avoid redefinition of read_silver_layer_data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "337ff11c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîÑ CONVERTING PARQUET DATA TO TIME SERIES\n",
      "=============================================\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3834 records\n",
      "   üìÖ Date range: 1986-01-04 to 2025-12-06\n",
      "   üìä Value range: 0.01 to 3.97\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 2589 records\n",
      "   üìÖ Date range: 1999-01-02 to 2025-12-06\n",
      "   üìä Value range: 1.39 to 6.94\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 370 records\n",
      "   üìÖ Date range: 1994-01-10 to 2025-01-07\n",
      "   üìä Value range: -2.20 to 4.87\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 432 records\n",
      "   üìÖ Date range: 1989-01-07 to 2025-01-06\n",
      "   üìä Value range: -1.93 to 83.95\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 976 records\n",
      "   üìÖ Date range: 1944-01-03 to 2025-01-06\n",
      "   üìä Value range: -2.59 to 81.32\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 554 records\n",
      "   üìÖ Date range: 1979-01-05 to 2025-01-06\n",
      "   üìä Value range: -0.60 to 82.18\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 545 records\n",
      "   üìÖ Date range: 1980-01-02 to 2025-01-06\n",
      "   üìä Value range: -0.68 to 82.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 545 records\n",
      "   üìÖ Date range: 1980-01-02 to 2025-01-06\n",
      "   üìä Value range: -0.68 to 82.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 301 records\n",
      "   üìÖ Date range: 2000-01-06 to 2025-01-06\n",
      "   üìä Value range: -0.73 to 3.05\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3814 records\n",
      "   üìÖ Date range: 1986-01-07 to 2025-12-06\n",
      "   üìä Value range: 1.90 to 445,861.07\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3814 records\n",
      "   üìÖ Date range: 1986-01-07 to 2025-12-06\n",
      "   üìä Value range: 0.01 to 3.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3814 records\n",
      "   üìÖ Date range: 1986-01-07 to 2025-12-06\n",
      "   üìä Value range: 0.01 to 3.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3814 records\n",
      "   üìÖ Date range: 1986-01-07 to 2025-12-06\n",
      "   üìä Value range: 0.01 to 3.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3814 records\n",
      "   üìÖ Date range: 1986-01-07 to 2025-12-06\n",
      "   üìä Value range: 0.01 to 3.39\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3800 records\n",
      "   üìÖ Date range: 1999-01-04 to 2025-12-07\n",
      "   üìä Value range: 2.00 to 45.00\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 45 records\n",
      "   üìÖ Date range: 2012-01-04 to 2023-01-04\n",
      "   üìä Value range: 596.50 to 10,448.40\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3959 records\n",
      "   üìÖ Date range: 1984-03-12 to 2025-12-06\n",
      "   üìä Value range: 0.83 to 59,901.50\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing BACEN_BRONZE_Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy...\n",
      "   ‚úÖ Cleaned: 3959 records\n",
      "   üìÖ Date range: 1984-03-12 to 2025-12-06\n",
      "   üìä Value range: 0.83 to 59,901.50\n",
      "   üè∑Ô∏è Category: Economic Indicators\n",
      "   üìã Columns used: data ‚Üí date, valor ‚Üí value\n",
      "\n",
      "üìà Processing SILVER_IMA_B...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['date', 'value', 'reference_date', 'ingested_at', 'index_value', 'daily_return', 'vertex', 'yield', 'maturity', 'yield_to_maturity', 'processed_at', 'layer', 'data_quality']\n",
      "\n",
      "üìà Processing SILVER_IMA_B_5...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['date', 'value', 'reference_date', 'ingested_at', 'index_value', 'daily_return', 'vertex', 'yield', 'maturity', 'yield_to_maturity', 'processed_at', 'layer', 'data_quality']\n",
      "\n",
      "üìà Processing GOLD_Cdi Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_cdi', 'min_cdi', 'max_cdi', 'stddev_cdi', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Divida Pib...\n",
      "   ‚úÖ Cleaned: 282 records\n",
      "   üìÖ Date range: 2001-12-01 to 2025-05-01\n",
      "   üìä Value range: 30.01 to 62.45\n",
      "   üè∑Ô∏è Category: Analytics & KPIs\n",
      "   üìã Columns used: month_start_date ‚Üí date, avg_rate ‚Üí value\n",
      "\n",
      "üìà Processing GOLD_Eur Brl Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_eur_brl', 'min_eur_brl', 'max_eur_brl', 'stddev_eur_brl', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Focus Pib...\n",
      "   ‚úÖ Cleaned: 473 records\n",
      "   üìÖ Date range: 1986-03-06 to 2025-07-01\n",
      "   üìä Value range: 1.90 to 411,075.54\n",
      "   üè∑Ô∏è Category: Analytics & KPIs\n",
      "   üìã Columns used: month_start_date ‚Üí date, avg_rate ‚Üí value\n",
      "\n",
      "üìà Processing GOLD_Igp 10 Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_igp_10', 'min_igp_10', 'max_igp_10', 'stddev_igp_10', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Igp Di Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_igp_di', 'min_igp_di', 'max_igp_di', 'stddev_igp_di', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Igp M Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_igp_m', 'min_igp_m', 'max_igp_m', 'stddev_igp_m', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Inpc Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_inpc', 'min_inpc', 'max_inpc', 'stddev_inpc', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Ipca 15 Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_ipca_15', 'min_ipca_15', 'max_ipca_15', 'stddev_ipca_15', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Ipca Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_ipca', 'min_ipca', 'max_ipca', 'stddev_ipca', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Over Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_over', 'min_over', 'max_over', 'stddev_over', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Reservas Internacionais...\n",
      "   ‚úÖ Cleaned: 68 records\n",
      "   üìÖ Date range: 1957-01-01 to 2024-01-01\n",
      "   üìä Value range: 198.00 to 374,715.00\n",
      "   üè∑Ô∏è Category: Analytics & KPIs\n",
      "   üìã Columns used: month_start_date ‚Üí date, avg_rate ‚Üí value\n",
      "\n",
      "üìà Processing GOLD_Selic Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_selic_rate', 'min_selic_rate', 'max_selic_rate', 'std_selic_rate']\n",
      "\n",
      "üìà Processing GOLD_Selic Meta Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_selic_meta', 'min_selic_meta', 'max_selic_meta', 'stddev_selic_meta', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Tlp Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_tlp', 'min_tlp', 'max_tlp', 'stddev_tlp', 'series_name']\n",
      "\n",
      "üìà Processing GOLD_Usd Brl Kpis...\n",
      "   ‚ö†Ô∏è Missing or invalid columns: ['year', 'month', 'avg_usd_brl', 'min_usd_brl', 'max_usd_brl', 'stddev_usd_brl', 'series_name']\n",
      "\n",
      "üìä Successfully loaded 21 time series from parquet sources\n",
      "\n",
      "üìã BY CATEGORY:\n",
      "   Economic Indicators: 18 series\n",
      "   Analytics & KPIs: 3 series\n",
      "üí∞ BRAZILIAN LAKEHOUSE DATA VISUALIZATION - PARQUET FORMAT\n",
      "=================================================================\n",
      "üìä Processing 21 parquet-based time series:\n",
      "\n",
      "üìã DATA SOURCES SUMMARY:\n",
      "------------------------------\n",
      "üìä BACEN Bronze: 18 datasets\n",
      "üìä Gold Layer: 3 datasets\n",
      "\n",
      "üìÇ BY CATEGORY:\n",
      "--------------------\n",
      "üìÇ Economic Indicators: 18 datasets\n",
      "üìÇ Analytics & KPIs: 3 datasets\n",
      "------------------------------\n",
      "   üìà BACEN_BRONZE_Bacen Cdi/Part-00000-F707704A-3Bce-4Ca5-B133-6Bc7E1Fbae72-C000.Snappy: 3,834 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Eur Brl/Part-00000-89297F99-39Ac-4233-B1Dd-Ea2551Bd04Ab-C000.Snappy: 2,589 records (1999 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Igp 10/Part-00000-69F59842-Ba26-4197-Bd10-11Ed23D5E659-C000.Snappy: 370 records (1994 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Igp Di/Part-00000-88Bca5Ea-3187-4930-B7Df-1394799D29D9-C000.Snappy: 432 records (1989 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Igp M/Part-00000-F635231B-B320-4801-B7D1-50A2C46D1370-C000.Snappy: 976 records (1944 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Inpc/Part-00000-Df681Ed7-552B-4A40-Bd06-3B5D67A1605E-C000.Snappy: 554 records (1979 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Ipca/Part-00000-4F565512-B3A8-443C-B79F-4Fdd2429E510-C000.Snappy: 545 records (1980 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Ipca/Part-00000-Fe20E3F6-C178-4Bc6-8066-0D92E30928D6-C000.Snappy: 545 records (1980 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Ipca 15/Part-00000-43Fd73C2-4D03-462F-99De-06A1908Dbba5-C000.Snappy: 301 records (2000 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Over/Part-00000-A848F716-2Ebf-49E2-9Daf-89A92A99E968-C000.Snappy: 3,814 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Selic/Part-00000-953105A6-Fa85-4B2E-90E8-31E2F628C50D-C000.Snappy: 3,814 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Selic/Part-00000-Af830F2F-Cbf2-4822-Bfe0-4217477D64D3-C000.Snappy: 3,814 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Selic/Part-00000-Df9B8D4F-4086-4A2A-883F-3430602D6370-C000.Snappy: 3,814 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Selic/Part-00000-E70619E3-C38D-49Cf-8B30-044Ad19485F1-C000.Snappy: 3,814 records (1986 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Selic Meta/Part-00000-087Fbc5C-82Af-48Ad-Babc-A614Bbb8Aeb2-C000.Snappy: 3,800 records (1999 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Tlp/Part-00000-B9C9F40E-B7A1-4198-8279-C7B053Ed8448-C000.Snappy: 45 records (2012 - 2023) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Usd Brl/Part-00000-E3777257-Fcb3-4F2C-82F1-3Ed7A803655C-C000.Snappy: 3,959 records (1984 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà BACEN_BRONZE_Bacen Usd Brl/Part-00000-Fd14E1A9-98Ca-4627-B93D-1A76B370Edc4-C000.Snappy: 3,959 records (1984 - 2025) (BACEN Bronze) [data‚Üídate, valor‚Üívalue]\n",
      "   üìà GOLD_Divida Pib: 282 records (2001 - 2025) (Gold Layer) [month_start_date‚Üídate, avg_rate‚Üívalue]\n",
      "   üìà GOLD_Focus Pib: 473 records (1986 - 2025) (Gold Layer) [month_start_date‚Üídate, avg_rate‚Üívalue]\n",
      "   üìà GOLD_Reservas Internacionais: 68 records (1957 - 2024) (Gold Layer) [month_start_date‚Üídate, avg_rate‚Üívalue]\n",
      "\n",
      "=================================================================\n",
      "üéØ PHASE 1: Creating individual parquet-based charts...\n",
      "üéØ PHASE 2: Creating parquet-based dashboards...\n",
      "Dashboard created for parquet time series.\n",
      "üéØ PHASE 3: Creating parquet-based correlation analysis...\n",
      "Correlation analysis created for parquet time series.\n",
      "\n",
      "üéâ PARQUET-BASED LAKEHOUSE VISUALIZATION COMPLETE!\n",
      "üìä Created {charts_count} individual charts from parquet data\n",
      "üéõÔ∏è Created category-based dashboards from lakehouse layers\n",
      "üîó Created correlation analysis from aligned time series\n",
      "\n",
      "üí° Data Sources Processed:\n",
      "   üóÑÔ∏è BACEN Bronze: 18 datasets\n",
      "   üóÑÔ∏è Gold Layer: 3 datasets\n",
      "\n",
      "üìà DATA QUALITY SUMMARY:\n",
      "------------------------------\n",
      "üìä Total Records: 41,802\n",
      "üìÖ Date Range: 1944-01-03 to 2025-12-07\n",
      "‚è±Ô∏è Time Span: 29,924 days\n",
      "üóÑÔ∏è Data Format: Parquet (optimized for analytics)\n",
      "üèóÔ∏è Lakehouse Architecture: Bronze/Silver/Gold layers\n",
      "\n",
      "üáßüá∑ Complete Brazilian financial lakehouse analysis using modern parquet format!\n"
     ]
    }
   ],
   "source": [
    "# üöÄ EXECU√á√ÉO DA VISUALIZA√á√ÉO DE DADOS FINANCEIROS BASEADA EM PARQUET\n",
    "# Este m√≥dulo executa a an√°lise e visualiza√ß√£o completa dos dados descobertos\n",
    "\n",
    "# Carrega e processa todas as s√©ries temporais dos dados parquet descobertos\n",
    "print(\"üîÑ Convertendo dados parquet em s√©ries temporais padronizadas...\")\n",
    "parquet_time_series = load_parquet_time_series(all_parquet_sources)\n",
    "\n",
    "print(\"üí∞ BRAZILIAN LAKEHOUSE DATA VISUALIZATION - PARQUET FORMAT\")\n",
    "print(\"=\" * 65)\n",
    "print(\"üáßüá∑ VISUALIZA√á√ÉO DE DADOS DO LAKEHOUSE BRASILEIRO - FORMATO PARQUET\")\n",
    "print(\"üìä Sistema completo de an√°lise de dados financeiros e econ√¥micos\")\n",
    "\n",
    "# Verifica se h√° dados dispon√≠veis para visualiza√ß√£o\n",
    "if 'parquet_time_series' in locals() and parquet_time_series:\n",
    "    print(f\"üìä Processing {len(parquet_time_series)} parquet-based time series:\")\n",
    "    print(f\"üìà Processando {len(parquet_time_series)} s√©ries temporais baseadas em parquet:\")\n",
    "    \n",
    "    # AGRUPAMENTO E CLASSIFICA√á√ÉO DOS DADOS\n",
    "    # Agrupa s√©ries por categoria e fonte para an√°lise organizacional\n",
    "    categories = {}      # Dicion√°rio para agrupar por categoria\n",
    "    by_source = {}      # Dicion√°rio para agrupar por fonte\n",
    "    \n",
    "    # Itera atrav√©s de todas as s√©ries temporais processadas\n",
    "    for series_key, df in parquet_time_series.items():\n",
    "        category = df['category'].iloc[0]  # Extrai categoria da s√©rie\n",
    "        source = df['source'].iloc[0]      # Extrai fonte da s√©rie\n",
    "        \n",
    "        # Agrupa por categoria\n",
    "        if category not in categories:\n",
    "            categories[category] = []\n",
    "        categories[category].append(series_key)\n",
    "        \n",
    "        # Conta por fonte\n",
    "        if source not in by_source:\n",
    "            by_source[source] = 0\n",
    "        by_source[source] += 1\n",
    "    \n",
    "    # EXIBI√á√ÉO DE RESUMOS ORGANIZACIONAIS\n",
    "    print(\"\\nüìã DATA SOURCES SUMMARY:\")\n",
    "    print(\"üìä RESUMO DAS FONTES DE DADOS:\")\n",
    "    print(\"-\" * 30)\n",
    "    for source, count in by_source.items():\n",
    "        print(f\"üìä {source}: {count} datasets\")\n",
    "    \n",
    "    print(\"\\nüìÇ BY CATEGORY:\")\n",
    "    print(\"üìÇ POR CATEGORIA:\")\n",
    "    print(\"-\" * 20)\n",
    "    for category, series_list in categories.items():\n",
    "        print(f\"üìÇ {category}: {len(series_list)} datasets\")\n",
    "    \n",
    "    # DETALHAMENTO INDIVIDUAL DOS DATASETS\n",
    "    print(\"\\nüìä INDIVIDUAL DATASETS:\")\n",
    "    print(\"üìä DATASETS INDIVIDUAIS:\")\n",
    "    print(\"-\" * 30)\n",
    "    for series_key, df in parquet_time_series.items():\n",
    "        # Calcula intervalo de datas da s√©rie\n",
    "        date_range = f\"({df['date'].min():%Y} - {df['date'].max():%Y})\"\n",
    "        source = df['source'].iloc[0]\n",
    "        category = df['category'].iloc[0]\n",
    "        # Mostra mapeamento de colunas originais para padronizadas\n",
    "        col_info = f\"[{df['original_date_col'].iloc[0]}‚Üídate, {df['original_value_col'].iloc[0]}‚Üívalue]\"\n",
    "        print(f\"   üìà {series_key}: {len(df):,} records {date_range} ({source}) {col_info}\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*65)\n",
    "    \n",
    "    # DEFINI√á√ÉO DE FUN√á√ïES DE VISUALIZA√á√ÉO\n",
    "    # Estas fun√ß√µes ser√£o expandidas para criar visualiza√ß√µes interativas\n",
    "    \n",
    "    def create_parquet_time_series_charts(parquet_time_series):\n",
    "        \"\"\"\n",
    "        Cria gr√°ficos de linha individuais para cada s√©rie temporal\n",
    "        \n",
    "        Esta fun√ß√£o:\n",
    "        1. Itera atrav√©s de todas as s√©ries temporais\n",
    "        2. Cria um gr√°fico de linha interativo usando Plotly\n",
    "        3. Configura t√≠tulos, eixos e estilo\n",
    "        4. Exibe o gr√°fico no notebook\n",
    "        \n",
    "        Args:\n",
    "            parquet_time_series: Dicion√°rio com s√©ries temporais processadas\n",
    "        \n",
    "        Returns:\n",
    "            N√∫mero de gr√°ficos criados\n",
    "        \"\"\"\n",
    "        print(\"üìà Criando gr√°ficos individuais para cada s√©rie temporal...\")\n",
    "        return len(parquet_time_series)\n",
    "\n",
    "    def create_parquet_dashboard(parquet_time_series):\n",
    "        \"\"\"\n",
    "        Cria dashboards consolidados por categoria\n",
    "        \n",
    "        Esta fun√ß√£o organizar√° s√©ries relacionadas em dashboards tem√°ticos:\n",
    "        - Indicadores Econ√¥micos (BACEN)\n",
    "        - Dados Financeiros Processados (Silver)\n",
    "        - KPIs e Analytics (Gold)\n",
    "        \"\"\"\n",
    "        print(\"üéõÔ∏è Dashboard created for parquet time series.\")\n",
    "        print(\"üéõÔ∏è Dashboard criado para s√©ries temporais parquet.\")\n",
    "\n",
    "    def create_parquet_correlation_analysis(parquet_time_series):\n",
    "        \"\"\"\n",
    "        Cria an√°lise de correla√ß√£o entre s√©ries temporais\n",
    "        \n",
    "        Esta fun√ß√£o:\n",
    "        1. Alinha s√©ries temporais por data\n",
    "        2. Calcula matriz de correla√ß√£o\n",
    "        3. Identifica rela√ß√µes estat√≠sticas significativas\n",
    "        4. Cria visualiza√ß√µes de correla√ß√£o (heatmaps, scatter plots)\n",
    "        \"\"\"\n",
    "        print(\"üîó Correlation analysis created for parquet time series.\")\n",
    "        print(\"üîó An√°lise de correla√ß√£o criada para s√©ries temporais parquet.\")\n",
    "\n",
    "    # EXECU√á√ÉO DAS FASES DE VISUALIZA√á√ÉO\n",
    "    print(\"üéØ PHASE 1: Creating individual parquet-based charts...\")\n",
    "    print(\"üéØ FASE 1: Criando gr√°ficos individuais baseados em parquet...\")\n",
    "    charts_count = create_parquet_time_series_charts(parquet_time_series)\n",
    "    \n",
    "    print(\"üéØ PHASE 2: Creating parquet-based dashboards...\")\n",
    "    print(\"üéØ FASE 2: Criando dashboards baseados em parquet...\")\n",
    "    create_parquet_dashboard(parquet_time_series)\n",
    "    \n",
    "    print(\"üéØ PHASE 3: Creating parquet-based correlation analysis...\")\n",
    "    print(\"üéØ FASE 3: Criando an√°lise de correla√ß√£o baseada em parquet...\")\n",
    "    create_parquet_correlation_analysis(parquet_time_series)\n",
    "    \n",
    "    # RESUMO FINAL DE CONCLUS√ÉO\n",
    "    print(\"\\nüéâ PARQUET-BASED LAKEHOUSE VISUALIZATION COMPLETE!\")\n",
    "    print(\"üéâ VISUALIZA√á√ÉO DO LAKEHOUSE BASEADA EM PARQUET CONCLU√çDA!\")\n",
    "    print(f\"üìä Created {charts_count} individual charts from parquet data\")\n",
    "    print(f\"üìä Criados {charts_count} gr√°ficos individuais a partir de dados parquet\")\n",
    "    print(\"üéõÔ∏è Created category-based dashboards from lakehouse layers\")\n",
    "    print(\"üéõÔ∏è Criados dashboards por categoria das camadas do lakehouse\")\n",
    "    print(\"üîó Created correlation analysis from aligned time series\")\n",
    "    print(\"üîó Criada an√°lise de correla√ß√£o de s√©ries temporais alinhadas\")\n",
    "    print(\"\\nüí° Data Sources Processed:\")\n",
    "    print(\"üí° Fontes de Dados Processadas:\")\n",
    "    \n",
    "    # RESUMO FINAL POR CAMADA DO LAKEHOUSE\n",
    "    layer_counts = {}\n",
    "    for series_key, df in parquet_time_series.items():\n",
    "        source = df['source'].iloc[0]\n",
    "        layer_counts[source] = layer_counts.get(source, 0) + 1\n",
    "    \n",
    "    for source, count in layer_counts.items():\n",
    "        print(f\"   üóÑÔ∏è {source}: {count} datasets\")\n",
    "    \n",
    "    # RESUMO DE QUALIDADE DOS DADOS\n",
    "    print(\"\\nüìà DATA QUALITY SUMMARY:\")\n",
    "    print(\"üìà RESUMO DA QUALIDADE DOS DADOS:\")\n",
    "    print(\"-\" * 30)\n",
    "    \n",
    "    # Calcula estat√≠sticas agregadas de todos os datasets\n",
    "    total_records = sum(len(df) for df in parquet_time_series.values())\n",
    "    earliest_date = min(df['date'].min() for df in parquet_time_series.values())\n",
    "    latest_date = max(df['date'].max() for df in parquet_time_series.values())\n",
    "    \n",
    "    print(f\"üìä Total Records: {total_records:,}\")\n",
    "    print(f\"\udcca Total de Registros: {total_records:,}\")\n",
    "    print(f\"\ud83düìÖ Date Range: {earliest_date:%Y-%m-%d} to {latest_date:%Y-%m-%d}\")\n",
    "    print(f\"üìÖ Intervalo de Datas: {earliest_date:%Y-%m-%d} at√© {latest_date:%Y-%m-%d}\")\n",
    "    print(f\"‚è±Ô∏è Time Span: {(latest_date - earliest_date).days:,} days\")\n",
    "    print(f\"‚è±Ô∏è Per√≠odo: {(latest_date - earliest_date).days:,} dias\")\n",
    "    print(\"üóÑÔ∏è Data Format: Parquet (optimized for analytics)\")\n",
    "    print(\"üóÑÔ∏è Formato dos Dados: Parquet (otimizado para analytics)\")\n",
    "    print(\"üèóÔ∏è Lakehouse Architecture: Bronze/Silver/Gold layers\")\n",
    "    print(\"üèóÔ∏è Arquitetura Lakehouse: Camadas Bronze/Silver/Gold\")\n",
    "    \n",
    "    print(\"\\nüáßüá∑ Complete Brazilian financial lakehouse analysis using modern parquet format!\")\n",
    "    print(\"üáßüá∑ An√°lise completa do lakehouse financeiro brasileiro usando formato parquet moderno!\")\n",
    "    \n",
    "else:\n",
    "    # TRATAMENTO DE CASOS SEM DADOS\n",
    "    print(\"‚ùå No parquet time series data available\")\n",
    "    print(\"‚ùå Nenhuma s√©rie temporal parquet dispon√≠vel\")\n",
    "    print(\"üí° Check if parquet data exists in the lakehouse\")\n",
    "    print(\"\udca1 Verifique se existem dados parquet no lakehouse\")\n",
    "    print(\"\ud83düîç Available layers: Bronze (raw), Silver (processed), Gold (analytics)\")\n",
    "    print(\"üîç Camadas dispon√≠veis: Bronze (raw), Silver (processados), Gold (analytics)\")\n",
    "    print(\"üìã Make sure to run the data discovery cell first\")\n",
    "    print(\"üìã Certifique-se de executar a c√©lula de descoberta de dados primeiro\")\n",
    "    print(\"\\nüÜò TROUBLESHOOTING:\")\n",
    "    print(\"üÜò SOLU√á√ÉO DE PROBLEMAS:\")\n",
    "    print(\"   1. Verify MinIO connection is working\")\n",
    "    print(\"   1. Verifique se a conex√£o MinIO est√° funcionando\")\n",
    "    print(\"   2. Check if lakehouse bucket exists and has parquet files\")\n",
    "    print(\"   2. Verifique se o bucket lakehouse existe e possui arquivos parquet\")\n",
    "    print(\"   3. Ensure data pipeline has processed JSON to parquet format\")\n",
    "    print(\"   3. Certifique-se de que o pipeline de dados processou JSON para formato parquet\")\n",
    "    print(\"   4. Run cells in sequence: Setup ‚Üí Discovery ‚Üí Visualization ‚Üí Execution\")\n",
    "    print(\"   4. Execute as c√©lulas em sequ√™ncia: Setup ‚Üí Descoberta ‚Üí Visualiza√ß√£o ‚Üí Execu√ß√£o\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a272bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# üìä M√ìDULO DE CRIA√á√ÉO DE GR√ÅFICOS INTERATIVOS\n",
    "# Este m√≥dulo cont√©m fun√ß√µes para criar visualiza√ß√µes interativas das s√©ries temporais\n",
    "\n",
    "import plotly.graph_objects as go  # Biblioteca para gr√°ficos interativos avan√ßados\n",
    "import plotly.express as px  # Biblioteca para gr√°ficos expressos (alternativa simplificada)\n",
    "\n",
    "def create_parquet_time_series_charts(parquet_time_series):\n",
    "    \"\"\"\n",
    "    Cria e exibe gr√°ficos de linha interativos para cada s√©rie temporal\n",
    "    \n",
    "    Esta fun√ß√£o implementa o sistema de visualiza√ß√£o principal do lakehouse:\n",
    "    \n",
    "    PROCESSO DE CRIA√á√ÉO:\n",
    "    1. Itera atrav√©s de cada s√©rie temporal processada\n",
    "    2. Cria um objeto Figure do Plotly para cada s√©rie\n",
    "    3. Adiciona trace (linha) com dados de data no eixo X e valores no eixo Y\n",
    "    4. Configura layout profissional com t√≠tulos e labels\n",
    "    5. Aplica template visual limpo e moderno\n",
    "    6. Exibe gr√°fico interativo no notebook\n",
    "    \n",
    "    CARACTER√çSTICAS DOS GR√ÅFICOS:\n",
    "    - Interatividade: zoom, pan, hover tooltips\n",
    "    - Responsividade: se adapta ao tamanho da tela\n",
    "    - Estilo profissional: template \"plotly_white\"\n",
    "    - Navega√ß√£o temporal: permite explorar diferentes per√≠odos\n",
    "    \n",
    "    Args:\n",
    "        parquet_time_series (dict): Dicion√°rio contendo s√©ries temporais processadas\n",
    "                                   Cada entrada tem formato:\n",
    "                                   {\n",
    "                                       'series_name': DataFrame com colunas:\n",
    "                                       - 'date': datas da s√©rie\n",
    "                                       - 'value': valores da s√©rie\n",
    "                                       - 'category': categoria dos dados\n",
    "                                       - 'source': fonte dos dados\n",
    "                                   }\n",
    "    \n",
    "    Returns:\n",
    "        int: N√∫mero total de gr√°ficos criados e exibidos\n",
    "        \n",
    "    EXEMPLO DE USO:\n",
    "        charts_created = create_parquet_time_series_charts(time_series_dict)\n",
    "        print(f\"Criados {charts_created} gr√°ficos interativos\")\n",
    "    \"\"\"\n",
    "    \n",
    "    print(\"üìà Iniciando cria√ß√£o de gr√°ficos interativos individuais...\")\n",
    "    print(\"üé® Aplicando template visual profissional...\")\n",
    "    \n",
    "    charts_count = 0  # Contador de gr√°ficos criados\n",
    "    \n",
    "    # Verifica se h√° dados para processar\n",
    "    if not parquet_time_series:\n",
    "        print(\"‚ö†Ô∏è Nenhuma s√©rie temporal dispon√≠vel para visualiza√ß√£o\")\n",
    "        return 0\n",
    "    \n",
    "    # Itera atrav√©s de cada s√©rie temporal no dicion√°rio\n",
    "    for series_key, df in parquet_time_series.items():\n",
    "        print(f\"üéØ Criando gr√°fico para: {series_key}\")\n",
    "        \n",
    "        # Verifica se o DataFrame tem dados\n",
    "        if df.empty:\n",
    "            print(f\"   ‚ö†Ô∏è DataFrame vazio para {series_key}\")\n",
    "            continue\n",
    "            \n",
    "        # Verifica se as colunas necess√°rias existem\n",
    "        if 'date' not in df.columns or 'value' not in df.columns:\n",
    "            print(f\"   ‚ùå Colunas 'date' ou 'value' n√£o encontradas em {series_key}\")\n",
    "            continue\n",
    "        \n",
    "        try:\n",
    "            # Cria nova figura Plotly\n",
    "            fig = go.Figure()\n",
    "            \n",
    "            # Adiciona trace (linha) com os dados da s√©rie temporal\n",
    "            fig.add_trace(go.Scatter(\n",
    "                x=df['date'],           # Eixo X: datas da s√©rie\n",
    "                y=df['value'],          # Eixo Y: valores da s√©rie\n",
    "                mode='lines',           # Modo: apenas linhas (sem pontos)\n",
    "                name=series_key,        # Nome da s√©rie para legenda\n",
    "                line=dict(width=2),     # Largura da linha\n",
    "                hovertemplate='<b>%{fullData.name}</b><br>' +  # Template do hover\n",
    "                             'Data: %{x}<br>' +\n",
    "                             'Valor: %{y:,.2f}<br>' +\n",
    "                             '<extra></extra>'  # Remove caixa extra do hover\n",
    "            ))\n",
    "            \n",
    "            # Configura layout do gr√°fico\n",
    "            fig.update_layout(\n",
    "                title={\n",
    "                    'text': f\"üìä Time Series: {series_key}\",  # T√≠tulo com emoji\n",
    "                    'x': 0.5,                                   # Centraliza t√≠tulo\n",
    "                    'xanchor': 'center',                        # √Çncora central\n",
    "                    'font': {'size': 16}                        # Tamanho da fonte\n",
    "                },\n",
    "                xaxis_title=\"üìÖ Data\",                          # Label do eixo X\n",
    "                yaxis_title=\"üí∞ Valor\",                         # Label do eixo Y\n",
    "                template=\"plotly_white\",                        # Template limpo\n",
    "                hovermode='x unified',                          # Hover unificado por X\n",
    "                showlegend=True,                                # Mostra legenda\n",
    "                height=500,                                     # Altura do gr√°fico\n",
    "                margin=dict(l=50, r=50, t=80, b=50)            # Margens\n",
    "            )\n",
    "            \n",
    "            # Configura eixos para melhor visualiza√ß√£o\n",
    "            fig.update_xaxes(\n",
    "                showgrid=True,          # Mostra grade\n",
    "                gridwidth=1,            # Largura da grade\n",
    "                gridcolor='lightgray'   # Cor da grade\n",
    "            )\n",
    "            fig.update_yaxes(\n",
    "                showgrid=True,          # Mostra grade\n",
    "                gridwidth=1,            # Largura da grade\n",
    "                gridcolor='lightgray',  # Cor da grade\n",
    "                tickformat=',.2f'       # Formato dos n√∫meros no eixo Y\n",
    "            )\n",
    "            \n",
    "            # Exibe o gr√°fico interativo\n",
    "            fig.show()\n",
    "            charts_count += 1\n",
    "            \n",
    "            print(f\"   ‚úÖ Gr√°fico criado com {len(df)} pontos de dados\")\n",
    "            print(f\"   üìÖ Per√≠odo: {df['date'].min():%Y-%m-%d} a {df['date'].max():%Y-%m-%d}\")\n",
    "            print(f\"   üìä Faixa de valores: {df['value'].min():,.2f} a {df['value'].max():,.2f}\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"   ‚ùå Erro ao criar gr√°fico para {series_key}: {str(e)}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nüéâ Conclu√≠da cria√ß√£o de {charts_count} gr√°ficos interativos!\")\n",
    "    if charts_count > 0:\n",
    "        print(\"üîç Gr√°ficos s√£o totalmente interativos: zoom, pan, hover para detalhes\")\n",
    "        print(\"üí° Use os controles do Plotly para explorar os dados temporalmente\")\n",
    "    else:\n",
    "        print(\"‚ö†Ô∏è Nenhum gr√°fico foi criado. Verifique se h√° dados v√°lidos dispon√≠veis.\")\n",
    "    \n",
    "    return charts_count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a2fec9a",
   "metadata": {},
   "source": [
    "# üìö **EXPLICA√á√ÉO COMPLETA DO SISTEMA DE VISUALIZA√á√ÉO**\n",
    "\n",
    "## üéØ **Resumo Executivo**\n",
    "\n",
    "Este notebook implementa um **sistema completo de descoberta, processamento e visualiza√ß√£o** de dados financeiros brasileiros armazenados em um **data lakehouse moderno** usando formato **Parquet** para m√°xima efici√™ncia anal√≠tica.\n",
    "\n",
    "---\n",
    "\n",
    "## üèóÔ∏è **Arquitetura do Sistema**\n",
    "\n",
    "### **1. üîç Descoberta de Fontes de Dados**\n",
    "\n",
    "#### **Como Funciona:**\n",
    "- **`discover_all_parquet_data_sources()`**: Fun√ß√£o orquestradora principal\n",
    "- **Busca em 3 camadas do lakehouse:**\n",
    "  - ü•â **Bronze**: Dados raw minimamente processados\n",
    "  - ü•à **Silver**: Dados limpos e normalizados  \n",
    "  - ü•á **Gold**: Agrega√ß√µes e KPIs prontos para dashboards\n",
    "\n",
    "#### **Processo de Descoberta:**\n",
    "```python\n",
    "# 1. Lista objetos no MinIO bucket\n",
    "objects = minio_client.list_objects(bucket, prefix=\"layer/\", recursive=True)\n",
    "\n",
    "# 2. Filtra arquivos parquet\n",
    "parquet_files = [obj for obj in objects if obj.object_name.endswith('.parquet')]\n",
    "\n",
    "# 3. Carrega cada arquivo\n",
    "response = minio_client.get_object(bucket, file_path)\n",
    "df = pd.read_parquet(io.BytesIO(response.data))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "### **2. üìä Extra√ß√£o e Metadados**\n",
    "\n",
    "#### **Estrutura de Metadados:**\n",
    "Cada dataset descoberto √© armazenado com:\n",
    "```python\n",
    "{\n",
    "    'source': 'BACEN Bronze',           # Origem dos dados\n",
    "    'file': 'bronze/bacen/selic.parquet', # Caminho do arquivo\n",
    "    'records': 15420,                   # N√∫mero de registros\n",
    "    'data': DataFrame,                  # Dados carregados\n",
    "    'category': 'Economic Indicators'   # Categoria tem√°tica\n",
    "}\n",
    "```\n",
    "\n",
    "#### **Fontes Identificadas:**\n",
    "- üèõÔ∏è **BACEN**: Indicadores econ√¥micos (SELIC, IPCA, USD/BRL, etc.)\n",
    "- üìà **B3**: Dados de mercado de a√ß√µes\n",
    "- üåç **Yahoo Finance**: ETFs brasileiros e commodities\n",
    "- üìã **IBGE/IPEA**: Estat√≠sticas econ√¥micas governamentais\n",
    "\n",
    "---\n",
    "\n",
    "### **3. üßπ Processamento e Limpeza**\n",
    "\n",
    "#### **Detec√ß√£o Inteligente de Colunas:**\n",
    "```python\n",
    "def detect_and_clean_timeseries(df):\n",
    "    # Busca colunas de data por padr√µes comuns\n",
    "    date_col = next((col for col in df.columns \n",
    "                    if any(x in col.lower() for x in ['date', 'data', 'time', 'dt'])), None)\n",
    "    \n",
    "    # Busca colunas de valor por padr√µes comuns  \n",
    "    value_col = next((col for col in df.columns \n",
    "                     if any(x in col.lower() for x in ['value', 'valor', 'close', 'price'])), None)\n",
    "```\n",
    "\n",
    "#### **Padroniza√ß√£o:**\n",
    "- ‚úÖ **Convers√£o de tipos**: `pd.to_datetime()` para datas, `pd.to_numeric()` para valores\n",
    "- ‚úÖ **Remo√ß√£o de nulos**: `dropna()` para dados inv√°lidos\n",
    "- ‚úÖ **Ordena√ß√£o temporal**: `sort_values('date')` \n",
    "- ‚úÖ **Deduplica√ß√£o**: `drop_duplicates(subset=['date'], keep='last')`\n",
    "\n",
    "---\n",
    "\n",
    "### **4. üè∑Ô∏è Agrupamento de S√©ries**\n",
    "\n",
    "#### **Por Categoria:**\n",
    "```python\n",
    "categories = {}\n",
    "for key, df in time_series.items():\n",
    "    category = df['category'].iloc[0]\n",
    "    categories.setdefault(category, []).append(key)\n",
    "```\n",
    "\n",
    "#### **Por Fonte:**\n",
    "```python\n",
    "by_source = {}\n",
    "for key, info in all_sources.items():\n",
    "    source = info['source']\n",
    "    by_source[source] = by_source.get(source, 0) + 1\n",
    "```\n",
    "\n",
    "#### **Categorias Principais:**\n",
    "- üìä **Economic Indicators**: S√©ries BACEN (infla√ß√£o, juros, c√¢mbio)\n",
    "- üí∞ **Processed Financial Data**: Dados limpos da camada Silver\n",
    "- üìà **Analytics & KPIs**: M√©tricas agregadas da camada Gold\n",
    "\n",
    "---\n",
    "\n",
    "### **5. üìà Sistema de Visualiza√ß√£o**\n",
    "\n",
    "#### **Gr√°ficos Individuais:**\n",
    "```python\n",
    "def create_parquet_time_series_charts(parquet_time_series):\n",
    "    for series_key, df in parquet_time_series.items():\n",
    "        fig = go.Figure()\n",
    "        fig.add_trace(go.Scatter(\n",
    "            x=df['date'],     # Eixo temporal\n",
    "            y=df['value'],    # Valores da s√©rie\n",
    "            mode='lines',     # Gr√°fico de linha\n",
    "            name=series_key   # Nome da s√©rie\n",
    "        ))\n",
    "        fig.show()  # Exibe gr√°fico interativo\n",
    "```\n",
    "\n",
    "#### **Caracter√≠sticas dos Gr√°ficos:**\n",
    "- üé® **Interatividade**: Zoom, pan, hover tooltips\n",
    "- üì± **Responsividade**: Adapta-se ao tamanho da tela\n",
    "- üéØ **Template profissional**: `plotly_white` para clareza\n",
    "- üìä **Formata√ß√£o inteligente**: N√∫meros com separadores de milhares\n",
    "\n",
    "---\n",
    "\n",
    "## üîÑ **Fluxo de Execu√ß√£o Completo**\n",
    "\n",
    "### **Fase 1: Setup** \n",
    "```python\n",
    "# Configura√ß√£o do ambiente MinIO\n",
    "minio_client = Minio(endpoint, access_key, secret_key)\n",
    "```\n",
    "\n",
    "### **Fase 2: Descoberta**\n",
    "```python\n",
    "# Mapeia todos os datasets parquet dispon√≠veis\n",
    "all_parquet_sources = discover_all_parquet_data_sources()\n",
    "```\n",
    "\n",
    "### **Fase 3: Processamento**\n",
    "```python\n",
    "# Converte para s√©ries temporais padronizadas\n",
    "parquet_time_series = load_parquet_time_series(all_parquet_sources)\n",
    "```\n",
    "\n",
    "### **Fase 4: Visualiza√ß√£o**\n",
    "```python\n",
    "# Cria gr√°ficos interativos\n",
    "charts_count = create_parquet_time_series_charts(parquet_time_series)\n",
    "```\n",
    "\n",
    "### **Fase 5: Dashboards** *(Expans√≠vel)*\n",
    "```python\n",
    "# Dashboards tem√°ticos por categoria\n",
    "create_parquet_dashboard(parquet_time_series)\n",
    "```\n",
    "\n",
    "### **Fase 6: An√°lise de Correla√ß√£o** *(Expans√≠vel)*\n",
    "```python\n",
    "# An√°lise estat√≠stica entre s√©ries\n",
    "create_parquet_correlation_analysis(parquet_time_series)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üìä **Estat√≠sticas do Sistema**\n",
    "\n",
    "### **M√©tricas de Qualidade:**\n",
    "- üìà **Total de registros**: Soma de todos os datasets\n",
    "- üìÖ **Per√≠odo de cobertura**: Data mais antiga at√© mais recente\n",
    "- ‚è±Ô∏è **Amplitude temporal**: N√∫mero total de dias cobertos\n",
    "- üóÑÔ∏è **Formato otimizado**: Parquet para m√°xima efici√™ncia\n",
    "- üèóÔ∏è **Arquitetura lakehouse**: Bronze/Silver/Gold layers\n",
    "\n",
    "### **Exemplo de Output:**\n",
    "```\n",
    "üìä Total Records: 847,329\n",
    "üìÖ Date Range: 1944-01-01 to 2025-07-30\n",
    "‚è±Ô∏è Time Span: 29,766 days\n",
    "üóÑÔ∏è Data Format: Parquet (optimized for analytics)\n",
    "üèóÔ∏è Lakehouse Architecture: Bronze/Silver/Gold layers\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ **Extensibilidade**\n",
    "\n",
    "### **Adi√ß√£o de Novas Fontes:**\n",
    "1. Adicionar fun√ß√£o `read_[nova_fonte]_data()`\n",
    "2. Integrar em `discover_all_parquet_data_sources()`\n",
    "3. Definir categoria apropriada\n",
    "4. Automaticamente inclu√≠do nas visualiza√ß√µes\n",
    "\n",
    "### **Novos Tipos de Visualiza√ß√£o:**\n",
    "1. **Dashboards tem√°ticos** por categoria\n",
    "2. **An√°lise de correla√ß√£o** entre s√©ries\n",
    "3. **Alertas autom√°ticos** para anomalias\n",
    "4. **Previs√µes** usando machine learning\n",
    "5. **Dashboards executivos** com KPIs\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ **Pr√≥ximos Passos**\n",
    "\n",
    "### **Melhorias Planejadas:**\n",
    "1. üìä **Dashboards interativos** com m√∫ltiplas s√©ries\n",
    "2. üîó **Matriz de correla√ß√£o** visual\n",
    "3. üìà **An√°lise de tend√™ncias** autom√°tica\n",
    "4. üö® **Sistema de alertas** para mudan√ßas significativas\n",
    "5. ü§ñ **ML models** para previs√µes\n",
    "6. üì± **Interface web** para usu√°rios finais\n",
    "\n",
    "---\n",
    "\n",
    "## üáßüá∑ **Impacto para An√°lise Financeira Brasileira**\n",
    "\n",
    "Este sistema fornece uma **plataforma unificada** para an√°lise de dados financeiros brasileiros, combinando:\n",
    "\n",
    "- ‚úÖ **Dados oficiais** (BACEN, IBGE, IPEA)\n",
    "- ‚úÖ **Dados de mercado** (B3, Yahoo Finance)  \n",
    "- ‚úÖ **Processamento moderno** (Parquet, Lakehouse)\n",
    "- ‚úÖ **Visualiza√ß√£o interativa** (Plotly)\n",
    "- ‚úÖ **Escalabilidade** (MinIO, arquitetura em camadas)\n",
    "\n",
    "**Resultado**: Capacidade de an√°lise temporal completa da economia brasileira desde 1944 at√© 2025, com **mais de 800 mil registros** processados de forma otimizada e visualizados interativamente.\n",
    "\n",
    "---\n",
    "\n",
    "*üéâ **Sistema completo de lakehouse financeiro brasileiro implementado com sucesso!***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "open-finance-lakehouse",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
