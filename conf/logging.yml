# To enable this custom logging configuration, set KEDRO_LOGGING_CONFIG to the path of this file.
# More information available at https://docs.kedro.org/en/stable/logging/logging.html
version: 1

disable_existing_loggers: False

formatters:
  simple:
    format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"

handlers:
  console:
    class: logging.StreamHandler
    level: INFO
    formatter: simple
    stream: ext://sys.stdout

  info_file_handler:
    class: logging.handlers.RotatingFileHandler
    level: INFO
    formatter: simple
    filename: info.log
    maxBytes: 10485760 # 10MB
    backupCount: 20
    encoding: utf8
    delay: True

  rich:
    class: kedro.logging.RichHandler
    rich_tracebacks: True
    # Advance options for customisation.
    # See https://docs.kedro.org/en/stable/logging/logging.html#project-side-logging-configuration
    # tracebacks_show_locals: False

loggers:
  kedro:
    level: INFO
    
  # Suppress Kedro deprecation warnings 
  kedro.io.data_catalog:
    level: ERROR
    
  # Suppress MLflow warnings
  mlflow:
    level: ERROR
    
  # Suppress Spark verbose output
  pyspark:
    level: WARN
    
  py4j:
    level: WARN
    
  # Suppress Hadoop S3A metrics warnings
  org.apache.hadoop.metrics2:
    level: ERROR
    
  # Suppress Spark temp directory cleanup warnings (Windows)
  org.apache.spark.SparkEnv:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.spark.util.ShutdownHookManager:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.spark.network.util.JavaUtils:
    level: ERROR
    handlers: [console]
    propagate: no
    
  # Suppress all Spark shutdown and cleanup related warnings
  org.apache.spark.util.Utils:
    level: ERROR 
    handlers: [console]
    propagate: no
    
  org.apache.spark.SparkContext:
    level: ERROR 
    handlers: [console]
    propagate: no
    
  org.apache.spark.util.SparkFileUtils:
    level: ERROR    
    handlers: [console]
    propagate: no
    
  # Suppress Java IO warnings during Spark cleanup
  java.io.IOException:
    level: ERROR
    handlers: [console]
    propagate: no
    
  # Suppress Ivy dependency resolution messages
  org.apache.ivy:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.ivy.core.resolve.ResolveEngine:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.ivy.plugins.resolver:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.ivy.plugins.repository:
    level: ERROR
    handlers: [console]
    propagate: no
  
  # Suppress Spark launcher and dependency resolution
  org.apache.spark.deploy.SparkSubmit:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.spark.launcher:
    level: ERROR
    handlers: [console]
    propagate: no
    
  org.apache.spark.launcher.OutputRedirector:
    level: ERROR
    handlers: [console]
    propagate: no

  pyspark_spaceflights:
    level: INFO

root:
  handlers: [rich, info_file_handler]
